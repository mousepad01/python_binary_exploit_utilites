from __future__ import annotations
from typing import Dict, Generator, List, Tuple, Set
# both above imports only for type hints

from copy import deepcopy
from rand import random
from sys import stdout

from parsebin import *
from utils import to_bytes, _is_int
from logger import Logger

from rop_platform import Platform
from stackview import Stack_view
from structured_element import Structured_element
from effect import Effect

from capstone import *
import z3

# NOTE: this file (currently) only implements functionality for x86_64 ELF files
# NOTE: any "address"-related keyword used does NOT take into accound ASLR / PIE

# TODO: option to create chains from gadgets from different binaries
# TODO: support for AARCH64

# gadget class that has associated a stack view and its effects (currently, operating on registers and/or stack popping)
# a gadget object can store two identical gadgets, but at different addresses
class ROP_gadget_x86_64:

    # maximum gadget byte length to be searched for
    MAX_GADGET_BYTE_LEN = 30

    def __init__(self):

        self.stack = Stack_view()
        self.effects: List[Effect] = []

        # self.b - bytes of the gadget
        # useful for identification (hashing) of a gadget / chain
        self.b: bytes = None

        # self.addrs - addresses of identical gadgets
        # used only at payload generation
        self.addrs: List[int] = []
    
        # self.eq_g - gadgets that differ by stack padding or nop instructions
        # used only at payload generation
        self.eq_g: List[ROP_gadget_x86_64] = []

    def get_bytes(self):
        return self.b

    def get_stack_size(self):
        return len(self.stack.elements)

    # by default, it contains the addresses without ASLR/PIE offsets
    def get_current_addrs(self):
        return [Stack_view.stack_values[addr] for addr in self.addrs]

    def show(self, capstone_handle: Cs = None, show_addr = True, show_stack = True, output_handle = stdout):
        
        if len(self.addrs) == 0:
            print("(empty gadget)", file = output_handle)
            return

        if capstone_handle is None:
            capstone_handle = Cs(CS_ARCH_X86, CS_MODE_64)

        disas_instr_generator = capstone_handle.disasm(self.b, self.get_current_addrs()[0])
        for ins in disas_instr_generator:

            if show_addr is True:
                print(f"{hex(ins.address)}: {ins.mnemonic} {ins.op_str}", file = output_handle)
            else:
                print(f"{ins.mnemonic} {ins.op_str}", file = output_handle)

        if show_stack is True:

            _s = f"----- STACK ({self.get_stack_size()} ELEMENTS) -----"
            print(_s, file = output_handle)

            self._show_stack_values(output_handle)

            print("-" * len(_s), file = output_handle)

    def _show_stack_values(self, output_handle):

        for idx, el in enumerate(self.stack.elements):

            if el.type == "64b_stack_val":

                val = Stack_view.stack_values[el.info['id']]
                if val is not None:
                    print(f"(+{hex(idx * 8)}) id {el.info['id']}: {hex(val)}", file = output_handle)
                else:
                    print(f"(+{hex(idx * 8)}) id {el.info['id']}: EMPTY", file = output_handle)
            else:
                print(f"(+{hex(idx * 8)}) ====PAD====", file = output_handle)

    def add_current_addr(self, addr: int):

        new_addr_id = Stack_view.get_elem_id()
        self.addrs.append(new_addr_id)
        Stack_view.stack_values[new_addr_id] = addr

    # auxiliary internal method for duplication
    def _duplicate_stack(self, cpy: ROP_gadget_x86_64 | ROP_chain_x86_64, copy_stack_associated_values):
        
        old_new_id: Dict[int, int] = {}
        def _get_new_id(old_id: int):
            
            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # recursive search for stack elements that need to be replaced
        def _recursive_replace(op_element: Structured_element):
            
            if op_element.type == "64b_stack_val":
                op_element.info["id"] = _get_new_id(op_element.info["id"])

            elif op_element.is_op():
                
                if op_element.info["term_1"] is not None:
                    _recursive_replace(op_element.info["term_1"])

                if op_element.info["term_2"] is not None:
                    _recursive_replace(op_element.info["term_2"])

        for stack_elem in self.stack.elements:

            if stack_elem.type == "64b_stack_pad":
                cpy.stack.push(Structured_element.instantiate_structured_element("64b_stack_pad"))

            elif stack_elem.type == "64b_stack_val":

                cpy_stack_elem = Structured_element.instantiate_structured_element("64b_stack_val")

                # check whether the current id has already been replaced in a previous stack element instance
                cpy_id = _get_new_id(stack_elem.info["id"])
                if cpy_id is None:
                    
                    cpy_stack_elem.info["id"] = Stack_view.get_elem_id()
                    old_new_id.update({stack_elem.info["id"]: cpy_stack_elem.info["id"]})

                    if copy_stack_associated_values is True:
                        Stack_view.stack_values[cpy_stack_elem.info["id"]] = Stack_view.stack_values[stack_elem.info["id"]]

                else:
                    cpy_stack_elem.info["id"] = cpy_id                    

                cpy.stack.push(cpy_stack_elem)

        cpy.effects = deepcopy(self.effects)
        for ef in cpy.effects:

            if ef.type == "LOAD_S":
                ef.params[0].info["id"] = _get_new_id(ef.params[0].info["id"])

            elif ef.type == "ARITH":
                _recursive_replace(ef.params[0])

        return cpy, old_new_id

    # a gadget has fixed stack element ids that are kept globally
    # so to use multiple times the same gadget,
    # a duplicate method is needed, that automatically 
    # makes a deep copy of the stack elements and ids, and also the effects
    # it returns the new copy and the old_new_id list
    # NOTE: if the old id had an associated value, it also copies it, if chosen so
    # NOTE: does NOT duplicate the elements from eq_g
    def duplicate(self, copy_stack_associated_values = True):

        cpy = ROP_gadget_x86_64()

        cpy.b = self.b

        cpy.eq_g = self.eq_g.copy()
  
        cpy.addrs = self.addrs.copy()
        for i in range(len(cpy.addrs)):
            
            addr_val = Stack_view.stack_values[cpy.addrs[i]]
            addr_id_cpy = Stack_view.get_elem_id()
            Stack_view.stack_values[addr_id_cpy] = addr_val            
            cpy.addrs[i] = addr_id_cpy

        return self._duplicate_stack(cpy, copy_stack_associated_values)
    
    # this method should ONLY be called when you DO NOT NEED THE GADGET ANYMORE
    # it clears the stack and removes the id s that are also present in the corresponding dictionary
    # so that no memory is leaked
    # NOTE: does not remove anything from eq_g
    def remove_stack_ids(self):
        
        self.b = None
        self.effects = None

        for addr_id in self.addrs:
            Stack_view.stack_values.pop(addr_id, None)

        for stack_elem in self.stack.elements:
            if stack_elem.type == "64b_stack_val":
                Stack_view.stack_values.pop(stack_elem.info["id"], None)   # if the key does not exist, None is returned

        self.stack = None

    # function to check whether the given registers remain unchanged or not
    def check_fixed_regs(self, fixed_reg_list: List[str]):

        for fixed_r in fixed_reg_list:
            for ef in self.effects:

                if ef.destination_element.info["reg_name"] == fixed_r: 

                    if ef.type in ["LOAD_CT", "MOV_RR", "LOAD_S"]:
                        return False

                    elif ef.type == "ARITH":
                        
                        nop_mov = Effect.make_mov_rr_effect(fixed_r, fixed_r)
                        if Effect._match_arith(nop_mov, ef) is False:
                            return False

        return True

    # auxiliary internal method for joining gadgets / chains
    @staticmethod
    def _join_ef_stk(fst: ROP_gadget_x86_64 | ROP_chain_x86_64, snd: ROP_gadget_x86_64 | ROP_chain_x86_64):

        fst_cpy, _ = fst.duplicate(copy_stack_associated_values=True)
        snd_cpy, _ = snd.duplicate(copy_stack_associated_values=True)

        joined_effects = Effect.join_effects(fst_cpy.effects, snd_cpy.effects)
        joined_stack = Stack_view.join_stacks(fst_cpy.stack, snd_cpy.stack)

        res_chain = ROP_chain_x86_64()

        res_chain.stack = joined_stack
        res_chain.effects = joined_effects

        return res_chain, fst_cpy, snd_cpy

    def join(self, snd: ROP_gadget_x86_64 | ROP_chain_x86_64) -> ROP_chain_x86_64:

        fst_cpy: ROP_gadget_x86_64
        res_chain, fst_cpy, snd_cpy = ROP_gadget_x86_64._join_ef_stk(self, snd)

        if type(snd) == ROP_chain_x86_64:

            res_chain.b = [fst_cpy.b] + snd_cpy.b
            res_chain.gadgets_stackview_offset = [0] + [off + fst_cpy.get_stack_size() for off in snd_cpy.gadgets_stackview_offset]
            res_chain.addrs = [fst_cpy.addrs] + snd_cpy.addrs
            res_chain.eq_g = [fst_cpy.eq_g] + snd_cpy.eq_g

        else:

            res_chain.b = [fst_cpy.b, snd_cpy.b]
            res_chain.gadgets_stackview_offset = [0, fst_cpy.get_stack_size()]
            res_chain.addrs = [fst_cpy.addrs, snd_cpy.addrs]
            res_chain.eq_g = [fst_cpy.eq_g, snd_cpy.eq_g]

        return res_chain

    # mostly for debugging purposes
    def __str__(self):
        return f"ROP gadget with stack {self.stack}, addresses are {self.get_current_addrs()}, effects {[str(ef) for ef in self.effects]}"

# class to store rop chains, 
# in almost the same way as rop gadgets
class ROP_chain_x86_64(ROP_gadget_x86_64):

    def __init__(self):

        self.stack: Stack_view = Stack_view()
        self.effects: List[Effect] = []

        self.b: List[bytes] = []

        self.addrs: List[List[int]] = []
        self.eq_g: List[List[ROP_gadget_x86_64]] = []

        # self.gadgets_stackview_offset - stack offset for each gadget
        self.gadgets_stackview_offset: List[int] = []

    # converts a gadget to a chain with only one gadget
    # does NOT copy
    @staticmethod
    def convert(gadget: ROP_gadget_x86_64) -> ROP_chain_x86_64:

        # no conversion needed
        if type(gadget) == ROP_chain_x86_64:
            return gadget

        chain = ROP_chain_x86_64()

        chain.effects = gadget.effects
        chain.stack = gadget.stack

        chain.b = [gadget.b]
        chain.gadgets_stackview_offset = [0]
        chain.addrs = [gadget.addrs]
        chain.eq_g = [gadget.eq_g]

        return chain

    def get_bytes(self):
        
        acc_b = b''
        for b_ in self.b:
            acc_b += b_

        return acc_b

    def get_gadget_cnt(self):
        return len(self.gadgets_stackview_offset)

    # generator instead of function as in ROP_gadget_x86_64 class
    def get_current_addrs(self): 
        for i in range(self.get_gadget_cnt()):
            yield [Stack_view.stack_values[addr_id] for addr_id in self.addrs[i]]

    def show(self, capstone_handle: Cs = None, show_addr = True, show_stack = True, output_handle = stdout):
        
        if len(self.addrs) == 0:
            print("(empty chain)", file = output_handle)
            return

        if capstone_handle is None:
            capstone_handle = Cs(CS_ARCH_X86, CS_MODE_64)

        _i = 0
        for addrs in self.get_current_addrs():

            disas_instr_generator = capstone_handle.disasm(self.b[_i], addrs[0])
            for ins in disas_instr_generator:

                if show_addr is True:
                    print(f"{hex(ins.address)}: {ins.mnemonic} {ins.op_str}")
                else:
                    print(f"{ins.mnemonic} {ins.op_str}")

            _i += 1

        if show_stack is True:

            _s = f"----- STACK ({self.get_stack_size()} ELEMENTS) -----"
            print(_s, file = output_handle)

            self._show_stack_values(output_handle)
            
            print("-" * len(_s), file = output_handle)

    def add_current_addr(self, addr: int, idx: int):
        
        new_addr_id = Stack_view.get_elem_id()
        self.addrs[idx].append(new_addr_id)
        Stack_view.stack_values[new_addr_id] = addr

    def duplicate(self, copy_stack_associated_values = True):

        cpy = ROP_chain_x86_64()

        cpy.b = self.b.copy()
        cpy.gadgets_stackview_offset = self.gadgets_stackview_offset.copy()
        cpy.eq_g = [l.copy() for l in self.eq_g]

        cpy.addrs = deepcopy(self.addrs)
        for i in range(self.get_gadget_cnt()):
            for j in range(len(cpy.addrs[i])):
            
                addr_val = Stack_view.stack_values[cpy.addrs[i][j]]
                addr_id_cpy = Stack_view.get_elem_id()
                Stack_view.stack_values[addr_id_cpy] = addr_val            
                cpy.addrs[i][j] = addr_id_cpy

        return self._duplicate_stack(cpy, copy_stack_associated_values)
    
    def remove_stack_ids(self):
        
        for i in range(self.get_gadget_cnt()):
            for addr in self.addrs[i]:
                Stack_view.stack_values.pop(addr, None)

        for stack_elem in self.stack.elements:
            if stack_elem.type == "64b_stack_val":
                Stack_view.stack_values.pop(stack_elem.info["id"], None)   # if the key does not exist, None is returned

        self.b = None
        self.effects = None
        self.gadgets_stackview_offset = None
        self.stack = None

    def join(self, snd: ROP_gadget_x86_64 | ROP_chain_x86_64) -> ROP_chain_x86_64:

        fst_cpy: ROP_chain_x86_64
        res_chain, fst_cpy, snd_cpy = ROP_gadget_x86_64._join_ef_stk(self, snd)
        
        if type(snd) == ROP_chain_x86_64:

            res_chain.b = fst_cpy.b + snd_cpy.b
            res_chain.gadgets_stackview_offset = fst_cpy.gadgets_stackview_offset
            res_chain.gadgets_stackview_offset += [off + fst_cpy.get_stack_size() for off in snd_cpy.gadgets_stackview_offset]
            res_chain.addrs = fst_cpy.addrs + snd_cpy.addrs
            res_chain.eq_g = fst_cpy.eq_g + snd_cpy.eq_g

        else:

            res_chain.b = fst_cpy.b
            res_chain.b.append(snd_cpy.b)
            res_chain.gadgets_stackview_offset = fst_cpy.gadgets_stackview_offset
            res_chain.gadgets_stackview_offset.append(fst_cpy.get_stack_size())
            res_chain.addrs = fst_cpy.addrs
            res_chain.addrs.append(snd_cpy.addrs)
            res_chain.eq_g = fst_cpy.eq_g
            res_chain.eq_g.append(snd_cpy.eq_g)

        return res_chain
    
    # method responsible for building payload for a single chain
    # addr_offset - to be added to (all) original addresses from this chain (eg. because of ASLR)
    # forbidden_bytes - list of forbidden bytes, that can force replacing current gadgets with alternatives
    # NOTE: payload can only be built from a chain, and not a gadget (for implementation simplicity)
    #       if a gadget is needed, it can be converted to a chain and then the payload can be built
    # NOTE: gadgets from eq_g are expected to be sorted by stack size
    def _make_payload(self, max_stack_size: int, forbidden_bytes: List[bytes] = [], 
                        addr_offset: int = 0, pad_byte = b'A') -> bytes:
        
        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in forbidden_bytes:
                    return False

            return True

        payload = b''

        for i in range(self.get_gadget_cnt()):

            found = False

            stack_offset = self.gadgets_stackview_offset[i]

            stack_end = 0
            if i == self.get_gadget_cnt() - 1:
                stack_end = len(self.stack.elements)
            else:
                stack_end = self.gadgets_stackview_offset[i + 1]

            stacks = [self.stack.elements[stack_offset: stack_end]] + [g.stack.elements for g in self.eq_g[i]]
            addrs = [self.addrs[i]] + [g.addrs for g in self.eq_g[i]]

            for j in range(len(stacks)):
                if len(stacks[j]) <= max_stack_size:

                    for k in range(len(addrs[j])):
                        
                        b_addr = to_bytes(Stack_view.stack_values[addrs[j][k]] + addr_offset)

                        if _check_bytes(b_addr) is True:

                            payload += b_addr
                            
                            found = True
                            for el in stacks[j][:-1]:

                                if el.type == "64b_stack_pad":
                                    payload += pad_byte * 8

                                elif el.type == "64b_stack_val":
                                    
                                    val = Stack_view.stack_values[el.info["id"]]

                                    if val is None:
                                        payload += pad_byte * 8
                                        continue
                                
                                    b = to_bytes(val)
                                    if _check_bytes(b) is True:
                                        payload += b
                                    else:
                                        return None     # stacks differ only by padding, so if a forbidden byte is found, 
                                                        # it is clear that there is no way of constructing the payload

                            max_stack_size -= len(stacks[j])
                            
                            if found is True:
                                break

                if found is True:
                    break

            if found is False:
                return None

        if len(payload) % 8 != 0:
            raise RuntimeError(f"Payload is not 8-byte aligned (length: {len(payload)})")
                        
        return payload

    # mostly for debugging purposes
    def __str__(self):
        return f"ROP chain with stack {self.stack}, addresses are {'TODO'}, effects {[str(ef) for ef in self.effects]}"

# class that is responsible for implementing gadget/chain searching
# also has a cache of found and processed gadgets
class ROP_searcher_x86_64:

    def __init__(self, filepath: str):

        def _find_endpoints_offsets():

            endpoints_offsets = []
            
            for i in range(len(self.exec_bytes)):
                
                xc_offset, xc = self.exec_bytes[i]
                for ib in range(len(xc)):

                    if xc[ib: ib + 1] in Platform.X86_64.ENDPOINTS.keys():
                        endpoints_offsets.append((i, xc_offset + ib))
            
            return endpoints_offsets

        def _find_ret_offsets():

            ret_offsets = []

            for i in range(len(self.exec_bytes)):
                
                xc_offset, xc = self.exec_bytes[i]
                for ib in range(len(xc)):

                    if xc[ib: ib + 1] == b'\xc3':
                        ret_offsets.append((i, xc_offset + ib))

            return ret_offsets

        self.exec_bytes = Elf_util(filepath).load_x_bytes()
        self.capstone = Cs(CS_ARCH_X86, CS_MODE_64)

        # constant, can be changed, but 3 is the maximum recommended value
        self.BRUTEFORCE_DEPTH = 2

        self.ret_offsets: List[Tuple[int, int]] = _find_ret_offsets()
        self.endpoints_offsets: List[Tuple[int, int]] = _find_endpoints_offsets()
        # endpoints (other than ret) UNUSED in x86 64

        self.gadgets: Set[ROP_gadget_x86_64] = set()
        self.retonly_gadget: ROP_gadget_x86_64 = ROP_gadget_x86_64() 
        self.effects_to_gadgets: Dict[str, Dict[str, List[ROP_gadget_x86_64]]] = {ef_t: {reg: [] for reg in Platform.X86_64.SUPPORTED_REGS} for ef_t in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]}

    def find_gadgets(self):

        # dict to help identify gadget duplicates
        # helps identify gadgets that differ only by stack padding or ignored instructions
        opstr_to_gadgets: Dict[str, Tuple[ROP_gadget_x86_64, bool]] = {}
        # helps identify gadgets that are identical
        bytes_to_gadgets: Dict[str, Tuple[ROP_gadget_x86_64, bool]] = {}

        def _get_opstr(b_instr: bytes):

            opstr = ''
            
            for instr in self.capstone.disasm(b_instr, 0):

                if (instr.mnemonic in Platform.X86_64.IGNORED_INSTR_MNEMONICS) or (instr.mnemonic == "nop") \
                    or (instr.mnemonic == "add" and "rsp, 0x" in instr.op_str):
                    continue

                opstr += instr.mnemonic
                opstr += instr.op_str

            return opstr

        # auxiliary method to synchronize stack ids
        def _stack_id_sync(g: ROP_gadget_x86_64, eg: ROP_gadget_x86_64):
            
            s_g = g.stack.elements
            s_eg = eg.stack.elements

            i = 0
            j = 0
            while (i < len(s_g)) and (j < len(s_eg)):

                while (i < len(s_g)) and (s_g[i].type == "64b_stack_pad"):
                    i += 1

                while (j < len(s_eg)) and (s_eg[j].type == "64b_stack_pad"):
                    j += 1

                if i == len(s_g):
                    assert(j == len(s_eg))

                if (i < len(s_g)) and (j < len(s_eg)):

                    Stack_view.stack_values.pop(s_eg[j], None)
                    s_eg[j] = s_g[i]

                    i += 1
                    j += 1

                if i == len(s_g):
                    assert(j == len(s_eg))
        
        # initialize ret-only gadget
        self.retonly_gadget.stack.push(Structured_element.instantiate_structured_element("64b_stack_val"))
        self.retonly_gadget.stack.elements[0].info["id"] = Stack_view.get_elem_id()
        self.retonly_gadget.b = Platform.X86_64.RET_OPCODE
        
        # to check in constant time if the basse address
        # of a current gadget candidate actually steps over another ret
        ret_onlyoffsets = set(r[1] for r in self.ret_offsets)

        for xc_index, ret_offset in self.ret_offsets:

            self.retonly_gadget.add_current_addr(ret_offset)
            
            neg_offset = 1
            while (ret_offset - neg_offset > 0) and ((ret_offset - neg_offset) not in ret_onlyoffsets):
                
                b_vaddr = self.exec_bytes[xc_index][0]
                b_instr = self.exec_bytes[xc_index][1][ret_offset - neg_offset - b_vaddr: ret_offset - b_vaddr + 1]

                stop = False

                if b_instr in bytes_to_gadgets.keys():

                    if bytes_to_gadgets[b_instr][1] is True:
                        bytes_to_gadgets[b_instr][0].add_current_addr(ret_offset - neg_offset)

                else:

                    opstr = _get_opstr(b_instr)
                    if (opstr not in opstr_to_gadgets.keys()) or (opstr_to_gadgets[opstr][1] is True):
                        
                        disas_instr_generator = self.capstone.disasm(b_instr, ret_offset - neg_offset)
                        g, stop = self.create_gadget(disas_instr_generator, b_instr, ret_offset - neg_offset)

                        if (g is not None) and (len(g.effects) > 0):
                            
                            bytes_to_gadgets.update({b_instr: (g, True)})

                            if opstr in opstr_to_gadgets.keys():
                                opstr_to_gadgets[opstr][0].eq_g.append(g)

                            else:
                                opstr_to_gadgets.update({opstr: (g, True)})

                                for ef in g.effects:
                                    self.effects_to_gadgets[ef.type][ef.destination_element.info["reg_name"]].append(g)

                                self.gadgets.add(g)

                        else:
                            bytes_to_gadgets.update({b_instr: (None, False)})
                            opstr_to_gadgets.update({opstr: (None, False)})
                
                if stop is True:
                    break
                    
                neg_offset += 1

        # for each g, synchronize stack ids between g and gadgets from g.eq_g
        # so that stacks can be interchanged, having (at most) the padding size different
        for g in self.gadgets:
            for eg in g.eq_g:
                _stack_id_sync(g, eg)
  
        # from all eq_g per gadget, select the gadget with the smallest stack size
        # by swapping everything except the effects, which are identical
        # and then sort the eq_g gadgets
        for g in self.gadgets:
            for eg in g.eq_g:
                
                # assert(len(g.effects) == len(eg.effects))
                
                if eg.get_stack_size() < g.get_stack_size():

                    swap_aux = g.b
                    g.b = eg.b
                    eg.b = swap_aux

                    swap_aux = g.stack
                    g.stack = eg.stack
                    eg.stack = swap_aux

                    swap_aux = g.addrs
                    g.addrs = eg.addrs
                    eg.addrs = swap_aux

            g.eq_g.sort(key = lambda gadget: len(gadget.stack.elements))

        # sorting by used stack size
        for ef in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]:
            for reg in Platform.X86_64.SUPPORTED_REGS:
                self.effects_to_gadgets[ef][reg].sort(key = lambda g: len(g.stack.elements))

    # creates a graph for transitioning a value between registers
    # NOTE: it does NOT support register start values
    def get_trans_reg_graph(self):

        # dict to retain all gadgets for moving a value from a register to another
        trans_reg_graph: Dict[str, Dict[str, List[ROP_gadget_x86_64]]] = {dest: {src: [] for src in Platform.X86_64.SUPPORTED_REGS} for dest in Platform.X86_64.SUPPORTED_REGS}

        # whether there is a path from [reg_dest][reg_src] or not
        path_from: Dict[str, Dict[str, bool]] = {dest: {src: False for src in Platform.X86_64.SUPPORTED_REGS} for dest in Platform.X86_64.SUPPORTED_REGS}

        for dest in Platform.X86_64.SUPPORTED_REGS:
            for src in Platform.X86_64.SUPPORTED_REGS:

                if dest == src:
                    path_from[dest][src] = True
                    continue

                dest_from_src_ef = Effect.make_mov_rr_effect(dest, src)
                dest_from_src_gadgets = self.search_gadget(wanted_effect=dest_from_src_ef, max_stack_size=2 ** 63, 
                                                            reg_start_values=[], max_search_cnt=2 ** 63)

                if len(dest_from_src_gadgets) != 0:

                    trans_reg_graph[dest][src] = dest_from_src_gadgets
                    path_from[dest][src] = True

        # completing path_from (Roy-Warshal)
        for k in Platform.X86_64.SUPPORTED_REGS:
            for i in Platform.X86_64.SUPPORTED_REGS:
                for j in Platform.X86_64.SUPPORTED_REGS:

                    if (path_from[i][k] is True) and (path_from[k][j] is True):
                        path_from[i][j] = True

        return trans_reg_graph, path_from
    
    # auxiliary method that checks
    # whether any "subchain" was previously yielded or not
    @staticmethod
    def _check_if_duplicate(gs: List[ROP_gadget_x86_64 | ROP_chain_x86_64], b_cache: Dict[bytes, bool]):

        def _chunks(l: List[ROP_gadget_x86_64 | ROP_chain_x86_64]):
            
            if len(l) == 0:
                return

            if len(l) == 1:
                yield l[0].get_bytes() 
                return

            if len(l) == 2:
                yield l[0].get_bytes()
                yield l[1].get_bytes()
                return

            for i in range(1, len(l)):
                yield b''.join([g.get_bytes() for g in l[:i]])
            yield b''.join([g.get_bytes() for g in l[1:]])

            yield from _chunks(l[1:])

        for subchain_b in _chunks(gs):
            if (subchain_b in b_cache.keys()) and (b_cache[subchain_b] is True):
                return True

        return False

    # internal method for searching a gadget
    # receives the wanted Effect, max stack size, the fixed registers list (optional) and the register start values (optional)
    # it also receives a filter function as argument, to filter all found gadgets, by default it is the identity
    # NOTE: it is a FUNCTION, NOT a GENERATOR
    # NOTE: fixed registers may actually be used, as long as at the end of the gadget they contain their initial value
    # NOTE: the arguments are assumed to be valid
    # NOTE: max stack size is measured internally as the number of 64bit elements (max stack size in bytes // 8)
    def search_gadget(self, wanted_effect: Effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect] = [], max_search_cnt: int = 100) -> List[ROP_gadget_x86_64]:

        # as in duplicate method, represents a map 
        # between the original gadget stack ids and the new gadget stack ids
        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # a gadget can be referenced multiple times in the effects_to_gadgets dictionary
        # (when a gadget has multiple effects)
        # so, once a gadget has been checked, there is no need to check it twice
        tried_gadget_cache = set()

        # main function to try a gadget 
        def _try_gadget(candidate_g: ROP_gadget_x86_64, wanted_effect: Effect, searched_effect_types: List[str]):
            
            if candidate_g in tried_gadget_cache:
                return None

            if candidate_g.get_stack_size() > max_stack_size:

                tried_gadget_cache.add(candidate_g)
                return None
                
            # copies that can be manipulated without changing the original objects
            candidate_g_cpy, org_to_fstid = candidate_g.duplicate(copy_stack_associated_values=True)
            wanted_effect_cpy: Effect = deepcopy(wanted_effect)

            start_values_cpy = deepcopy(reg_start_values)
            candidate_g_cpy.effects = Effect.join_effects(start_values_cpy, candidate_g_cpy.effects)

            # every entry in effects_to_gadgets has a corresponding Effect
            # it is not kept in the dict, but can be found
            # by searching in the gadget's Effect list, by the reg_out name
            # NOTE: the type is not checked, because it can be changed by the simplifly calls from before
            #       and even if they did not, the check would be redundant (only one Effect with the corresponding reg_name as destination)
            candidate_effect = None
            for ef in candidate_g_cpy.effects:

                if ef.destination_element.info["reg_name"] == wanted_effect_cpy.destination_element.info["reg_name"]:
                    candidate_effect = ef
                    break

            if candidate_effect.type not in searched_effect_types:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            matched = wanted_effect_cpy.match(candidate_effect)
            if matched is False:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            is_fixed = candidate_g_cpy.check_fixed_regs(fixed_reg_list)
            if is_fixed is False:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            # gadget is accepted, a third copy is created from the original gadget
            # that is not simplified like the first gadget copy, 
            # but does contain all the additional stack ids and their associated value from the first gadget copy
            # then, the first temporary copy has its stack ids and other contents removed

            accepted_gadget, org_to_sndid = candidate_g.duplicate(copy_stack_associated_values=True)

            for org_stack_elem in candidate_g.stack.elements:
                if org_stack_elem.type == "64b_stack_val":

                    fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                    if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[fstid]:

                        if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                            raise RuntimeError("original gadget and cloned gadget non-null values are different")

                        sndid = _get_new_id(org_to_sndid, org_stack_elem.info["id"])
                        Stack_view.stack_values[sndid] = Stack_view.stack_values[fstid]

                    # else, the accepted_gadget already has the original value

            candidate_g_cpy.remove_stack_ids()

            tried_gadget_cache.add(candidate_g)
            return accepted_gadget

        # table of possible Effect types matching
        # there can be multiple searched effects because, given specific circumstances, some effects can change type
        # NOTE: LOAD_S is intentionally restricted to only other LOAD_S effects, for an efficient/ fast search
        #       if one wants to have all the possible ways of loading a value in a register, LOAD_CT matching should be chosen instead
        # LOAD_S -> LOAD_S
        # LOAD_CT -> LOAD_CT, LOAD_S (always false if max stack size == 0), ARITH
        # MOV_RR -> MOV_RR, ARITH
        # ARITH -> ARITH

        # searched Effect type filtering
        # is done in two places: here, less restrictive
        # and inside the try gadget function, more restrictive
        # this is because we still want the search to be optimised
        # but also we need to take into account that the reg start values
        # can change some Effect types into other types

        found_g: List[ROP_gadget_x86_64] = []
        searched_effect_types_snd: List[str] = []
        searched_effect_types_fst: List[str] = []

        if wanted_effect.type == "LOAD_S":

            searched_effect_types_snd.append("LOAD_S")

            searched_effect_types_fst.append("LOAD_S")

        elif wanted_effect.type == "LOAD_CT":

            searched_effect_types_snd.append("LOAD_S")
            searched_effect_types_snd.append("LOAD_CT")
            searched_effect_types_snd.append("ARITH")

            searched_effect_types_fst.append("LOAD_S")
            searched_effect_types_fst.append("LOAD_CT")
            searched_effect_types_fst.append("MOV_RR")
            searched_effect_types_fst.append("ARITH")

        elif wanted_effect.type == "MOV_RR":

            searched_effect_types_snd.append("MOV_RR")
            searched_effect_types_snd.append("ARITH")

            searched_effect_types_fst.append("MOV_RR")
            searched_effect_types_fst.append("ARITH")

        elif wanted_effect.type == "ARITH":

            searched_effect_types_snd.append("ARITH")
            
            searched_effect_types_fst.append("ARITH")
            searched_effect_types_fst.append("MOV_RR")

        for srch_t in searched_effect_types_fst:

            found_per_t_cnt = 0

            candidate_g: ROP_gadget_x86_64
            for candidate_g in self.effects_to_gadgets[srch_t][wanted_effect.destination_element.info["reg_name"]]:
                
                accepted_gadget = _try_gadget(candidate_g, wanted_effect, searched_effect_types_snd)
                if accepted_gadget is not None:

                    found_g.append(accepted_gadget)

                    found_per_t_cnt += 1
                    if found_per_t_cnt == max_search_cnt:
                        break
        
        found_g.sort(key = lambda g: g.get_stack_size())
        return found_g[:max_search_cnt]

    # main method of parsing instruction chunks and creating gadgets
    # here it is decided whether the gadget is valid / accepted / supported, what effects is has and so on
    # NOTE: addr parameter contains the default address, when ASLR/PIE is NOT enabled
    def create_gadget(self, instr_generator: Generator[CsInsn, None, None], b_instr: bytes, addr: int = None) -> Tuple[ROP_gadget_x86_64, bool]:
        
        # decide here whether to send signal to the caller procedure
        # so that it stops appending preffixes to the same "gadget"
        def _send_stop_flag():
            return len(b_instr) > ROP_gadget_x86_64.MAX_GADGET_BYTE_LEN

        def _gadget_end(instr: CsInsn):
            return (instr.mnemonic == "ret") and (len(instr.op_str) == 0)

        # first, each instruction is analysed semantically and translated in some effects
        # then, the effects will be cumulated from first to last instruction, to obtain the gadget
        effects_per_instruction: List[List[Effect]] = []

        is_ret = False
        for instr in instr_generator:

            if _gadget_end(instr) is True:
                is_ret = True       # check whether the gedget ends with "ret" or not
                break

            instr_effects = Effect.analyse_instr(instr)
            if instr_effects is None:
                return None, _send_stop_flag()

            effects_per_instruction.append(instr_effects)
        
        if is_ret is False:
            return None, _send_stop_flag()

        new_stack, new_effects = Effect.join_instr_effects(effects_per_instruction)

        candidate_gadget = ROP_gadget_x86_64()
        candidate_gadget.stack = new_stack
        candidate_gadget.effects = new_effects
        
        if candidate_gadget is None:
            return None, _send_stop_flag()

        candidate_gadget.add_current_addr(addr)
        candidate_gadget.b = b_instr

        return candidate_gadget, _send_stop_flag()

    # function that automatically finds a chain that satisfies the Effect R_dest <- R_src
    # based on max stack size and a trans graph
    # NOTE: inside this function, no other constraints or checks are implemented
    def transition_chain_generator(self, dest: str, src: str, trans_graph: Dict[str, Dict[str, List[ROP_gadget_x86_64]]], max_stack_size: int):

        # auxiliary data structure for the graph traversal
        _visited = set()

        # generator that returns a list of gadgets that compose the transfer path, and the accumulated stack size
        def _path_finder(current_reg: str, mss: int):

            _visited.add(current_reg)

            if current_reg == src:
                yield [], 0
                    
            else:

                for src_reg, gs in trans_graph[current_reg].items():
                    if (src_reg not in _visited) and (len(gs) > 0):

                        mss_reached = False

                        for path_suffix, stack_size in _path_finder(src_reg, mss - gs[0].get_stack_size()):
                
                            for trans_g in gs:
                                
                                tgss = trans_g.get_stack_size()

                                if tgss + stack_size <= mss:
                                    yield [trans_g] + path_suffix, tgss + stack_size
                                else:
                                    mss_reached = True
                                    break
                            
                            # FIXME remove this if?
                            #       its assumption is wrong,
                            #       not sure if it affects the results by much, tho
                            if mss_reached is True:
                                break
                    
            _visited.remove(current_reg)

        return _path_finder(dest, max_stack_size)

    # method responsible for automatically constructing rop chains
    # for only one wanted Effect
    # based on gadgets from effects_to_gadgets dict
    # and on the different methods implemented
    # NOTE: based on different searching methods called, reg start values might be ignored
    def _search_chain(self, wanted_effect: Effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect] = [], only_gadgets = False) -> List[ROP_chain_x86_64]:

        if max_stack_size < 0:
            return

        # every sequence of bytes is analysed exactly once
        # also, if a chain is yielded, 
        # then no chain with this current chain as a "subchain" will be analysed 
        # (this mechanism avoids chains that satisfy the wanted Effect, but have junk preffixes / suffixes)
        b_cache: Dict[bytes, bool] = {}

        yield from self._search_gadgets(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                    reg_start_values=reg_start_values, b_cache=b_cache)

        if only_gadgets is False:
        
            if wanted_effect.type == "LOAD_CT":

                yield from self._search_chain_by_substitution(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list, 
                                                                reg_start_values=reg_start_values, b_cache=b_cache)

                yield from self._search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=reg_start_values, b_cache=b_cache)

            elif wanted_effect.type == "ARITH":

                yield from self._search_chain_by_substitution(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list, 
                                                                reg_start_values=reg_start_values, b_cache=b_cache)
                
                yield from self._search_chain_by_substitution_adv(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list, 
                                                                    reg_start_values=reg_start_values, b_cache=b_cache)

                yield from self._search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=reg_start_values, b_cache=b_cache)

            elif wanted_effect.type == "MOV_RR":

                yield from self._search_mov_chains(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                                    reg_start_values=reg_start_values, b_cache=b_cache)

                yield from self._search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=reg_start_values, b_cache=b_cache)

            else:
                raise RuntimeError(f"Unrecognised wanted Effect type when searching chains: {wanted_effect.type}")
    
    # search chains with multiple wanted effects
    def search_chain(self, wanted_effects: List[Effect], max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect] = [], only_gadgets = False) -> List[ROP_chain_x86_64]:
            
        b_cache: Dict[bytes, bool] = {}
        def _get_bytes(chs: List[ROP_chain_x86_64]):

            b_repr = b''
            for ch in chs:
                b_repr += ch.get_bytes()

            return b_repr

        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        r_to_wef: Dict[str, Effect] = {}

        def _map_r_to_wef():

            for wef in wanted_effects:
                
                r = wef.destination_element.info["reg_name"]

                if r in r_to_wef.keys():
                    raise RuntimeError("same destination register found in more than one wanted Effect")

                r_to_wef.update({r: wef})

        r_to_gen: Dict[str, Generator] = {}
        r_to_startgen: Dict[str, Generator] = {}

        r_gen_mss: Dict[str, List[int]] = {}
        r_startgen_mss: Dict[str, List[int]] = {}

        def _update_generator(r: str, start: bool):

            wef = r_to_wef[r]

            if start is True:

                if len(r_startgen_mss[r]) == 0:
                    return False

                mss = r_startgen_mss[r][0]
                r_startgen_mss[r] = r_startgen_mss[r][1:]

                r_to_startgen.update({r: self._search_chain(wanted_effect = wef, max_stack_size = mss, fixed_reg_list = fixed_reg_list,
                                                            reg_start_values = reg_start_values, only_gadgets = False)})
            else:

                if len(r_gen_mss[r]) == 0:
                    return False

                mss = r_gen_mss[r][0]
                r_gen_mss[r] = r_gen_mss[r][1:]

                r_to_gen.update({r: self._search_chain(wanted_effect = wef, max_stack_size = mss, fixed_reg_list = fixed_reg_list,
                                                            reg_start_values = [], only_gadgets = False)})

            return True

        chs: List[Tuple[ROP_chain_x86_64, Set[str], Set[str]]] = []
        startchs: List[Tuple[ROP_chain_x86_64, Set[str], Set[str]]] = []

        # cache of bytes of generated chains
        ch_b_cache: Set[bytes] = set()
        startch_b_cache: Set[bytes] = set()

        def _generate_chs(qty: int):
            
            def _get_v_i(ch: ROP_chain_x86_64, r: str):

                validate = {r}
                invalidate = set()

                for r_, wef_ in r_to_wef.items():
                    if r_ != r:
                        
                        wef_cpy = deepcopy(wef_)
                        ch_cpy, ch_to_chcpy_ids = ch.duplicate(copy_stack_associated_values = True)

                        to_match_ef: Effect = None
                        for ef in ch_cpy.effects:

                            if ef.destination_element.info["reg_name"] == r_:
                                to_match_ef = ef
                                break

                        if to_match_ef is None:
                            continue

                        if wef_cpy.match(to_match_ef) is False:
                            ch_cpy.remove_stack_ids()
                            invalidate.add(r_)
                            continue

                        for org_stack_elem in ch.stack.elements:
                            if org_stack_elem.type == "64b_stack_val":

                                cpyid = _get_new_id(ch_to_chcpy_ids, org_stack_elem.info["id"])
                                if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[cpyid]:

                                    if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                        raise RuntimeError("original chain and cloned chain non-null values are different")

                                    Stack_view.stack_values[org_stack_elem.info["id"]] = Stack_view.stack_values[cpyid]

                        ch_cpy.remove_stack_ids()
                        validate.add(r_)

                return validate, invalidate

            total_gen = 0

            for r, _ in r_to_wef.items():
                
                gen = r_to_gen[r]
                
                _gen_cnt = 0
                while _gen_cnt < qty:
                    
                    ch: ROP_chain_x86_64
                    for ch in gen:

                        b = ch.get_bytes()
                        if b in ch_b_cache:
                            continue

                        ch_b_cache.add(b)

                        validate, invalidate = _get_v_i(ch, r)
                        chs.append((ch, validate, invalidate))

                        _gen_cnt += 1
                        if _gen_cnt == qty:
                            break

                    if _gen_cnt < qty:

                        success = _update_generator(r, False)
                        if success is False:
                            break

                startgen = r_to_startgen[r]

                _startgen_cnt = 0
                while _startgen_cnt < qty:
                    
                    ch: ROP_chain_x86_64
                    for ch in startgen:

                        b = ch.get_bytes()
                        if b in startch_b_cache:
                            continue

                        startch_b_cache.add(b)

                        validate, invalidate = _get_v_i(ch, r)
                        startchs.append((ch, validate, invalidate))

                        _startgen_cnt += 1
                        if _startgen_cnt == qty:
                            break

                    if _startgen_cnt < qty:

                        success = _update_generator(r, False)
                        if success is False:
                            break    

                    total_gen += _startgen_cnt + _gen_cnt

            if total_gen == 0:
                return False            

            return True
                
        # cache of a state (mv + ci)
        state_cache: Dict[str, int] = {}

        def _get_state_str(mv: Set[str], ci: Set[str]):

            mvl = [s for s in mv]
            cil = [s for s in ci]
            mvl.sort()
            cil.sort()

            return f"{''.join(mvl)}|{''.join(cil)}"

        def _path_search(mv: Set[str], ci: Set[str], mss: int, start: bool):

            if len(mv) == 0:
                yield [], 0
                return
            
            _chs = chs
            if start is True:
                _chs = startchs
            
            # append chains that satisfy a wanted Effect from mv
            for ch, validate, invalidate in _chs:
                
                # stack size
                ch_ss = ch.get_stack_size()
                if ch_ss > mss:
                    continue
                
                # ci inclusion
                if invalidate.issubset(ci) is False:
                    continue

                # usefullness
                m0 = validate.difference(mv)
                m1 = validate.intersection(mv)

                if len(m1) == 0:
                    continue

                new_mv = mv.difference(m1)
                new_ci = ci.difference(invalidate).union(m0)

                # already visited
                state_str = _get_state_str(new_mv, new_ci)
                if (state_str in state_cache.keys()) and (state_cache[state_str] >= mss):
                    continue

                if state_str in state_cache.keys():
                    state_cache[state_str] = mss
                else:
                    state_cache.update({state_str: mss})

                for suf, stack_size in _path_search(new_mv, new_ci, mss - ch_ss, False):
                    yield [ch] + suf, stack_size + ch_ss

            # append chains that "guard" some wanted effects
            for ch, validate, invalidate in _chs:
                
                # stack size
                ch_ss = ch.get_stack_size()
                if ch_ss > mss:
                    continue
                
                # ci inclusion
                if invalidate.issubset(ci) is False:
                    continue

                # usefullness
                m0 = validate.difference(mv)
                m1 = validate.intersection(mv)

                if len(m0) == 0:
                    continue

                new_mv = mv.difference(m1)
                new_ci = ci.difference(invalidate).union(m0)

                # already visited
                state_str = _get_state_str(new_mv, new_ci)
                if (state_str in state_cache.keys()) and (state_cache[state_str] >= mss):
                    continue

                if state_str in state_cache.keys():
                    state_cache[state_str] = mss
                else:
                    state_cache.update({state_str: mss})

                for suf, stack_size in _path_search(new_mv, new_ci, mss - ch_ss, False):
                    yield [ch] + suf, stack_size + ch_ss

        if len(wanted_effects) == 1:

            yield from self._search_chain(wanted_effect = wanted_effects[0], max_stack_size = max_stack_size, fixed_reg_list = fixed_reg_list,
                                            reg_start_values = reg_start_values, only_gadgets = only_gadgets)

        elif only_gadgets is True:

            for g in self._search_gadgets(wanted_effect = wanted_effects[0], max_stack_size = max_stack_size, fixed_reg_list = fixed_reg_list,
                                            reg_start_values = reg_start_values, b_cache = b_cache):

                g_cpy, org_to_cpyid = g.duplicate()
                start_values_cpy = deepcopy(reg_start_values)
                g_cpy.effects = Effect.join_effects(start_values_cpy, g_cpy.effects)

                wef_sat = True
                for wef in wanted_effects[1:]:

                    wef_cpy = deepcopy(wef)

                    to_check_effect: Effect = None
                    for ef in g_cpy.effects:

                        if ef.destination_element.info["reg_name"] == wef_cpy.destination_element.info["reg_name"]:
                            to_check_effect = ef
                            break
                    
                    if to_check_effect is None:
                        wef_sat = False
                        break

                    if wef_cpy.match(to_check_effect) is False:
                        wef_sat = False
                        break

                    if g_cpy.check_fixed_regs(fixed_reg_list) is False:
                        wef_sat = False
                        break

                if wef_sat is False:
                    g_cpy.remove_stack_ids()
                    continue

                for org_stack_elem in g.stack.elements:
                    if org_stack_elem.type == "64b_stack_val":

                        cpyid = _get_new_id(org_to_cpyid, org_stack_elem.info["id"])
                        if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[cpyid]:

                            if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                raise RuntimeError("original chain and cloned chain non-null values are different")

                            Stack_view.stack_values[org_stack_elem.info["id"]] == Stack_view.stack_values[cpyid]

                g_cpy.remove_stack_ids()

                yield g

        else:

            _map_r_to_wef()

            r_gen_mss: Dict[str, List[int]] = {r: [max_stack_size / len(wanted_effects), max_stack_size] for r in r_to_wef.keys()}
            r_startgen_mss: Dict[str, List[int]] = {r: [max_stack_size / len(wanted_effects), max_stack_size] for r in r_to_wef.keys()}

            for r, _ in r_to_wef.items():
                _update_generator(r, False)
                _update_generator(r, True)

            try:

                qty_gen = 1
                while True:
                    
                    success = _generate_chs(qty_gen)
                    if success is False:
                        break

                    path: List[ROP_chain_x86_64]
                    for path, stack_size in _path_search(mv = {r for r in r_to_wef.keys()}, ci = set(), mss = max_stack_size, start = True):
                        
                        if stack_size > max_stack_size:
                            raise RuntimeError("max stack size constraint violated")
                        
                        b = _get_bytes(path)
                        if b in b_cache.keys():
                            continue

                        b_cache.update({b: False})

                        if ROP_searcher_x86_64._check_if_duplicate(path, b_cache) is True:
                            continue

                        acc_ch, _ = path[-1].duplicate()
                        for ch in path[-2::-1]:

                            ch_aux = acc_ch.join(ch)
                            acc_ch.remove_stack_ids()
                            acc_ch = ch_aux

                        b_cache[b] = True
                        yield acc_ch

                    qty_gen *= 2

            finally:
                
                ch: ROP_chain_x86_64
                for ch, _, _ in chs:
                    ch.remove_stack_ids()

                for ch, _, _ in startchs:
                    ch.remove_stack_ids()

    # internal method that searches by bruteforce
    # has a maximum chain length parameter
    # and it is limited to chains of 4 gadgets long
    # besides search cache, only one filtering condition: 
    #       * at least a gadget from the chain must have the destination register the destination reg of the wanted Effect
    # NOTE: extremely slow
    # NOTE: to disable bruteforce search, set the self.BRUTEFORCE_DEPTH to less than 1
    def _search_by_bruteforce(self, wanted_effect: Effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                                reg_start_values: List[Effect] = [], b_cache: Dict[bytes, bool] = {}):

        max_g_cnt = self.BRUTEFORCE_DEPTH
        if max_g_cnt > 4:
            raise RuntimeError(f"Cannot search chains by bruteforce for depth {max_g_cnt} - max allowed is 6")

        if max_g_cnt < 1:
            return

        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # function that creates a rop chain
        # from a copy of a given gadget input,
        # and taking into account reg start values 
        def _prepare(g: ROP_gadget_x86_64) -> ROP_chain_x86_64:

            cpy_g, _ = g.duplicate()
            return ROP_chain_x86_64.convert(cpy_g)

        # all the gadgets converted to atomic chains
        base_gs: List[ROP_chain_x86_64] = [_prepare(g) for g in self.gadgets]

        # yields all different arrangements of gadgets of length k
        def _get_paths(k: int):
            
            if k == 0:
                yield [], 0

            else:
                for suf, stack_size in _get_paths(k - 1):
                    for g in base_gs:
                        yield [g] + suf, stack_size + g.get_stack_size()

        try:

            for l in range(max_g_cnt):
                for path, stack_size in _get_paths(l + 1):

                    if stack_size > max_stack_size:
                        continue    

                    if ROP_searcher_x86_64._check_if_duplicate(path, b_cache) is True:
                        continue

                    candidate_ch: ROP_chain_x86_64 = path[-1].duplicate()[0]
                    for g in path[-2::-1]:

                        candidate_ch_aux = candidate_ch.join(g)
                        candidate_ch.remove_stack_ids()
                        candidate_ch = candidate_ch_aux

                    b = candidate_ch.get_bytes()
                    if b in b_cache.keys():
                        candidate_ch.remove_stack_ids()
                        continue

                    b_cache.update({b: False})

                    wef_dest_reg_found = False

                    g: ROP_gadget_x86_64
                    for g in path:
                        for ef in g.effects:
                            if ef.destination_element.info["reg_name"] == wanted_effect.destination_element.info["reg_name"]:
                                wef_dest_reg_found = True

                    if wef_dest_reg_found is False:
                        continue

                    candidate_ch_aux, org_to_fstid = candidate_ch.duplicate()
                    wanted_effect_cpy = deepcopy(wanted_effect)

                    start_values_cpy = deepcopy(reg_start_values)
                    candidate_ch_aux.effects = Effect.join_effects(start_values_cpy, candidate_ch_aux.effects)

                    to_check_effect: Effect = None
                    for ef in candidate_ch_aux.effects:
                        if ef.destination_element.info["reg_name"] == wanted_effect_cpy.destination_element.info["reg_name"]:
                            to_check_effect = ef
                            break

                    if to_check_effect is None:
                        candidate_ch_aux.remove_stack_ids()
                        candidate_ch.remove_stack_ids()
                        continue

                    if wanted_effect_cpy.match(to_check_effect) is False:
                        candidate_ch_aux.remove_stack_ids()
                        candidate_ch.remove_stack_ids()
                        continue

                    if candidate_ch_aux.check_fixed_regs(fixed_reg_list) is False:
                        candidate_ch_aux.remove_stack_ids()
                        candidate_ch.remove_stack_ids()
                        continue

                    for org_stack_elem in candidate_ch.stack.elements:
                        if org_stack_elem.type == "64b_stack_val":

                            fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                            if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[fstid]:

                                if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                    raise RuntimeError("original chain and cloned chain non-null values are different")

                                Stack_view.stack_values[org_stack_elem.info["id"]] = Stack_view.stack_values[fstid]

                    candidate_ch_aux.remove_stack_ids()

                    b_cache[b] = True
                    yield candidate_ch
        
        finally:

            for ch in base_gs:
                ch.remove_stack_ids()

    # internal method that searches only gadgets, 
    # and converts the results into ROP_chain_x86_64 objects
    def _search_gadgets(self, wanted_effect: Effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect] = [], b_cache: Dict[bytes, bool] = {}):

        gadgets = self.search_gadget(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                            reg_start_values=reg_start_values, max_search_cnt=2 ** 63)

        for g in gadgets:
            
            b = g.get_bytes()
            if b not in b_cache.keys():

                b_cache.update({b: True})
                yield ROP_chain_x86_64.convert(g)

    # internal method that searches rop chains for MOV_RR type Effect
    # resembles the _search_chain_by_substitution
    def _search_mov_chains(self, wanted_effect: Effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [],
                            reg_start_values: List[Effect] = [], b_cache: Dict[bytes, bool] = {}):

        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None
        
        trans_graph, _ = self.get_trans_reg_graph()

        dest = wanted_effect.destination_element.info["reg_name"]
        src = wanted_effect.params[0].info["reg_name"]

        try:
 
            for path, _ in self.transition_chain_generator(dest, src, trans_graph, max_stack_size):
                
                if len(path) == 0:
                    continue

                if ROP_searcher_x86_64._check_if_duplicate(path, b_cache) is True:
                    continue

                candidate_ch = ROP_chain_x86_64.convert(path[-1].duplicate()[0])
                for g in path[-2::-1]:

                    candidate_ch_aux = candidate_ch.join(g)
                    candidate_ch.remove_stack_ids()
                    candidate_ch = candidate_ch_aux

                b = candidate_ch.get_bytes()
                if b in b_cache.keys():
                    candidate_ch.remove_stack_ids()
                    continue

                b_cache.update({b: False})

                candidate_ch_cpy, org_to_fstid = candidate_ch.duplicate()

                start_values_cpy = deepcopy(reg_start_values)
                candidate_ch_cpy.effects = Effect.join_effects(start_values_cpy, candidate_ch_cpy.effects)

                # because of start values, the wanted Effect needs to be checked 
                wanted_effect_cpy = deepcopy(wanted_effect)

                to_check_ef: Effect = None
                for ef in candidate_ch_cpy.effects:
                    
                    if ef.destination_element.info["reg_name"] == dest:
                        to_check_ef = ef
                        break

                if (to_check_ef is None) or (wanted_effect_cpy.match(to_check_ef) is False):
                    candidate_ch_cpy.remove_stack_ids()
                    candidate_ch.remove_stack_ids()
                    continue

                if candidate_ch_cpy.check_fixed_regs(fixed_reg_list) is False:
                    candidate_ch_cpy.remove_stack_ids()
                    candidate_ch.remove_stack_ids()
                    continue

                for org_stack_elem in candidate_ch.stack.elements:
                    if org_stack_elem.type == "64b_stack_val":

                        fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                        if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[fstid]:

                            if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                raise RuntimeError("original chain and cloned chain non-null values are different")

                            Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[fstid]

                candidate_ch_cpy.remove_stack_ids()

                b_cache[b] = True
                yield candidate_ch

        finally:
                
            for _, d in trans_graph.items():
                for _, gs in d.items():
                    if gs is not None:
                        for g in gs:
                            g.remove_stack_ids()

    # internal method responsible for automatically constructing rop chains
    # it searches gadgets based on substituting register operands
    # and then joining the Effect-satisfying gadgets with the transition gadgets
    def _search_chain_by_substitution(self, wanted_effect: Effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                                        reg_start_values: List[Effect] = [], b_cache: Dict[bytes, bool] = {}):

        if wanted_effect.type not in ["ARITH", "LOAD_CT"]:
            raise RuntimeError(f"tyring to search chain inside _search_chain_by_substitution for wanted Effect type {wanted_effect.type}")

        # graph as a list(dict) of neighbours, and the path existence matrix
        trans_graph, path_from = self.get_trans_reg_graph()

        # auxiliary method
        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # returns a list of all reg_in used, and the reg_out,
        # for an ARITH / LOAD_CT Effect
        def _find_used_regs(ef: Effect) -> Tuple[List[str], str]:

            def _rec_find(el: Structured_element):
                
                if el is None:
                    return []

                if el.type == "reg_in":
                    return [el.info["reg_name"]]

                if el.is_op():
                    return _rec_find(el.info["term_1"]) + _rec_find(el.info["term_2"])

                if el.type == "64b_stack_val":
                    raise RuntimeError("wanted Effect contains stack elements")

                return []

            if ef.type == "LOAD_CT":
                return [], ef.destination_element.info["reg_name"]

            elif ef.type == "ARITH":
                
                found = _rec_find(ef.params[0])

                to_return = []
                for r in found:
                    if r not in to_return:
                        to_return.append(r)

                return to_return, ef.destination_element.info["reg_name"]

        # generator that computes all the possible 
        # value transitions for the given registers, according to trans graph
        # (including identity replacements)
        # NOTE: a reg from regs_to_replace is a fixed source, and the outputs contain all possible destinations
        # NOTE: it assumes there is no stack element
        def _replace_seq_gen(regs_to_replace: List[str]):
            
            if len(regs_to_replace) == 0:
                yield []

            else:
                current_reg = regs_to_replace[0]
                for suffix in _replace_seq_gen(regs_to_replace[1:]):
                    
                    for dest in path_from.keys():
                        if (path_from[dest][current_reg] is True) and (dest not in suffix):

                            yield [dest] + suffix

        # generator that returns all nodes that can reach dest_reg
        # NOTE: the dest_reg is a fixed destination, and the results contain all possible sources
        def _replace_dest_reg(dest_reg: str):
            
            for src, is_path in path_from[dest_reg].items():
                if is_path is True:
                    yield src

        # creates a new copy of the given Effect,
        # and replaces all reg_in elements and, separately, the destination register
        # NOTE: it assumes there is no stack element
        def _apply_substitutions(ef: Effect, regs_to_replace: List[str], replacements: List[str], dest_reg_replacement: str):
            
            def _rec_subst(el: Structured_element):

                if el is None:
                    return None

                if el.type == "reg_in":
                    el.info["reg_name"] = replacements[regs_to_replace.index(el.info["reg_name"])]

                elif el.is_op():
                    _rec_subst(el.info["term_1"])
                    _rec_subst(el.info["term_2"])

                elif el.type == "64b_stack_val":
                    raise RuntimeError("wanted Effect contains stack elements")

            subst_ef = deepcopy(ef)
            subst_ef.destination_element.info["reg_name"] = dest_reg_replacement

            if subst_ef.type == "ARITH":
                _rec_subst(subst_ef.params[0])

            return subst_ef

        # replace every Rk[i] with the corresponding Rx[i]
        # the rx should be part of the result yielded by replace seq gen called on rk
        # mss - max stack size
        def _genpath(rk: List[str], rx: List[str], mss: int):

            def _perm(n, k):

                if k == 0:
                    yield []

                else:
                    for suf in _perm(n, k - 1):
                        for i in range(n):
                            if i not in suf:
                                yield [i] + suf

            def _internal_genpath(_rk, _rx, _mss):

                if len(_rk) == 0:
                    yield [], 0

                else:
                    rk_current = _rk[0]
                    rx_current = _rx[0]

                    for trans_gs, stack_size in self.transition_chain_generator(rx_current, rk_current, trans_graph, _mss):
                        for suffix, suf_stack_size in _internal_genpath(_rk[1:], _rx[1:], _mss - stack_size):

                            yield trans_gs + suffix, suf_stack_size + stack_size

            for p in _perm(len(rk), len(rk)):

                shuffled_rk = [rk[i] for i in p]
                shuffled_rx = [rx[i] for i in p]

                for path, stack_size in _internal_genpath(shuffled_rk, shuffled_rx, mss):
                    yield path, stack_size

        try:

            wef_used_regs, dest_reg = _find_used_regs(wanted_effect)

            for repl_seq in _replace_seq_gen(wef_used_regs):
                for repl_dest_reg in _replace_dest_reg(dest_reg):
                    
                    wef_subst = _apply_substitutions(wanted_effect, regs_to_replace=wef_used_regs, 
                                                        replacements=repl_seq, dest_reg_replacement=repl_dest_reg)

                    gs = self.search_gadget(wef_subst, max_stack_size=max_stack_size, fixed_reg_list=[],
                                            reg_start_values=[], max_search_cnt=2 ** 63)

                    if len(gs) == 0:
                        continue

                    try:

                        # for each gadget that satisfies wanted Effect with substitutions
                        #   for each way to move the result from intermediary dest reg to the real dest reg
                        #       for each way to replace all the reg_in elements
                        for wef_g in gs:

                            mss_aux1 = max_stack_size - wef_g.get_stack_size()
                            for repl_dest_path, ss_1 in self.transition_chain_generator(dest_reg, repl_dest_reg, trans_graph, mss_aux1):
                                
                                mss_aux2 = mss_aux1 - ss_1
                                if mss_aux2 < 0:
                                    raise RuntimeError(f"stack size bigger than mss in genpath: {mss_aux1}, max {ss_1}")

                                for path, ss_2 in _genpath(wef_used_regs, repl_seq, mss_aux2):

                                    if ss_2 > mss_aux2:
                                        raise RuntimeError(f"stack size bigger than mss in genpath: {ss_2}, max {mss_aux2}")

                                    # join from the end to the beginning: repl_dest_path, g, path
                                    final_path: List[ROP_gadget_x86_64]
                                    final_path = repl_dest_path + [wef_g] + path

                                    if ROP_searcher_x86_64._check_if_duplicate(path, b_cache) is True:
                                        continue

                                    candidate_ch = ROP_chain_x86_64.convert(final_path[-1].duplicate()[0])
                                    for g_aux in final_path[-2::-1]:
                    
                                        candidate_ch_aux = candidate_ch.join(g_aux)
                                        candidate_ch.remove_stack_ids()
                                        candidate_ch = candidate_ch_aux
                                
                                    if candidate_ch.get_stack_size() != ss_1 + ss_2 + wef_g.get_stack_size():
                                        raise RuntimeError(f"stack size inconsistent: expected {ss_1 + ss_2 + wef_g.get_stack_size()}, got {candidate_ch.get_stack_size()}")

                                    b = candidate_ch.get_bytes()
                                    if b in b_cache.keys():
                                        candidate_ch.remove_stack_ids()
                                        continue
                                    
                                    b_cache.update({b: False})

                                    # check if the obtained result really matches the wanted Effect
                                    # (check is needed because the transition paths' side effects are not taken into account when searching)

                                    # also, the start values are plugged in
                                    candidate_ch_cpy, org_to_fstid = candidate_ch.duplicate()

                                    start_values_cpy = deepcopy(reg_start_values)
                                    candidate_ch_cpy.effects = Effect.join_effects(start_values_cpy, candidate_ch_cpy.effects)

                                    to_check_effect: Effect = None
                                    for ef in candidate_ch_cpy.effects:

                                        if ef.destination_element.info["reg_name"] == dest_reg:
                                            to_check_effect = ef
                                            break
                                    
                                    if to_check_effect is None:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    wanted_effect_cpy = deepcopy(wanted_effect)

                                    if wanted_effect_cpy.match(to_check_effect) is False:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    if candidate_ch_cpy.check_fixed_regs(fixed_reg_list) is False:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    # match arith might have changed some stack values
                                    accepted_chain, org_to_sndid = candidate_ch.duplicate(copy_stack_associated_values=True)

                                    for org_stack_elem in candidate_ch.stack.elements:
                                        if org_stack_elem.type == "64b_stack_val":

                                            fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                                            if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[fstid]:

                                                if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                                    raise RuntimeError("original chain and cloned chain non-null values are different")

                                                sndid = _get_new_id(org_to_sndid, org_stack_elem.info["id"])
                                                Stack_view.stack_values[sndid] = Stack_view.stack_values[fstid]

                                    candidate_ch_cpy.remove_stack_ids()
                                    candidate_ch.remove_stack_ids()

                                    b_cache[b] = True
                                    yield accepted_chain

                    finally:

                        g: ROP_gadget_x86_64
                        for g in gs:
                            g.remove_stack_ids()
        
        finally:

            # clean up unused stack ids
            for _, d in trans_graph.items():
                for _, gs in d.items():
                    if gs is not None:
                        for g in gs:
                            g.remove_stack_ids()
    
    # exactly like the above method
    # but also tries to substitute constants
    def _search_chain_by_substitution_adv(self, wanted_effect: Effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                                        reg_start_values: List[Effect] = [], b_cache: Dict[bytes, bool] = {}):

        if wanted_effect.type not in ["ARITH", "LOAD_CT"]:
            raise RuntimeError(f"tyring to search chain inside _search_chain_by_substitution for wanted Effect type {wanted_effect.type}")

        # graph as a list(dict) of neighbours, and the path existence matrix
        trans_graph, path_from = self.get_trans_reg_graph()

        # gadget {Ri: {CTj: [gk, ...]}, ...} that stores gadgets of type gk: Ri <- CTj
        # almost the same as ROP_searcher_x86_64.effects_to_gadgets
        load_ct_gadgets_cache: Dict[str, Dict[int, List[ROP_gadget_x86_64]]] = {r: {} for r in Platform.X86_64.SUPPORTED_REGS}

        # auxiliary method that helps with substituting constants
        def _init_ct_g_cache():

            for r in Platform.X86_64.SUPPORTED_REGS:
                for g in self.effects_to_gadgets["LOAD_CT"][r]:
                    
                    for ef in g.effects:
                        if ef.destination_element.info["reg_name"] == r:

                            ct = ef.params[0].info["value"]

                            if ct in load_ct_gadgets_cache[r].keys():
                                load_ct_gadgets_cache[r][ct].append(g)
                            else:
                                load_ct_gadgets_cache[r].update({ct: [g]})

        # auxiliary method
        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # returns a list of all reg_in and constants used, and the reg_out
        # the registers or constants that can(will) be substituted in this function
        # are simply called symbols 
        def _find_subst_symbols(ef: Effect) -> Tuple[List[str | int], str]:

            def _rec_find(el: Structured_element):
                
                if el is None:
                    return []

                if el.type == "reg_in":
                    return [el.info["reg_name"]]

                if el.type == "ct_val":
                    return [el.info["value"]]

                if el.is_op():
                    return _rec_find(el.info["term_1"]) + _rec_find(el.info["term_2"])

                if el.type == "64b_stack_val":
                    raise RuntimeError("wanted Effect contains stack elements")

                return []

            if ef.type == "LOAD_CT":
                return [], ef.destination_element.info["reg_name"]

            elif ef.type == "ARITH":
                
                found = _rec_find(ef.params[0])
                
                to_return = []
                for sym in found:
                    if sym not in to_return:
                        to_return.append(sym)

                return to_return, ef.destination_element.info["reg_name"]

        # generator that computes all the possible 
        # value transitions for the given registers, according to trans graph
        # and all possible constant substitution with registers, also according to trans graph
        # but also according to load_ct_gadgets_cache
        # it includes identity replacements, both for registers and constants (the case a constant is NOT replaced is marked with None)
        # NOTE: a reg from syms_to_replace is a fixed source, and the outputs contain all possible destinations
        # NOTE: it assumes there is no stack element
        def _replace_seq_gen(syms_to_replace: List[str | int]):
            
            if len(syms_to_replace) == 0:
                yield []

            else:
                current_sym = syms_to_replace[0]
                for suffix in _replace_seq_gen(syms_to_replace[1:]):
                    
                    # it is a register to be substituted
                    if current_sym in Platform.X86_64.SUPPORTED_REGS:
                    
                        for dest in path_from.keys():
                            if (path_from[dest][current_sym] is True) and (dest not in suffix):

                                yield [dest] + suffix

                    # it is a constant to be substituted
                    else:
                        
                        # base case when the constant is NOT replaced
                        yield [None] + suffix
                        
                        for r, gs_dict in load_ct_gadgets_cache.items():
                            if current_sym in gs_dict.keys():
                                
                                for r_ in Platform.X86_64.SUPPORTED_REGS:
                                    if (path_from[r_][r] is True) and (r_ not in suffix):

                                        yield [(r_, r)] + suffix

        # generator that returns all nodes that can reach dest_reg
        # NOTE: the dest_reg is a fixed destination, and the results contain all possible sources
        def _replace_dest_reg(dest_reg: str):
            
            for src, is_path in path_from[dest_reg].items():
                if is_path is True:
                    yield src

        # creates a new copy of the given Effect,
        # and replaces all reg_in elements and constants, and, separately, the destination register
        # NOTE: it assumes there is no stack element
        def _apply_substitutions(ef: Effect, syms_to_replace: List[str | int], replacements: List[str | None | Tuple[str, str]], dest_reg_replacement: str):
            
            def _rec_subst(el: Structured_element):

                if el is None:
                    return None

                if el.type == "reg_in":
                    el.info["reg_name"] = replacements[syms_to_replace.index(el.info["reg_name"])]

                elif el.type == "ct_val":
                    
                    subst = replacements[syms_to_replace.index(el.info["value"])]
                    if subst is not None:

                        el.type = "reg_in"
                        el.info = {"reg_name": subst[0]}

                elif el.is_op():
                    _rec_subst(el.info["term_1"])
                    _rec_subst(el.info["term_2"])

                elif el.type == "64b_stack_val":
                    raise RuntimeError("wanted Effect contains stack elements")

            subst_ef = deepcopy(ef)
            subst_ef.destination_element.info["reg_name"] = dest_reg_replacement

            if subst_ef.type == "ARITH":
                _rec_subst(subst_ef.params[0])

            return subst_ef

        # replace every Rk[i] with the corresponding Rx[i]
        # the rx should be part of the result yielded by replace seq gen called on rk
        # mss - max stack size
        def _genpath(rk: List[str | int], rx: List[str | None | Tuple[str, str]], mss: int):

            def _perm(n, k):

                if k == 0:
                    yield []

                else:
                    for suf in _perm(n, k - 1):
                        for i in range(n):
                            if i not in suf:
                                yield [i] + suf

            def _internal_genpath(_rk, _rx, _mss):

                if _mss < 1:
                    return

                if len(_rk) == 0:
                    yield [], 0

                else:

                    rk_current = _rk[0]
                    rx_current = _rx[0]

                    # Rx <- Rk register substitution
                    if rk_current in Platform.X86_64.SUPPORTED_REGS:

                        for trans_gs, stack_size in self.transition_chain_generator(rx_current, rk_current, trans_graph, _mss):
                            for suffix, suf_stack_size in _internal_genpath(_rk[1:], _rx[1:], _mss - stack_size):

                                yield trans_gs + suffix, suf_stack_size + stack_size

                    # Rx <- CT constant to register substitution
                    elif rx_current is not None:

                        subst_reg, loadct_reg = rx_current

                        for trans_gs, stack_size in self.transition_chain_generator(subst_reg, loadct_reg, trans_graph, _mss):
                            for loadct_g in load_ct_gadgets_cache[loadct_reg][rk_current]:

                                loadct_g_ss = loadct_g.get_stack_size()

                                for suffix, suf_stack_size in _internal_genpath(_rk[1:], _rx[1:], _mss - stack_size - loadct_g_ss):
                                    yield trans_gs + [loadct_g] + suffix, suf_stack_size + stack_size + loadct_g_ss

                    # CT remains unchanged
                    else:
                        yield from _internal_genpath(_rk[1:], _rx[1:], _mss)

            for p in _perm(len(rk), len(rk)):

                shuffled_rk = [rk[i] for i in p]
                shuffled_rx = [rx[i] for i in p]

                for path, stack_size in _internal_genpath(shuffled_rk, shuffled_rx, mss):
                    yield path, stack_size

        try:

            _init_ct_g_cache()

            wef_used_syms, dest_reg = _find_subst_symbols(wanted_effect)

            for repl_seq in _replace_seq_gen(wef_used_syms):
                for repl_dest_reg in _replace_dest_reg(dest_reg):
                    
                    wef_subst = _apply_substitutions(wanted_effect, syms_to_replace=wef_used_syms, 
                                                        replacements=repl_seq, dest_reg_replacement=repl_dest_reg)

                    gs = self.search_gadget(wef_subst, max_stack_size=max_stack_size, fixed_reg_list=[],
                                            reg_start_values=[], max_search_cnt=2 ** 63)

                    if len(gs) == 0:
                        continue

                    try:

                        # for each gadget that satisfies wanted Effect with substitutions
                        #   for each way to move the result from intermediary dest reg to the real dest reg
                        #       for each way to replace all the reg_in elements
                        for wef_g in gs:

                            mss_aux1 = max_stack_size - wef_g.get_stack_size()
                            for repl_dest_path, ss_1 in self.transition_chain_generator(dest_reg, repl_dest_reg, trans_graph, mss_aux1):
                                
                                mss_aux2 = mss_aux1 - ss_1
                                if mss_aux2 < 0:
                                    raise RuntimeError(f"stack size bigger than mss in genpath: {mss_aux1}, max {ss_1}")

                                for path, ss_2 in _genpath(wef_used_syms, repl_seq, mss_aux2):

                                    if ss_2 > mss_aux2:
                                        raise RuntimeError(f"stack size bigger than mss in genpath: {ss_2}, max {mss_aux2}")

                                    # join from the end to the beginning: repl_dest_path, g, path
                                    final_path: List[ROP_gadget_x86_64]
                                    final_path = repl_dest_path + [wef_g] + path

                                    if ROP_searcher_x86_64._check_if_duplicate(path, b_cache) is True:
                                        continue

                                    candidate_ch = ROP_chain_x86_64.convert(final_path[-1].duplicate()[0])
                                    for g_aux in final_path[-2::-1]:
                    
                                        candidate_ch_aux = candidate_ch.join(g_aux)
                                        candidate_ch.remove_stack_ids()
                                        candidate_ch = candidate_ch_aux
                                
                                    if candidate_ch.get_stack_size() != ss_1 + ss_2 + wef_g.get_stack_size():
                                        raise RuntimeError(f"stack size inconsistent: expected {ss_1 + ss_2 + wef_g.get_stack_size()}, got {candidate_ch.get_stack_size()}")

                                    b = candidate_ch.get_bytes()
                                    if b in b_cache.keys():
                                        candidate_ch.remove_stack_ids()
                                        continue
                                    
                                    b_cache.update({b: False})

                                    # check if the obtained result really matches the wanted Effect
                                    # (check is needed because the transition paths' side effects are not taken into account when searching)

                                    # also, the start values are plugged in
                                    candidate_ch_cpy, org_to_fstid = candidate_ch.duplicate()

                                    start_values_cpy = deepcopy(reg_start_values)
                                    candidate_ch_cpy.effects = Effect.join_effects(start_values_cpy, candidate_ch_cpy.effects)

                                    to_check_effect: Effect = None
                                    for ef in candidate_ch_cpy.effects:

                                        if ef.destination_element.info["reg_name"] == dest_reg:
                                            to_check_effect = ef
                                            break
                                    
                                    if to_check_effect is None:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    wanted_effect_cpy = deepcopy(wanted_effect)

                                    if wanted_effect_cpy.match(to_check_effect) is False:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    if candidate_ch_cpy.check_fixed_regs(fixed_reg_list) is False:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    # match arith might have changed some stack values
                                    accepted_chain, org_to_sndid = candidate_ch.duplicate(copy_stack_associated_values=True)

                                    for org_stack_elem in candidate_ch.stack.elements:
                                        if org_stack_elem.type == "64b_stack_val":

                                            fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                                            if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[fstid]:

                                                if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                                    raise RuntimeError("original chain and cloned chain non-null values are different")

                                                sndid = _get_new_id(org_to_sndid, org_stack_elem.info["id"])
                                                Stack_view.stack_values[sndid] = Stack_view.stack_values[fstid]

                                    candidate_ch_cpy.remove_stack_ids()
                                    candidate_ch.remove_stack_ids()

                                    b_cache[b] = True
                                    yield accepted_chain

                    finally:

                        g: ROP_gadget_x86_64
                        for g in gs:
                            g.remove_stack_ids()
        
        finally:

            # clean up unused stack ids
            for _, d in trans_graph.items():
                for _, gs in d.items():
                    if gs is not None:
                        for g in gs:
                            g.remove_stack_ids()

# auxiliary class that helps in building the payload
class ROP_payload:

    class _alignment:

        # default alignment at the beginning of a payload
        DEFAULT_ALIGNMENT = 8

        SUPPORTED_ALIGNMENTS = [8, 16, 32, 64]
        
        def __init__(self, bound: int, is_aligned = False):

            self.bound = bound
            self.is_aligned = is_aligned

    class _addr:

        def __init__(self, addr: int):
            self.addr = addr

    def __init__(self, rop_searcher, output_handle = stdout):

        self.logger = Logger(session_name = "PAYLOAD BUILDER", output_handle = output_handle)
        self.rop_searcher: ROP_searcher_x86_64 = rop_searcher
        
        self.pad_byte = b'A'
        self.max_b_size = 160
        self.forbidden_bytes: List[bytes] = []

        self._raw_payload: List[ROP_payload._addr | bytes | ROP_payload._alignment | ROP_chain_x86_64] = []

    def set_max_size(self, max_byte_size: int) -> None:
        self.max_b_size = max_byte_size

    def add_chain(self, ch: ROP_chain_x86_64) -> None:
        self._raw_payload.append(ch)

    def add_bytes(self, b: bytes) -> None:
        self._raw_payload.append(b)

    def add_padding(self, pad_len: int)-> None:
        self._raw_payload.append(self.pad_byte * pad_len)

    def add_addr(self, addr: int) -> None:
        self._raw_payload.append(ROP_payload._addr(addr))

    # it marks that the stack is aligned to the specified boundary
    # thus ignoring the (deduced) alignment up to this point
    def is_aligned_as(self, bound: int = 8) -> None:

        if bound not in ROP_payload._alignment.SUPPORTED_ALIGNMENTS:
            raise RuntimeError(f"Requested stack alignment of {bound} bytes is not supported")

        self._raw_payload.append(ROP_payload._alignment(bound, is_aligned = True))

    # when building payload
    # this statement is equivalent to adding return-only gadgets
    def align_as(self, bound: int = 8) -> None:

        if bound not in ROP_payload._alignment.SUPPORTED_ALIGNMENTS:
            raise RuntimeError(f"Requested stack alignment of {bound} bytes is not supported")

        self._raw_payload.append(ROP_payload._alignment(bound, is_aligned = False))

    # remove the last added element
    def remove_last_added(self) -> None:

        if len(self._raw_payload) > 0:
            self._raw_payload.pop()

    # method responsible for building final payload, in bytes
    # NOTE: addr offset does NOT apply to given "naked" addresses,
    #       only to chain(gadget) addresses (and ret-only alignment gadgets)
    def build(self, chain_addr_offset: int = 0) -> bytes:

        _t = self.logger.log_info("Building payload...", start_timer = True)
        
        payload = b''

        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in self.forbidden_bytes:
                    return False

            return True

        # returns the (biggest) alignment
        def _check_alignment(to_check_len: int):
            
            for al in ROP_payload._alignment.SUPPORTED_ALIGNMENTS[::-1]:
                if to_check_len % al == 0:
                    return al

            return 0

        # searches for return address 
        # that does not contain forbidden bytes
        _cached_ret_addr = None
        def _get_ret_addr():

            nonlocal _cached_ret_addr
            
            if _cached_ret_addr is None:
                for ret_addr in self.rop_searcher.retonly_gadget.get_current_addrs():

                    b_ret_addr = to_bytes(ret_addr + chain_addr_offset)
                    if _check_bytes(b_ret_addr) is True:

                        _cached_ret_addr = b_ret_addr
                        break

            return _cached_ret_addr

        # preprocess the payload:
        #   * join adjacent chains
        def _preprocess():

            preproc_payload = [self._raw_payload[0]]

            for i in range(1, len(self._raw_payload)):

                if (type(preproc_payload[-1]) != ROP_chain_x86_64) or (type(self._raw_payload[i]) != ROP_chain_x86_64):
                    preproc_payload.append(self._raw_payload[i])

                elif (type(preproc_payload[-1]) == ROP_chain_x86_64) and (type(self._raw_payload[i]) == ROP_chain_x86_64):

                    aux_ch = preproc_payload[-1].join(self._raw_payload[i])
                    preproc_payload[-1].remove_stack_ids()
                    preproc_payload[-1] = aux_ch

                else:
                    raise RuntimeError(f"Encountered element of unknown type {type(self._raw_payload[i])} while trying to make payload")

            return preproc_payload

        preproc_payload = _preprocess()

        b_mss = self.max_b_size
        alignment_aux = ROP_payload._alignment.DEFAULT_ALIGNMENT
        
        for item in preproc_payload:

            if type(item) == bytes:

                if _check_bytes(item) is True:

                    payload += item
                    b_mss -= len(item)

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += len(item)
                    alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("Some given bytes for building payload contains forbidden bytes", end_timer = _t)
                    return None

            elif type(item) == ROP_payload._addr:

                b_item = to_bytes(item.addr)

                if _check_bytes(b_item) is True:

                    payload += b_item
                    b_mss -= 8

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += 8
                    alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("A given address for building payload contains forbidden bytes", end_timer = _t)
                    return None

            elif type(item) == ROP_payload._alignment:

                if item.is_aligned is False:
                    
                    current_alignment = _check_alignment(alignment_aux)
                    while current_alignment < item.bound:

                        b_ret_addr = _get_ret_addr()
                        if b_ret_addr is None:

                            self.logger.log_warning("Could not find return address for alignment that does not contain forbidden bytes", end_timer = _t)
                            return None

                        payload += b_ret_addr
                        b_mss -= 8

                        if b_mss < 0:
                            self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                            return None

                        alignment_aux += 8
                        alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]
                        current_alignment = _check_alignment(alignment_aux)

                else:
                    alignment_aux = item.bound

            elif type(item) == ROP_chain_x86_64:

                if b_mss < 8:
                    self.logger.log_warning(f"Not enough payload length for constructing payload for a given chain: only {b_mss} bytes left", end_timer = _t)
                
                payload_ = item._make_payload(max_stack_size = b_mss // 8, forbidden_bytes = self.forbidden_bytes, 
                                                addr_offset = chain_addr_offset, pad_byte = self.pad_byte)
                if payload_ is not None:

                    payload += payload_
                    b_mss -= len(payload_)

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += len(payload_)
                    alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("Creating payload for a given rop chain failed", end_timer = _t)
                    return None

        self.logger.log_success("Successfully built the payload", end_timer = _t)

        return payload

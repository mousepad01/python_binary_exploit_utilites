from __future__ import annotations
from typing import Dict, Generator, List, Tuple, Set
# both above imports only for type hints

from copy import deepcopy
from rand import random
from sys import stdout

from parsebin import *
from utils import to_bytes, _is_int
from logger import Logger

from rop_platform import Platform
from stackview import Stack_view
from structured_element import Structured_element_old
from effect import Effect_old

from capstone import *
import z3

class ROP_gadget_x86_64:
    '''
        Gadget class (for x86_64) that has associated a stack view and its effects\n
        A gadget object can store two identical gadgets, but at different addresses
    '''

    MAX_GADGET_BYTE_LEN = 30
    '''Maximum gadget byte length to be searched for'''

    def __init__(self):

        self.stack = Stack_view()
        self.effects: List[Effect_old] = []

        # self.b - bytes of the gadget
        # useful for identification (hashing) of a gadget / chain
        self.b: bytes = None

        # self.addrs - addresses of identical gadgets
        # used only at payload generation
        self.addrs: List[int] = []
    
        # self.eq_g - gadgets that differ by stack padding or nop instructions
        # used only at payload generation
        self.eq_g: List[ROP_gadget_x86_64] = []

    def get_bytes(self):
        '''
            Get the instruction bytes of this gadget
        '''
        return self.b

    def get_stack_size(self):
        return len(self.stack.elements)

    def get_current_addrs(self):
        '''
            Return current addresses where this gadget can be found\n
            By default, it contains the addresses without ASLR/PIE offsets
        '''
        return [Stack_view.stack_values[addr] for addr in self.addrs]

    def show(self, capstone_handle: Cs = None, show_addr = True, show_stack = True, output_handle = stdout):
        '''
            Prints gadget contents in a human-readable form
        '''

        if len(self.addrs) == 0:
            print("(empty gadget)", file = output_handle)
            return

        if capstone_handle is None:
            capstone_handle = Cs(CS_ARCH_X86, CS_MODE_64)

        disas_instr_generator = capstone_handle.disasm(self.b, self.get_current_addrs()[0])
        for ins in disas_instr_generator:

            if show_addr is True:
                print(f"{hex(ins.address)}: {ins.mnemonic} {ins.op_str}", file = output_handle)
            else:
                print(f"{ins.mnemonic} {ins.op_str}", file = output_handle)

        if show_stack is True:

            _s = f"----- STACK ({self.get_stack_size()} ELEMENTS) -----"
            print(_s, file = output_handle)

            self._show_stack_values(output_handle)

            print("-" * len(_s), file = output_handle)

    def _show_stack_values(self, output_handle):

        for idx, el in enumerate(self.stack.elements):

            if el.type == "64b_stack_val":

                val = Stack_view.stack_values[el.info['id']]
                if val is not None:
                    print(f"(+{hex(idx * 8)}) id {el.info['id']}: {hex(val)}", file = output_handle)
                else:
                    print(f"(+{hex(idx * 8)}) id {el.info['id']}: EMPTY", file = output_handle)
            else:
                print(f"(+{hex(idx * 8)}) ====PAD====", file = output_handle)

    def add_current_addr(self, addr: int):

        new_addr_id = Stack_view.get_elem_id()
        self.addrs.append(new_addr_id)
        Stack_view.stack_values[new_addr_id] = addr

    def _duplicate_stack(self, cpy: ROP_gadget_x86_64 | ROP_chain_x86_64, copy_stack_associated_values):
        '''
            Auxiliary internal method for duplication
        '''

        old_new_id: Dict[int, int] = {}
        def _get_new_id(old_id: int):
            
            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # recursive search for stack elements that need to be replaced
        def _recursive_replace(op_element: Structured_element_old):
            
            if op_element.type == "64b_stack_val":
                op_element.info["id"] = _get_new_id(op_element.info["id"])

            elif op_element.is_op():
                
                if op_element.info["term_1"] is not None:
                    _recursive_replace(op_element.info["term_1"])

                if op_element.info["term_2"] is not None:
                    _recursive_replace(op_element.info["term_2"])

        for stack_elem in self.stack.elements:

            if stack_elem.type == "64b_stack_pad":
                cpy.stack.push(Structured_element_old.instantiate_structured_element("64b_stack_pad"))

            elif stack_elem.type == "64b_stack_val":

                cpy_stack_elem = Structured_element_old.instantiate_structured_element("64b_stack_val")

                # check whether the current id has already been replaced in a previous stack element instance
                cpy_id = _get_new_id(stack_elem.info["id"])
                if cpy_id is None:
                    
                    cpy_stack_elem.info["id"] = Stack_view.get_elem_id()
                    old_new_id.update({stack_elem.info["id"]: cpy_stack_elem.info["id"]})

                    if copy_stack_associated_values is True:
                        Stack_view.stack_values[cpy_stack_elem.info["id"]] = Stack_view.stack_values[stack_elem.info["id"]]

                else:
                    cpy_stack_elem.info["id"] = cpy_id                    

                cpy.stack.push(cpy_stack_elem)

        cpy.effects = deepcopy(self.effects)
        for ef in cpy.effects:

            if ef.type == "LOAD_S":
                ef.params[0].info["id"] = _get_new_id(ef.params[0].info["id"])

            elif ef.type == "ARITH":
                _recursive_replace(ef.params[0])

        return cpy, old_new_id

    def duplicate(self, copy_stack_associated_values = True):
        '''
            Copy constructor that automatically manages stack ids\n
            It returns the new copy and the old-to-new ids list
        '''

        cpy = ROP_gadget_x86_64()

        cpy.b = self.b

        cpy.eq_g = self.eq_g.copy()
  
        cpy.addrs = self.addrs.copy()
        for i in range(len(cpy.addrs)):
            
            addr_val = Stack_view.stack_values[cpy.addrs[i]]
            addr_id_cpy = Stack_view.get_elem_id()
            Stack_view.stack_values[addr_id_cpy] = addr_val            
            cpy.addrs[i] = addr_id_cpy

        return self._duplicate_stack(cpy, copy_stack_associated_values)
    
    def remove_stack_ids(self):
        '''
            Method that clears stack ids\n
            Call it when a gadget (chain) is not needed anymore, to prevent memory leaks\n
            NOTE: does not remove anything from eq_g
        '''
        
        self.b = None
        self.effects = None

        for addr_id in self.addrs:
            Stack_view.del_id(addr_id)

        for stack_elem in self.stack.elements:
            if stack_elem.type == "64b_stack_val":
                Stack_view.del_id(stack_elem.info["id"])

        self.stack = None

    def check_fixed_regs(self, fixed_reg_list: List[str], mode='complete'):
        ''' 
            Function to check whether the given registers remain unchanged or not\n
            mode: 
            * fast - only checks destination_element for each effect
            * complete - checks match with identity effect R <- R when R is found as a destination element
        '''

        if mode == 'complete':

            for fixed_r in fixed_reg_list:
                for ef in self.effects:

                    if ef.destination_element.info["reg_name"] == fixed_r: 

                        if ef.type in ["LOAD_CT", "MOV_RR", "LOAD_S"]:
                            return False

                        elif ef.type == "ARITH":
                            
                            nop_mov = Effect_old.make_mov_rr_effect(fixed_r, fixed_r)
                            if Effect_old._match_arith(nop_mov, ef) is False:
                                return False

            return True

        elif mode == 'fast':

            for fixed_r in fixed_reg_list:
                for ef in self.effects:
                    if ef.destination_element.info["reg_name"] == fixed_r:
                        return False

            return True

        else:
            raise RuntimeError(f"unknown mode for fixed registers checking: {mode}")

    @staticmethod
    def _join_ef_stk(fst: ROP_gadget_x86_64 | ROP_chain_x86_64, snd: ROP_gadget_x86_64 | ROP_chain_x86_64):
        '''
            Auxiliary internal method for joining gadgets / chains 
        '''

        fst_cpy, _ = fst.duplicate(copy_stack_associated_values=True)
        snd_cpy, _ = snd.duplicate(copy_stack_associated_values=True)

        joined_effects = Effect_old.join_effects(fst_cpy.effects, snd_cpy.effects)
        joined_stack = Stack_view.join_stacks(fst_cpy.stack, snd_cpy.stack)

        res_chain = ROP_chain_x86_64()

        res_chain.stack = joined_stack
        res_chain.effects = joined_effects

        return res_chain, fst_cpy, snd_cpy

    def join(self, snd: ROP_gadget_x86_64 | ROP_chain_x86_64) -> ROP_chain_x86_64:
        '''
            Join two gadgets (chains)
        '''

        fst_cpy: ROP_gadget_x86_64
        res_chain, fst_cpy, snd_cpy = ROP_gadget_x86_64._join_ef_stk(self, snd)

        if type(snd) == ROP_chain_x86_64:

            res_chain.b = [fst_cpy.b] + snd_cpy.b
            res_chain.gadgets_stackview_offset = [0] + [off + fst_cpy.get_stack_size() for off in snd_cpy.gadgets_stackview_offset]
            res_chain.addrs = [fst_cpy.addrs] + snd_cpy.addrs
            res_chain.eq_g = [fst_cpy.eq_g] + snd_cpy.eq_g

        else:

            res_chain.b = [fst_cpy.b, snd_cpy.b]
            res_chain.gadgets_stackview_offset = [0, fst_cpy.get_stack_size()]
            res_chain.addrs = [fst_cpy.addrs, snd_cpy.addrs]
            res_chain.eq_g = [fst_cpy.eq_g, snd_cpy.eq_g]

        return res_chain

    # mostly for debugging purposes
    def __str__(self):
        return f"ROP gadget with stack {self.stack}, addresses are {self.get_current_addrs()}, effects {[str(ef) for ef in self.effects]}"

class ROP_chain_x86_64(ROP_gadget_x86_64):
    '''
        Chain class (for x86_64)\n
        Stores the entire abstract representation of every possible chain
    '''

    def __init__(self):

        self.stack: Stack_view = Stack_view()
        self.effects: List[Effect_old] = []

        self.b: List[bytes] = []

        self.addrs: List[List[int]] = []
        self.eq_g: List[List[ROP_gadget_x86_64]] = []

        # self.gadgets_stackview_offset - stack offset for each gadget
        self.gadgets_stackview_offset: List[int] = []

    @staticmethod
    def convert(gadget: ROP_gadget_x86_64) -> ROP_chain_x86_64:
        '''
            Converts a gadget to a chain with only one gadget WITHOUT copying
        '''

        # no conversion needed
        if type(gadget) == ROP_chain_x86_64:
            return gadget

        chain = ROP_chain_x86_64()

        chain.effects = gadget.effects
        chain.stack = gadget.stack

        chain.b = [gadget.b]
        chain.gadgets_stackview_offset = [0]
        chain.addrs = [gadget.addrs]
        chain.eq_g = [gadget.eq_g]

        return chain

    def get_bytes(self):
        '''
            Get the instruction bytes of this chain
        '''
        
        acc_b = b''
        for b_ in self.b:
            acc_b += b_

        return acc_b

    def get_gadget_cnt(self):
        return len(self.gadgets_stackview_offset)

    # generator instead of function as in ROP_gadget_x86_64 class
    def get_current_addrs(self): 
        for i in range(self.get_gadget_cnt()):
            yield [Stack_view.stack_values[addr_id] for addr_id in self.addrs[i]]

    def show(self, capstone_handle: Cs = None, show_addr = True, show_stack = True, output_handle = stdout):
        '''
            Prints chain contents in a human-readable form
        '''

        if len(self.addrs) == 0:
            print("(empty chain)", file = output_handle)
            return

        if capstone_handle is None:
            capstone_handle = Cs(CS_ARCH_X86, CS_MODE_64)

        _i = 0
        for addrs in self.get_current_addrs():

            disas_instr_generator = capstone_handle.disasm(self.b[_i], addrs[0])
            for ins in disas_instr_generator:

                if show_addr is True:
                    print(f"{hex(ins.address)}: {ins.mnemonic} {ins.op_str}")
                else:
                    print(f"{ins.mnemonic} {ins.op_str}")

            _i += 1

        if show_stack is True:

            _s = f"----- STACK ({self.get_stack_size()} ELEMENTS) -----"
            print(_s, file = output_handle)

            self._show_stack_values(output_handle)
            
            print("-" * len(_s), file = output_handle)

    def add_current_addr(self, addr: int, idx: int):
        
        new_addr_id = Stack_view.get_elem_id()
        self.addrs[idx].append(new_addr_id)
        Stack_view.stack_values[new_addr_id] = addr

    def duplicate(self, copy_stack_associated_values = True):
        '''
            Copy constructor that automatically manages stack ids\n
            It returns the new copy and the old-to-new ids list
        '''

        cpy = ROP_chain_x86_64()

        cpy.b = self.b.copy()
        cpy.gadgets_stackview_offset = self.gadgets_stackview_offset.copy()
        cpy.eq_g = [l.copy() for l in self.eq_g]

        cpy.addrs = deepcopy(self.addrs)
        for i in range(self.get_gadget_cnt()):
            for j in range(len(cpy.addrs[i])):
            
                addr_val = Stack_view.stack_values[cpy.addrs[i][j]]
                addr_id_cpy = Stack_view.get_elem_id()
                Stack_view.stack_values[addr_id_cpy] = addr_val            
                cpy.addrs[i][j] = addr_id_cpy

        return self._duplicate_stack(cpy, copy_stack_associated_values)
    
    def remove_stack_ids(self):
        '''
            Method that clears stack ids\n
            Call it when a gadget (chain) is not needed anymore, to prevent memory leaks\n
            NOTE: does not remove anything from eq_g
        '''
        
        for i in range(self.get_gadget_cnt()):
            for addr in self.addrs[i]:
                Stack_view.del_id(addr)

        for stack_elem in self.stack.elements:
            if stack_elem.type == "64b_stack_val":
                Stack_view.del_id(stack_elem.info["id"])

        self.b = None
        self.effects = None
        self.gadgets_stackview_offset = None
        self.stack = None

    def join(self, snd: ROP_gadget_x86_64 | ROP_chain_x86_64) -> ROP_chain_x86_64:
        '''
            Join two gadgets (chains)
        '''

        fst_cpy: ROP_chain_x86_64
        res_chain, fst_cpy, snd_cpy = ROP_gadget_x86_64._join_ef_stk(self, snd)
        
        if type(snd) == ROP_chain_x86_64:

            res_chain.b = fst_cpy.b + snd_cpy.b
            res_chain.gadgets_stackview_offset = fst_cpy.gadgets_stackview_offset
            res_chain.gadgets_stackview_offset += [off + fst_cpy.get_stack_size() for off in snd_cpy.gadgets_stackview_offset]
            res_chain.addrs = fst_cpy.addrs + snd_cpy.addrs
            res_chain.eq_g = fst_cpy.eq_g + snd_cpy.eq_g

        else:

            res_chain.b = fst_cpy.b
            res_chain.b.append(snd_cpy.b)
            res_chain.gadgets_stackview_offset = fst_cpy.gadgets_stackview_offset
            res_chain.gadgets_stackview_offset.append(fst_cpy.get_stack_size())
            res_chain.addrs = fst_cpy.addrs
            res_chain.addrs.append(snd_cpy.addrs)
            res_chain.eq_g = fst_cpy.eq_g
            res_chain.eq_g.append(snd_cpy.eq_g)

        return res_chain
    
    # NOTE: gadgets from eq_g are expected to be sorted by stack size
    def _make_payload(self, max_stack_size: int, forbidden_bytes: List[bytes] = [], 
                        addr_offset: int = 0, pad_sequence = b'A') -> bytes:
        '''
            Internal method that builds the payload for this chain
        '''
        
        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in forbidden_bytes:
                    return False

            return True

        payload = b''

        for i in range(self.get_gadget_cnt()):

            found = False

            stack_offset = self.gadgets_stackview_offset[i]

            stack_end = 0
            if i == self.get_gadget_cnt() - 1:
                stack_end = len(self.stack.elements)
            else:
                stack_end = self.gadgets_stackview_offset[i + 1]

            stacks = [self.stack.elements[stack_offset: stack_end]] + [g.stack.elements for g in self.eq_g[i]]
            addrs = [self.addrs[i]] + [g.addrs for g in self.eq_g[i]]

            for j in range(len(stacks)):
                if len(stacks[j]) <= max_stack_size:

                    for k in range(len(addrs[j])):
                        
                        b_addr = to_bytes(Stack_view.stack_values[addrs[j][k]] + addr_offset)

                        if _check_bytes(b_addr) is True:

                            payload += b_addr
                            
                            found = True
                            for el in stacks[j][:-1]:

                                if el.type == "64b_stack_pad":
                                    payload += (pad_sequence * 8)[:8]

                                elif el.type == "64b_stack_val":
                                    
                                    val = Stack_view.stack_values[el.info["id"]]

                                    if val is None:
                                        payload += (pad_sequence * 8)[:8]
                                        continue
                                
                                    b = to_bytes(val)
                                    if _check_bytes(b) is True:
                                        payload += b
                                    else:
                                        return None     # stacks differ only by padding, so if a forbidden byte is found, 
                                                        # it is clear that there is no way of constructing the payload

                            max_stack_size -= len(stacks[j])
                            
                            if found is True:
                                break

                if found is True:
                    break

            if found is False:
                return None

        if len(payload) % 8 != 0:
            raise RuntimeError(f"Payload is not 8-byte aligned (length: {len(payload)})")
                        
        return payload

    # mostly for debugging purposes
    def __str__(self):
        return f"ROP chain with stack {self.stack}, addresses are {'TODO'}, effects {[str(ef) for ef in self.effects]}"

class ROP_searcher_x86_64:
    '''
        Internal class that implements the search algorithms
    '''

    def __init__(self, filepath: str, logger: Logger):

        def _find_ret_offsets():

            ret_offsets = []

            for i in range(len(self.exec_bytes)):
                
                xc_offset, xc = self.exec_bytes[i]
                for ib in range(len(xc)):

                    if xc[ib: ib + 1] == b'\xc3':
                        ret_offsets.append((i, xc_offset + ib))

            return ret_offsets

        self.logger = logger

        self.exec_bytes = Elf_util(filepath).load_x_bytes()
        self.capstone = Cs(CS_ARCH_X86, CS_MODE_64)

        # constant, can be changed, but 3 is the maximum recommended value
        self.BRUTEFORCE_DEPTH = 2

        self.ret_offsets: List[Tuple[int, int]] = _find_ret_offsets()

        self.gadgets: Set[ROP_gadget_x86_64] = set()
        self.retonly_gadget: ROP_gadget_x86_64 = ROP_gadget_x86_64() 
        self.effects_to_gadgets: Dict[str, Dict[str, List[ROP_gadget_x86_64]]] = {ef_t: {reg: [] for reg in Platform.X86_64.SUPPORTED_REGS} for ef_t in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]}

        # cached results of calling self.get_trans_reg_graph()
        self.trans_register_graph = None
        self.path_from = None

    def find_gadgets(self):

        # dict to help identify gadget duplicates
        # helps identify gadgets that differ only by stack padding or ignored instructions
        opstr_to_gadgets: Dict[str, Tuple[ROP_gadget_x86_64, bool]] = {}
        # helps identify gadgets that are identical
        bytes_to_gadgets: Dict[str, Tuple[ROP_gadget_x86_64, bool]] = {}

        def _get_opstr(b_instr: bytes):

            opstr = ''
            
            for instr in self.capstone.disasm(b_instr, 0):

                if (instr.mnemonic in Platform.X86_64.IGNORED_INSTR_MNEMONICS) or (instr.mnemonic == "nop") \
                    or (instr.mnemonic == "add" and "rsp, 0x" in instr.op_str):
                    continue

                opstr += instr.mnemonic
                opstr += instr.op_str

            return opstr

        # auxiliary method to synchronize stack ids
        def _stack_id_sync(g: ROP_gadget_x86_64, eg: ROP_gadget_x86_64):
            
            s_g = g.stack.elements
            s_eg = eg.stack.elements

            i = 0
            j = 0
            while (i < len(s_g)) and (j < len(s_eg)):

                while (i < len(s_g)) and (s_g[i].type == "64b_stack_pad"):
                    i += 1

                while (j < len(s_eg)) and (s_eg[j].type == "64b_stack_pad"):
                    j += 1

                if i == len(s_g):
                    assert(j == len(s_eg))

                if (i < len(s_g)) and (j < len(s_eg)):

                    Stack_view.del_id(s_eg[j])
                    s_eg[j] = s_g[i]

                    i += 1
                    j += 1

                if i == len(s_g):
                    assert(j == len(s_eg))
        
        # initialize ret-only gadget
        self.retonly_gadget.stack.push(Structured_element_old.instantiate_structured_element("64b_stack_val"))
        self.retonly_gadget.stack.elements[0].info["id"] = Stack_view.get_elem_id()
        self.retonly_gadget.b = b'\xc3'
        
        # to check in constant time if the basse address
        # of a current gadget candidate actually steps over another ret
        ret_onlyoffsets = set(r[1] for r in self.ret_offsets)

        for xc_index, ret_offset in self.ret_offsets:

            self.retonly_gadget.add_current_addr(ret_offset)
            
            neg_offset = 1
            while (ret_offset - neg_offset > 0) and ((ret_offset - neg_offset) not in ret_onlyoffsets):
                
                b_vaddr = self.exec_bytes[xc_index][0]
                b_instr = self.exec_bytes[xc_index][1][ret_offset - neg_offset - b_vaddr: ret_offset - b_vaddr + 1]

                stop = False

                if b_instr in bytes_to_gadgets.keys():

                    if bytes_to_gadgets[b_instr][1] is True:
                        bytes_to_gadgets[b_instr][0].add_current_addr(ret_offset - neg_offset)

                else:

                    opstr = _get_opstr(b_instr)
                    if (opstr not in opstr_to_gadgets.keys()) or (opstr_to_gadgets[opstr][1] is True):
                        
                        disas_instr_generator = self.capstone.disasm(b_instr, ret_offset - neg_offset)
                        g, stop = self.create_gadget(disas_instr_generator, b_instr, ret_offset - neg_offset)

                        if (g is not None) and (len(g.effects) > 0):
                            
                            bytes_to_gadgets.update({b_instr: (g, True)})

                            if opstr in opstr_to_gadgets.keys():
                                opstr_to_gadgets[opstr][0].eq_g.append(g)

                            else:
                                opstr_to_gadgets.update({opstr: (g, True)})

                                for ef in g.effects:
                                    self.effects_to_gadgets[ef.type][ef.destination_element.info["reg_name"]].append(g)

                                self.gadgets.add(g)

                        else:
                            bytes_to_gadgets.update({b_instr: (None, False)})
                            opstr_to_gadgets.update({opstr: (None, False)})
                
                if stop is True:
                    break
                    
                neg_offset += 1

        # for each g, synchronize stack ids between g and gadgets from g.eq_g
        # so that stacks can be interchanged, having (at most) the padding size different
        for g in self.gadgets:
            for eg in g.eq_g:
                _stack_id_sync(g, eg)
  
        # from all eq_g per gadget, select the gadget with the smallest stack size
        # by swapping everything except the effects, which are identical
        # and then sort the eq_g gadgets
        for g in self.gadgets:
            for eg in g.eq_g:
                
                # assert(len(g.effects) == len(eg.effects))
                
                if eg.get_stack_size() < g.get_stack_size():

                    swap_aux = g.b
                    g.b = eg.b
                    eg.b = swap_aux

                    swap_aux = g.stack
                    g.stack = eg.stack
                    eg.stack = swap_aux

                    swap_aux = g.addrs
                    g.addrs = eg.addrs
                    eg.addrs = swap_aux

            g.eq_g.sort(key = lambda gadget: len(gadget.stack.elements))

        # sorting by used stack size
        for ef in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]:
            for reg in Platform.X86_64.SUPPORTED_REGS:
                self.effects_to_gadgets[ef][reg].sort(key = lambda g: len(g.stack.elements))

    def get_trans_reg_graph(self):
        '''
            Method that creates the graph for transitioning a value between registers
            * graph without any fixed register restirction
            * sub-graphs for one fixed register restriction, for each register
            * sub-graphs for pairs or 2 fixed registers, for each possible (ordered) pair\n
            NOTE: it does not support register start values
        '''

        if self.trans_register_graph is not None:
            return self.trans_register_graph, self.path_from

        _t = self.logger.log_info("Transition graph absent from memory. Building transition graph (might take minutes)...", start_timer=True)

        rs = deepcopy(Platform.X86_64.SUPPORTED_REGS)
        rs.sort()

        # all possible keys for fixed reg field: none(empty string), registers, or tuples of 2 registers
        all_fixedreg_keys = [""] + \
                            [r for r in rs] + \
                            [(rs[ir1], rs[ir2]) for ir1 in range(len(rs) - 1) for ir2 in range(ir1 + 1, len(rs))]

        # trans_reg_graph[fixed regs][dest][src][list of transition gadgets]
        trans_reg_graph: Dict[str | Tuple[str], Dict[str, Dict[str, List[ROP_gadget_x86_64]]]] = \
                {
                    fixed:
                    {
                        dest: 
                        {
                            src: [] 
                            for src in rs
                        } 
                        for dest in rs
                    }
                    for fixed in all_fixedreg_keys
                }

        # path_from[fixed regs][dest][src][path exists or not]
        path_from: Dict[str | Tuple[str], Dict[str, Dict[str, bool]]] = \
                {
                    fixed:
                    {
                        dest: 
                        {
                            src: False 
                            for src in rs
                        } 
                        for dest in rs
                    }
                    for fixed in all_fixedreg_keys
                }

        for dest in rs:
            for src in rs:

                if dest == src:

                    for fixed_arg in all_fixedreg_keys:
                        path_from[fixed_arg][dest][src] = True

                    continue

                dest_from_src_ef = Effect_old.make_mov_rr_effect(dest, src)
                dest_from_src_gadgets = self.filter_gadgets(wanted_effect=dest_from_src_ef, max_stack_size=2 ** 63, 
                                                            reg_start_values=[], max_search_cnt=2 ** 63)
                
                if len(dest_from_src_gadgets) != 0:
                    for fixed_arg in all_fixedreg_keys:
                        
                        if fixed_arg == "":

                            trans_reg_graph[""][dest][src] = dest_from_src_gadgets
                            path_from[""][dest][src] = True

                        elif type(fixed_arg) is str:

                            for g in dest_from_src_gadgets:
                                if g.check_fixed_regs([fixed_arg], mode='fast'):

                                    trans_reg_graph[fixed_arg][dest][src].append(g)
                                    path_from[fixed_arg][dest][src] = True

                        elif type(fixed_arg) is tuple:

                            for g in dest_from_src_gadgets:
                                if g.check_fixed_regs([fixed_arg[0], fixed_arg[1]], mode='fast'):

                                    trans_reg_graph[fixed_arg][dest][src].append(g)
                                    path_from[fixed_arg][dest][src] = True

        # completing path_from (Roy-Warshal) for each subgraph

        for fixed_arg in all_fixedreg_keys:

            for k in rs:
                for i in rs:
                    for j in rs:

                        if (path_from[fixed_arg][i][k] is True) and (path_from[fixed_arg][k][j] is True):
                            path_from[fixed_arg][i][j] = True

        self.trans_register_graph = trans_reg_graph
        self.path_from = path_from

        self.logger.log_success("Transition graph successfully built.", end_timer=_t)

        return trans_reg_graph, path_from

    def transition_chain_generator(self, dest: str, src: str, 
                                    trans_subgraph: Dict[str, Dict[str, List[ROP_gadget_x86_64]]], 
                                    subgraph_path_from: Dict[str, Dict[str, bool]], max_stack_size: int) -> Tuple[List[ROP_gadget_x86_64 | ROP_chain_x86_64], int]:
        '''
            Generator that yields all possible transition chains that satisfy the effect dest <- src\n
            The transitions are exclusively based on the transition subgraph given as a parameter\n
            TODO; optimize for shortest path for stack size
        '''

        # auxiliary data structure for the graph traversal
        _visited = set()

        # generator that returns a list of gadgets that compose the transfer path, and the accumulated stack size
        def _path_finder(current_reg: str, mss: int):

            _visited.add(current_reg)

            if current_reg == src:
                yield [], 0
                    
            else:

                for src_reg, gs in trans_subgraph[current_reg].items():
                    if (src_reg not in _visited) and (subgraph_path_from[src_reg][src] is True) and (len(gs) > 0):

                        mss_reached = False

                        for path_suffix, stack_size in _path_finder(src_reg, mss - gs[0].get_stack_size()):
                            for trans_g in gs:
                                
                                tgss = trans_g.get_stack_size()

                                if tgss + stack_size <= mss:
                                    yield [trans_g] + path_suffix, tgss + stack_size
                                else:
                                    mss_reached = True
                                    break
                            
                            # not always true
                            # but helpful to limit 
                            # the number of possibilities
                            if mss_reached is True:
                                break
                    
            _visited.remove(current_reg)

        return _path_finder(dest, max_stack_size)

    @staticmethod
    def _check_if_duplicate(gs: List[ROP_gadget_x86_64 | ROP_chain_x86_64], b_cache: Dict[bytes, bool]):
        '''
            Auxiliary method that checks whether any "subchain" was previously yielded or not
        '''

        def _chunks(l: List[ROP_gadget_x86_64 | ROP_chain_x86_64]):
            
            if len(l) == 0:
                return

            if len(l) == 1:
                yield l[0].get_bytes() 
                return

            if len(l) == 2:
                yield l[0].get_bytes()
                yield l[1].get_bytes()
                return

            for i in range(1, len(l)):
                yield b''.join([g.get_bytes() for g in l[:i]])
            yield b''.join([g.get_bytes() for g in l[1:]])

            yield from _chunks(l[1:])

        for subchain_b in _chunks(gs):
            if (subchain_b in b_cache.keys()) and (b_cache[subchain_b] is True):
                return True

        return False

    def create_gadget(self, instr_generator: Generator[CsInsn, None, None], b_instr: bytes, addr: int = None) -> Tuple[ROP_gadget_x86_64, bool]:
        '''
            Main (internal) method to create gadgets from raw bytes
        '''
        
        # decide here whether to send signal to the caller procedure
        # so that it stops appending preffixes to the same "gadget"
        def _send_stop_flag():
            return len(b_instr) > ROP_gadget_x86_64.MAX_GADGET_BYTE_LEN

        def _gadget_end(instr: CsInsn):
            return (instr.mnemonic == "ret") and (len(instr.op_str) == 0)

        # first, each instruction is analysed semantically and translated in some effects
        # then, the effects will be cumulated from first to last instruction, to obtain the gadget
        effects_per_instruction: List[List[Effect_old]] = []

        is_ret = False
        for instr in instr_generator:

            if _gadget_end(instr) is True:
                is_ret = True       # check whether the gedget ends with "ret" or not
                break

            instr_effects = Effect_old.analyse_instr(instr)
            if instr_effects is None:
                return None, _send_stop_flag()

            effects_per_instruction.append(instr_effects)
        
        if is_ret is False:
            return None, _send_stop_flag()

        new_stack, new_effects = Effect_old.join_instr_effects(effects_per_instruction)

        if new_stack is None:
            return None, _send_stop_flag()

        candidate_gadget = ROP_gadget_x86_64()
        candidate_gadget.stack = new_stack
        candidate_gadget.effects = new_effects

        candidate_gadget.add_current_addr(addr)
        candidate_gadget.b = b_instr

        return candidate_gadget, _send_stop_flag()

    def search_chain(self, wanted_effects: List[Effect_old], max_stack_size: int = 2**63, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect_old] = [], only_gadgets = False) -> List[ROP_chain_x86_64]:
        '''
            Internal method for searching chains with multiple wanted effects
        '''

        if only_gadgets is False and len(reg_start_values) > 0:
            raise RuntimeError("Register start values feature is only supported for gadget-only search (no chains of 2+ gadgets)")

        if only_gadgets is False and len(wanted_effects) > 1:
            raise RuntimeError("Multiple wanted effects (>1) are only supported for gadget-only search (no chains of 2+ gadgets)")

        b_cache: Dict[bytes, bool] = {}

        if only_gadgets is True:

            def _get_new_id(old_new_id: Dict[int, int], old_id: int):

                if old_id in old_new_id.keys():
                    return old_new_id[old_id]

                return None

            for g in self.search_gadgets(wanted_effect = wanted_effects[0], max_stack_size = max_stack_size, fixed_reg_list = fixed_reg_list,
                                            reg_start_values = reg_start_values, b_cache = b_cache):

                g_cpy, org_to_cpyid = g.duplicate()
                start_values_cpy = deepcopy(reg_start_values)
                g_cpy.effects = Effect_old.join_effects(start_values_cpy, g_cpy.effects)

                wef_sat = True
                for wef in wanted_effects[1:]:

                    wef_cpy = deepcopy(wef)

                    to_check_effect: Effect_old = None
                    for ef in g_cpy.effects:

                        if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == wef_cpy.destination_element.info["reg_name"]:
                            to_check_effect = ef
                            break
                    
                    if to_check_effect is None:
                        wef_sat = False
                        break

                    if wef_cpy.match(to_check_effect) is False:
                        wef_sat = False
                        break

                    if g_cpy.check_fixed_regs(fixed_reg_list) is False:
                        wef_sat = False
                        break

                if wef_sat is False:
                    g_cpy.remove_stack_ids()
                    continue

                for org_stack_elem in g.stack.elements:
                    if org_stack_elem.type == "64b_stack_val":

                        cpyid = _get_new_id(org_to_cpyid, org_stack_elem.info["id"])

                        if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[cpyid]:

                            if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                raise RuntimeError("original chain and cloned chain non-null values are different")

                            Stack_view.stack_values[org_stack_elem.info["id"]] == Stack_view.stack_values[cpyid]

                g_cpy.remove_stack_ids()

                yield g

        elif len(wanted_effects) == 1:

            wanted_effect = wanted_effects[0]
            
            if max_stack_size < 0:
                return

            yield from self.search_gadgets(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                            reg_start_values=reg_start_values, b_cache=b_cache)
            
            if wanted_effect.type == "LOAD_CT":

                yield from self.search_chain_by_substitution(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                                fixed_reg_list=fixed_reg_list, b_cache=b_cache)

                yield from self.search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                        fixed_reg_list=fixed_reg_list, b_cache=b_cache)

            elif wanted_effect.type == "ARITH":
                
                yield from self.search_chain_by_substitution(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                                fixed_reg_list=fixed_reg_list, b_cache=b_cache)

                yield from self.search_chain_by_substitution_adv(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                                    fixed_reg_list=fixed_reg_list, b_cache=b_cache)

                yield from self.search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                        fixed_reg_list=fixed_reg_list, b_cache=b_cache)

            elif wanted_effect.type == "MOV_RR":

                yield from self.search_mov_chains(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                    fixed_reg_list=fixed_reg_list, b_cache=b_cache)

                yield from self.search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                        fixed_reg_list=fixed_reg_list, b_cache=b_cache)

            else:
                raise RuntimeError(f"Unrecognised wanted effect type when searching chains: {wanted_effect.type}")

    def filter_gadgets(self, wanted_effect: Effect_old, max_stack_size: int = 2**63, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect_old] = [], max_search_cnt: int = 100) -> List[ROP_gadget_x86_64]:
        '''
            Internal method for searching gadgets that satisfy a single wanted effect\n
            It is usually pretty fast since it does not attemp at building any kind of chain\n
            Note that, unlike other chain searching implementations, this is a FUNCTION, NOT a GENERATOR\n
            (check docs section 'Gadget search' for more details)
        '''

        # as in duplicate method, represents a map 
        # between the original gadget stack ids and the new gadget stack ids
        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # a gadget can be referenced multiple times in the effects_to_gadgets dictionary
        # (when a gadget has multiple effects)
        # so, once a gadget has been checked, there is no need to check it twice
        tried_gadget_cache = set()

        # main function to try a gadget 
        def _try_gadget(candidate_g: ROP_gadget_x86_64, wanted_effect: Effect_old, searched_effect_types: List[str]):
            
            if candidate_g in tried_gadget_cache:
                return None

            if candidate_g.get_stack_size() > max_stack_size:

                tried_gadget_cache.add(candidate_g)
                return None
                
            # copies that can be manipulated without changing the original objects
            candidate_g_cpy, org_to_fstid = candidate_g.duplicate(copy_stack_associated_values=True)
            wanted_effect_cpy: Effect_old = deepcopy(wanted_effect)

            start_values_cpy = deepcopy(reg_start_values)
            candidate_g_cpy.effects = Effect_old.join_effects(start_values_cpy, candidate_g_cpy.effects)

            # every entry in effects_to_gadgets has a corresponding Effect
            # it is not kept in the dict, but can be found
            # by searching in the gadget's Effect list, by the reg_out name
            # NOTE: the type is not checked (only one Effect with the corresponding reg_name as destination)
            candidate_effect = None
            for ef in candidate_g_cpy.effects:

                if ef.destination_element.info["reg_name"] == wanted_effect_cpy.destination_element.info["reg_name"]:
                    candidate_effect = ef
                    break

            if candidate_effect.type not in searched_effect_types:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            matched = wanted_effect_cpy.match(candidate_effect)
            if matched is False:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            is_fixed = candidate_g_cpy.check_fixed_regs(fixed_reg_list)
            if is_fixed is False:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            # gadget is accepted, a third copy is created from the original gadget
            # that is not simplified like the first gadget copy, 
            # but does contain all the additional stack ids and their associated value from the first gadget copy
            # then, the first temporary copy has its stack ids and other contents removed

            accepted_gadget, org_to_sndid = candidate_g.duplicate(copy_stack_associated_values=True)

            for org_stack_elem in candidate_g.stack.elements:
                if org_stack_elem.type == "64b_stack_val":

                    fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                    if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[fstid]:

                        if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                            raise RuntimeError("original gadget and cloned gadget non-null values are different")

                        sndid = _get_new_id(org_to_sndid, org_stack_elem.info["id"])
                        Stack_view.stack_values[sndid] = Stack_view.stack_values[fstid]

                    # else, the accepted_gadget already has the original value

            candidate_g_cpy.remove_stack_ids()

            tried_gadget_cache.add(candidate_g)
            return accepted_gadget

        # table of possible Effect types matching
        # there can be multiple searched effects because, given specific circumstances, some effects can change type
        # NOTE: LOAD_S is intentionally restricted to only other LOAD_S effects, for an efficient/ fast search
        #       if one wants to have all the possible ways of loading a value in a register, LOAD_CT matching should be chosen instead
        # LOAD_S -> LOAD_S
        # LOAD_CT -> LOAD_CT, LOAD_S (always false if max stack size == 0), ARITH
        # MOV_RR -> MOV_RR, ARITH
        # ARITH -> ARITH

        # searched Effect type filtering
        # is done in two places: here, less restrictive
        # and inside the try gadget function, more restrictive
        # this is because we still want the search to be optimised
        # but also we need to take into account that the reg start values
        # can change some Effect types into other types

        found_g: List[ROP_gadget_x86_64] = []
        searched_effect_types_snd: List[str] = []
        searched_effect_types_fst: List[str] = []

        if wanted_effect.type == "LOAD_S":

            searched_effect_types_snd.append("LOAD_S")

            searched_effect_types_fst.append("LOAD_S")

        elif wanted_effect.type == "LOAD_CT":

            searched_effect_types_snd.append("LOAD_S")
            searched_effect_types_snd.append("LOAD_CT")
            searched_effect_types_snd.append("ARITH")

            searched_effect_types_fst.append("LOAD_S")
            searched_effect_types_fst.append("LOAD_CT")
            searched_effect_types_fst.append("MOV_RR")
            searched_effect_types_fst.append("ARITH")

        elif wanted_effect.type == "MOV_RR":

            searched_effect_types_snd.append("MOV_RR")
            searched_effect_types_snd.append("ARITH")

            searched_effect_types_fst.append("MOV_RR")
            searched_effect_types_fst.append("ARITH")

        elif wanted_effect.type == "ARITH":

            searched_effect_types_snd.append("ARITH")
            
            searched_effect_types_fst.append("ARITH")
            searched_effect_types_fst.append("MOV_RR")

        for srch_t in searched_effect_types_fst:

            found_per_t_cnt = 0
        
            candidate_g: ROP_gadget_x86_64
            for candidate_g in self.effects_to_gadgets[srch_t][wanted_effect.destination_element.info["reg_name"]]:
                
                accepted_gadget = _try_gadget(candidate_g, wanted_effect, searched_effect_types_snd)
                if accepted_gadget is not None:

                    found_g.append(accepted_gadget)

                    found_per_t_cnt += 1
                    if found_per_t_cnt == max_search_cnt:
                        break
        
        found_g.sort(key = lambda g: g.get_stack_size())
        return found_g[:max_search_cnt]

    def search_gadgets(self, wanted_effect: Effect_old, max_stack_size: int = 2**63, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect_old] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains formed from one single gadget\n
            Fastest chain search method\n
            (check docs for more details)
        '''

        gadgets = self.filter_gadgets(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                            reg_start_values=reg_start_values, max_search_cnt=2 ** 63)

        for g in gadgets:
            
            b = g.get_bytes()
            if b not in b_cache.keys():

                b_cache.update({b: True})
                yield ROP_chain_x86_64.convert(g)

    def search_mov_chains(self, wanted_effect: Effect_old, max_stack_size: int = 2**63, 
                            fixed_reg_list: List[str] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains that satisfy MOV_RR effects\n
            It makes use of the transition graph\n
            The execution time may increase exponentially if at least one of those conditions are reached:
            * all possible chains are yielded
            * len(fixed register list) > 2\n
            (check docs section 'Substitution based MOV_RR search' for more details)
        '''
        
        trans_graph, path_from = self.get_trans_reg_graph()

        if len(fixed_reg_list) == 0:

            trans_graph = trans_graph[""]
            path_from = path_from[""]

        elif len(fixed_reg_list) == 1:

            trans_graph = trans_graph[fixed_reg_list[0]]
            path_from = path_from[fixed_reg_list[0]]

        elif len(fixed_reg_list) >= 2:

            fixed_reg_list.sort()
            trans_graph = trans_graph[(fixed_reg_list[0], fixed_reg_list[1])]
            path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

        dest = wanted_effect.destination_element.info["reg_name"]
        src = wanted_effect.params[0].info["reg_name"]

        if path_from[dest][src] is False:
            self.logger.log_warning("(chain searcher): transition path does not exist")
            return

        for path, _ in self.transition_chain_generator(dest, src, trans_graph, path_from, max_stack_size):

            if len(path) == 0:
                continue

            if ROP_searcher_x86_64._check_if_duplicate(path, b_cache) is True:
                continue

            candidate_ch = ROP_searcher_x86_64.convert(path[-1].duplicate()[0])
            for g in path[-2::-1]:

                candidate_ch_aux = candidate_ch.join(g)
                candidate_ch.remove_stack_ids()
                candidate_ch = candidate_ch_aux

            if candidate_ch.get_stack_size() > max_stack_size:
                candidate_ch.remove_stack_ids()
                continue

            b = candidate_ch.get_bytes()
            if b in b_cache.keys():
                candidate_ch.remove_stack_ids()
                continue

            b_cache.update({b: False})

            wanted_effect_cpy = deepcopy(wanted_effect)

            to_check_ef: Effect_old = None
            for ef in candidate_ch.effects:
                
                if ef.destination_element.info["reg_name"] == dest:
                    to_check_ef = ef
                    break

            if (to_check_ef is None) or (wanted_effect_cpy.match(to_check_ef) is False):
                self.logger.log_debug(f"Effect not matched (X86_64 mov), when expected to match. Please report this to the creator of this tool.")
                candidate_ch.remove_stack_ids()
                continue

            if candidate_ch.check_fixed_regs(fixed_reg_list) is False:
                candidate_ch.remove_stack_ids()
                continue

            b_cache[b] = True
            yield candidate_ch

    def search_chain_by_substitution(self, wanted_effect: Effect_old, max_stack_size: int = 2**63, 
                                        fixed_reg_list: List[str] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains that satisfy ARITH or LOAD_CT effects, by (register-only) substitutions\n
            The execution time may increase exponentially if at least one of those conditions are reached:
            * all possible chains are yielded
            * number of fixed registers > 2
            * number of fixed registers + number of reg_in elements from the wanted effect > 3
            * max stack size is given\n
            (check docs section 'Substitution (register-only) based ARITH search' for more details)
        '''

        self.logger.log_debug("search by substitution")

        if wanted_effect.type not in ["ARITH", "LOAD_CT"]:
            raise RuntimeError(f"tyring to search chain inside _search_chain_by_substitution for wanted effect type {wanted_effect.type}")

        trans_graph, path_from = self.get_trans_reg_graph()

        fixed_reg_list = deepcopy(fixed_reg_list)
        fixed_reg_list.sort()

        SUPPORTED_SUBSTITUTION_REGS = deepcopy(Platform.X86_64.SUPPORTED_REGS)

        # ---------------

        def _find_used_regs(ef: Effect_old) -> Tuple[List[str], str]:
            '''
                Find all reg_in used, and the reg_out, for an ARITH / LOAD_CT Effect
            '''

            def _rec_find(el: Structured_element_old):
                
                if el is None:
                    return []

                if el.type == "reg_in":
                    return [el.info["reg_name"]]

                if el.is_op():
                    return _rec_find(el.info["term_1"]) + _rec_find(el.info["term_2"])

                if el.type == "64b_stack_val":
                    raise RuntimeError("wanted effect contains stack elements")

                return []

            if ef.type == "LOAD_CT":
                return [], ef.destination_element.info["reg_name"]

            elif ef.type == "ARITH":
                
                found = _rec_find(ef.params[0])

                to_return = []
                for r in found:
                    if r not in to_return:
                        to_return.append(r)

                return to_return, ef.destination_element.info["reg_name"]

        def _get_substitution(regs_to_replace: List[str], already_replaced: List[str]) -> Dict[str, Tuple[str, List[str]]]:
            '''
                Generator that finds all possible substitutions, without substituting the destination register
            '''

            if len(regs_to_replace) == 0:
                yield {}
                return

            r = regs_to_replace[0]
            regs_to_replace = regs_to_replace[1:]

            keep_fixed = regs_to_replace + already_replaced + fixed_reg_list

            # try to find subgraph for failproof substitutions

            if len(keep_fixed) == 0:
                subgraph_path_from = path_from[""]

            elif len(keep_fixed) == 1:
                subgraph_path_from = path_from[keep_fixed[0]]

            elif len(keep_fixed) >= 2:
                
                # register names need to be sorted
                if keep_fixed[0] > keep_fixed[1]:

                    _swapvar = keep_fixed[0]
                    keep_fixed[0] = keep_fixed[1]
                    keep_fixed[1] = _swapvar

                subgraph_path_from = path_from[(keep_fixed[0], keep_fixed[1])]

            # yield all possible combinations

            for r_sub_candidate in SUPPORTED_SUBSTITUTION_REGS:

                if r_sub_candidate not in keep_fixed and \
                    subgraph_path_from[r_sub_candidate][r] is True:

                    r_sub = r_sub_candidate
                    for sub in _get_substitution(regs_to_replace, already_replaced + [r_sub]):

                        total_sub = {r: (r_sub, keep_fixed)}
                        total_sub.update(sub)
                        yield total_sub

        def _get_substitution_dest(dest_reg: str) -> str:
            '''
                Find all possible substitution for the destination register of the wanted effect
            '''

            if len(fixed_reg_list) == 0:
                subgraph_path_from = path_from[""]

            elif len(fixed_reg_list) == 1:
                subgraph_path_from = path_from[fixed_reg_list[0]]

            elif len(fixed_reg_list) >= 2:
                subgraph_path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

            for r_sub in SUPPORTED_SUBSTITUTION_REGS:
                if r_sub != dest_reg and subgraph_path_from[dest_reg][r_sub] is True:
                    yield r_sub

        def _get_reglist_permutation(rs: List[str]) -> List[str]:
            '''
                Yield all permutations of a list of registers\n
                Used to determine the order for substitutions 
            '''

            def _perm(n, k):

                if k == 0:
                    yield []

                else:
                    for suf in _perm(n, k - 1):
                        for i in range(n):
                            if i not in suf:
                                yield [i] + suf

            for p in _perm(len(rs), len(rs)):
                yield [rs[i] for i in p]

        def _apply_substitutions(ef: Effect_old, substitution: Dict[str, Tuple[str, List[str]]], dest_substitution: str):
            '''
                Apply a given substitution on an effect
            '''

            def _rec_subst(el: Structured_element_old):

                if el is None:
                    return None

                if el.type == "reg_in":
                    el.info["reg_name"] = substitution[el.info["reg_name"]][0]

                elif el.is_op():
                    _rec_subst(el.info["term_1"])
                    _rec_subst(el.info["term_2"])

                elif el.type == "64b_stack_val":
                    raise RuntimeError("wanted Effect contains stack elements")

            subst_ef = deepcopy(ef)
            subst_ef.destination_element.info["reg_name"] = dest_substitution

            if subst_ef.type == "ARITH":
                _rec_subst(subst_ef.params[0])

            return subst_ef

        def _get_transition(ordered_reg_list: List[str], substitution: Dict[str, Tuple[str, List[str]]], local_max_ss: int) -> Tuple[List[ROP_gadget_x86_64 | ROP_chain_x86_64], int]:
            '''
                Yield all possible transitions, as a list of gadgets (chains), and the associated (minimum) stack size\n
                NOTE: without dest substitution transition
            '''

            if len(ordered_reg_list) == 0:
                yield [], 0
                return 

            r = ordered_reg_list[0]
            ordered_reg_list = ordered_reg_list[1:]

            r_sub, keep_fixed = substitution[r]

            if len(keep_fixed) == 0:

                trans_subgraph = trans_graph[""]
                subgraph_path_from = path_from[""]

            elif len(keep_fixed) == 1:

                trans_subgraph = trans_graph[keep_fixed[0]]
                subgraph_path_from = path_from[keep_fixed[0]]

            elif len(keep_fixed) >= 2:

                # register names need to be sorted
                if keep_fixed[0] > keep_fixed[1]:

                    _swapvar = keep_fixed[0]
                    keep_fixed[0] = keep_fixed[1]
                    keep_fixed[1] = _swapvar

                trans_subgraph = trans_graph[(keep_fixed[0], keep_fixed[1])]
                subgraph_path_from = path_from[(keep_fixed[0], keep_fixed[1])]

            for trans, current_ss in \
                self.transition_chain_generator(r_sub, r, trans_subgraph, subgraph_path_from, local_max_ss):

                for trans_suffix, suffix_ss in _get_transition(ordered_reg_list, substitution, local_max_ss - current_ss):

                    yield trans[::-1] + trans_suffix, current_ss + suffix_ss

        def _get_transition_dest(dest_reg: str, dest_substitution: str, local_max_ss: int) -> Tuple[List[ROP_gadget_x86_64 | ROP_chain_x86_64], int]:
            '''
                Yield all possible transitions for the destination register, as a list of gadgets (chains)
            '''

            if len(fixed_reg_list) == 0:

                trans_subgraph = trans_graph[""]
                subgraph_path_from = path_from[""]

            elif len(fixed_reg_list) == 1:

                trans_subgraph = trans_graph[fixed_reg_list[0]]
                subgraph_path_from = path_from[fixed_reg_list[0]]

            elif len(fixed_reg_list) >= 2:

                trans_subgraph = trans_graph[(fixed_reg_list[0], fixed_reg_list[1])]
                subgraph_path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

            for trans_d, ss in self.transition_chain_generator(dest_reg, dest_substitution, trans_subgraph, subgraph_path_from, local_max_ss):
                yield trans_d[::-1], ss

        # ---------------

        wef_in_regs, wef_dest_reg = _find_used_regs(wanted_effect)

        if len(fixed_reg_list) > 2:
            self.logger.log_warning("running substitution-based search that violates recommended constraint of " + \
                                    f"|fixed regs| <= 2 ({len(fixed_reg_list)} detected); " + \
                                    "note that the running time increases exponentially - check the documentation for more info")

        if len(wef_in_regs) + len(fixed_reg_list) > 3:
            self.logger.log_warning("running substitution-based search that violates recommended constraint of " + \
                                    f"|register parameters inside the wanted effect| + |fixed regs| <= 3 ({len(wef_in_regs) + len(fixed_reg_list)} detected); " + \
                                    "note that the running time increases exponentially - check the documentation for more info")

        # for each substitution order possible
        for ordered_reg_list in _get_reglist_permutation(wef_in_regs):
            
            # for each substitution possible
            for subst in _get_substitution(ordered_reg_list, []):
                for subst_dest in _get_substitution_dest(wef_dest_reg):
                    
                    # apply substitution on the wanted effect
                    wef_subst = _apply_substitutions(wanted_effect, subst, subst_dest)

                    wef_subst_gs = self.filter_gadgets(wef_subst, max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=[], max_search_cnt=2 ** 63)

                    # if substituted wanted effect cannot be satisfied
                    # try the next substitution
                    if len(wef_subst_gs) == 0:
                        continue
                    
                    # (used to break from all the loops inside the try block for whatever reason)
                    break_ = False

                    # (wrap in try block to delete temporary gadgets in a "finally" block)
                    try:
                    
                        # for each gadget that satisfies the substituted wanted effect
                        for wef_subst_g in wef_subst_gs:

                            # for each transition that implements the substitution
                            for trans, trans_ss in _get_transition(ordered_reg_list, subst, 
                                                                max_stack_size - wef_subst_g.get_stack_size()):
                                for trans_dest, trans_dest_ss in _get_transition_dest(wef_dest_reg, subst_dest, 
                                                                                    max_stack_size - wef_subst_g.get_stack_size() - trans_ss):

                                    # join the gadgets, 
                                    # validate the properties of the resulting chain, 
                                    # and yield it

                                    if wef_subst_g.get_stack_size() + trans_ss + trans_dest_ss > max_stack_size:
                                        break_ = True
                                        break

                                    to_join = trans + [wef_subst_g] + trans_dest

                                    if ROP_searcher_x86_64._check_if_duplicate(to_join, b_cache) is True:
                                        continue

                                    candidate_ch = ROP_chain_x86_64.convert(to_join[0].duplicate()[0])
                                    for g_aux in to_join[1:]:
                    
                                        candidate_ch_aux = candidate_ch.join(g_aux)
                                        candidate_ch.remove_stack_ids()
                                        candidate_ch = candidate_ch_aux

                                    if candidate_ch.get_stack_size() > max_stack_size:
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    b = candidate_ch.get_bytes()
                                    if b in b_cache.keys():
                                        candidate_ch.remove_stack_ids()
                                        continue
                                    
                                    b_cache.update({b: False})

                                    wanted_effect_cpy = deepcopy(wanted_effect)

                                    to_check_effect: Effect_old = None
                                    for ef in candidate_ch.effects:

                                        if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == wef_dest_reg:
                                            to_check_effect = ef
                                            break
                                    
                                    if (to_check_effect is None) or (wanted_effect_cpy.match(to_check_effect) is False):
                                        self.logger.log_debug(f"Effect not matched (X86_64 subst), when expected to match. Please report this to the creator of this tool.")
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    if candidate_ch.check_fixed_regs(fixed_reg_list, 'complete') is False:
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    b_cache[b] = True
                                    yield candidate_ch

                                if break_ is True:
                                    break

                            if break_ is True:
                                break

                    finally:

                        # delete temporary gadgets
                        for wef_subst_g in wef_subst_gs: 
                            wef_subst_g.remove_stack_ids()

    def search_chain_by_substitution_adv(self, wanted_effect: Effect_old, max_stack_size: int = 2**63, 
                                            fixed_reg_list: List[str] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains that satisfy ARITH or LOAD_CT effects, by (register and constants) substitutions\n
            The execution time may increase exponentially if at least one of those conditions are reached:
            * all possible chains are yielded
            * number of fixed registers > 2
            * number of fixed registers + number of reg_in elements from the wanted effect + number of constants from the wanted effect > 3
            * max stack size is given\n
            (check docs section 'Substitution (register and constants) based ARITH search' for more details)
        '''

        self.logger.log_debug("search by substitution advanced")

        if wanted_effect.type not in ["ARITH", "LOAD_CT"]:
            raise RuntimeError(f"tyring to search chain inside _search_chain_by_substitution for wanted effect type {wanted_effect.type}")

        trans_graph, path_from = self.get_trans_reg_graph()

        SUPPORTED_SUBSTITUTION_REGS = deepcopy(Platform.X86_64.SUPPORTED_REGS)

        rs = deepcopy(SUPPORTED_SUBSTITUTION_REGS)
        rs.sort()

        all_fixedreg_keys = [""] + \
                            [r for r in rs] + \
                            [(rs[ir1], rs[ir2]) for ir1 in range(len(rs) - 1) for ir2 in range(ir1 + 1, len(rs))]

        # load_ct_map[fixed regs][src ct][dest reg][list of transition gadgets]
        load_ct_map: Dict[str | Tuple[str], Dict[int, Dict[str, List[ROP_gadget_x86_64]]]] = \
                {
                    fixed: {}
                    for fixed in all_fixedreg_keys
                }

        fixed_reg_list = deepcopy(fixed_reg_list)
        fixed_reg_list.sort()

        # ---------------

        def _find_used_rcs(ef: Effect_old) -> Tuple[List[str | Tuple[int, int]], str]:
            '''
                Find all reg_in and ct_val used, and the reg_out, for an ARITH / LOAD_CT Effect\n
            '''

            preorder_ct_idx = -1
            def _rec_find(el: Structured_element_old):

                nonlocal preorder_ct_idx
                
                if el is None:
                    return []

                if el.type == "reg_in":
                    return [el.info["reg_name"]]

                if el.is_op():

                    r1 = _rec_find(el.info["term_1"])
                    r2 = _rec_find(el.info["term_2"])
                    return r1 + r2

                if el.type == "ct_val":
                    
                    preorder_ct_idx += 1
                    return [(el.info["value"], preorder_ct_idx)]

                if el.type == "64b_stack_val":
                    raise RuntimeError("wanted effect contains stack elements")

                return []

            if ef.type == "LOAD_CT":
                return [(ef.params[0].info["value"], 0)], ef.destination_element.info["reg_name"]

            elif ef.type == "ARITH":
                
                found = _rec_find(ef.params[0])

                to_return = []
                for r in found:

                    if r not in to_return:
                        to_return.append(r)

                return to_return, ef.destination_element.info["reg_name"]
            
        def _populate_load_ct_map(el: Structured_element_old) -> None:
            '''
                Populate load_ct_map, by searching for constants in the wanted effect
            '''
            
            if el is None:
                return

            if el.is_op():
                _populate_load_ct_map(el.info["term_1"])
                _populate_load_ct_map(el.info["term_2"])

            if el.type == "ct_val":
                
                ct_value = el.info["value"]
                
                if ct_value in load_ct_map[""].keys():
                    return

                for fixed_arg in all_fixedreg_keys:
                    load_ct_map[fixed_arg].update({ct_value: {r: [] for r in SUPPORTED_SUBSTITUTION_REGS}})
                            
                for r in SUPPORTED_SUBSTITUTION_REGS:

                    ct_to_r = Effect_old.make_load_ct_effect(r, ct_value)
                    load_ct_gs = self.filter_gadgets(ct_to_r, max_stack_size=max_stack_size, 
                                                    fixed_reg_list=[], reg_start_values=[], max_search_cnt=2**64)

                    if len(load_ct_gs) == 0:
                        continue

                    for fixed_arg in all_fixedreg_keys:
                        
                        if fixed_arg == "":
                            load_ct_map[""][ct_value][r] = load_ct_gs

                        elif type(fixed_arg) is str:

                            for g in load_ct_gs:
                                if g.check_fixed_regs([fixed_arg], mode='fast'):

                                    load_ct_map[fixed_arg][ct_value][r].append(g)

                        elif type(fixed_arg) is tuple:

                            for g in load_ct_gs:
                                if g.check_fixed_regs([fixed_arg[0], fixed_arg[1]], mode='fast'):

                                    load_ct_map[fixed_arg][ct_value][r].append(g)

        def _get_substitution(rcs_to_replace: List[str | Tuple[int, int]], already_replaced: List[str]) -> Dict[str | int, Tuple[str, List[str]]]:
            '''
                Generator that finds all possible substitutions, without substituting the destination register
            '''

            if len(rcs_to_replace) == 0:
                yield {}
                return

            rc = rcs_to_replace[0]
            rcs_to_replace = rcs_to_replace[1:]

            keep_fixed = already_replaced + fixed_reg_list

            for reg_or_ct in rcs_to_replace:
                if reg_or_ct in SUPPORTED_SUBSTITUTION_REGS:

                    keep_fixed.append(reg_or_ct)

            # try to find subgraph for failproof substitutions

            if len(keep_fixed) == 0:

                subgraph_path_from = path_from[""]
                load_ct_submap = load_ct_map[""]

            elif len(keep_fixed) == 1:

                subgraph_path_from = path_from[keep_fixed[0]]
                load_ct_submap = load_ct_map[keep_fixed[0]]

            elif len(keep_fixed) >= 2:
                
                # register names need to be sorted
                if keep_fixed[0] > keep_fixed[1]:

                    _swapvar = keep_fixed[0]
                    keep_fixed[0] = keep_fixed[1]
                    keep_fixed[1] = _swapvar

                subgraph_path_from = path_from[(keep_fixed[0], keep_fixed[1])]
                load_ct_submap = load_ct_map[(keep_fixed[0], keep_fixed[1])]

            # yield all possible combinations

            # register
            if rc in SUPPORTED_SUBSTITUTION_REGS:

                for r_sub_candidate in SUPPORTED_SUBSTITUTION_REGS:

                    if r_sub_candidate not in keep_fixed and \
                        subgraph_path_from[r_sub_candidate][rc] is True:

                        r_sub = r_sub_candidate
                        for sub in _get_substitution(rcs_to_replace, already_replaced + [r_sub]):

                            total_sub = {rc: (r_sub, keep_fixed)}
                            total_sub.update(sub)
                            yield total_sub

            # constant 
            else:

                ct, preorder_idx = rc

                # case when constant is not substituted
                for sub in _get_substitution(rcs_to_replace, already_replaced):

                    total_sub = {preorder_idx: (None, keep_fixed)}
                    total_sub.update(sub)
                    yield total_sub
                
                # case when constant is substituted
                for ct_sub_candidate in SUPPORTED_SUBSTITUTION_REGS:

                    if ct_sub_candidate not in keep_fixed and \
                        len(load_ct_submap[ct][ct_sub_candidate]) > 0:

                        ct_sub = ct_sub_candidate
                        for sub in _get_substitution(rcs_to_replace, already_replaced + [ct_sub]):

                            total_sub = {preorder_idx: (ct_sub, keep_fixed)}
                            total_sub.update(sub)
                            yield total_sub

        def _get_substitution_dest(dest_reg: str) -> str:
            '''
                Find all possible substitution for the destination register of the wanted effect
            '''

            if len(fixed_reg_list) == 0:
                subgraph_path_from = path_from[""]

            elif len(fixed_reg_list) == 1:
                subgraph_path_from = path_from[fixed_reg_list[0]]

            elif len(fixed_reg_list) >= 2:
                subgraph_path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

            for r_sub in SUPPORTED_SUBSTITUTION_REGS:
                if r_sub != dest_reg and subgraph_path_from[dest_reg][r_sub] is True:
                    yield r_sub

        def _get_rclist_permutation(rcs: List[str | Tuple[int, int]]) -> List[str]:
            '''
                Yield all permutations of a list of registers and constants\n
                Used to determine the order for substitutions 
            '''

            def _perm(n, k):

                if k == 0:
                    yield []

                else:
                    for suf in _perm(n, k - 1):
                        for i in range(n):
                            if i not in suf:
                                yield [i] + suf

            for p in _perm(len(rcs), len(rcs)):
                yield [rcs[i] for i in p]

        def _apply_substitutions(ef: Effect_old, substitution: Dict[str | int, Tuple[str, List[str]]], dest_substitution: str):
            '''
                Apply a given substitution on an effect
            '''

            preorder_ct_idx = -1
            def _rec_subst(el: Structured_element_old):

                nonlocal preorder_ct_idx

                if el is None:
                    return None

                if el.type == "reg_in":
                    el.info["reg_name"] = substitution[el.info["reg_name"]][0]

                elif el.is_op():
                    _rec_subst(el.info["term_1"])
                    _rec_subst(el.info["term_2"])

                elif el.type == "ct_val":

                    preorder_ct_idx += 1

                    r_subst, _ = substitution[preorder_ct_idx]
                    if r_subst is None:
                        return

                    el.type = "reg_in"
                    el.info = {"reg_name": r_subst}

            subst_ef = deepcopy(ef)
            subst_ef.destination_element.info["reg_name"] = dest_substitution

            _rec_subst(subst_ef.params[0])

            return subst_ef

        def _get_transition(ordered_rc_list: List[str | Tuple[int, int]], substitution: Dict[str | int, Tuple[str, List[str]]], local_max_ss: int) \
                                -> Tuple[List[ROP_gadget_x86_64 | ROP_chain_x86_64], int]:
            '''
                Yield all possible transitions, as a list of gadgets (chains), and the associated (minimum) stack size\n
                NOTE: without dest substitution transition
            '''

            if len(ordered_rc_list) == 0:
                yield [], 0
                return 

            rc = ordered_rc_list[0]
            ordered_rc_list = ordered_rc_list[1:]

            # register
            if rc in SUPPORTED_SUBSTITUTION_REGS:

                r_sub, keep_fixed = substitution[rc]

                if len(keep_fixed) == 0:

                    trans_subgraph = trans_graph[""]
                    subgraph_path_from = path_from[""]

                elif len(keep_fixed) == 1:

                    trans_subgraph = trans_graph[keep_fixed[0]]
                    subgraph_path_from = path_from[keep_fixed[0]]

                elif len(keep_fixed) >= 2:

                    # register names need to be sorted
                    if keep_fixed[0] > keep_fixed[1]:

                        _swapvar = keep_fixed[0]
                        keep_fixed[0] = keep_fixed[1]
                        keep_fixed[1] = _swapvar
                    
                    trans_subgraph = trans_graph[(keep_fixed[0], keep_fixed[1])]
                    subgraph_path_from = path_from[(keep_fixed[0], keep_fixed[1])]

                for trans, current_ss in \
                    self.transition_chain_generator(r_sub, rc, trans_subgraph, subgraph_path_from, local_max_ss):

                    for trans_suffix, suffix_ss in _get_transition(ordered_rc_list, substitution, local_max_ss - current_ss):

                        yield trans[::-1] + trans_suffix, current_ss + suffix_ss

            # constant
            else:

                ct, preorder_idx = rc
                r_sub, keep_fixed = substitution[preorder_idx]

                # constant is not substituted
                if r_sub is None:
                    yield from _get_transition(ordered_rc_list, substitution, local_max_ss)

                # constant is substituted
                else:

                    if len(keep_fixed) == 0 or len(keep_fixed) > 2:
                        load_ct_submap = load_ct_map[""]

                    elif len(keep_fixed) == 1:
                        load_ct_submap = load_ct_map[keep_fixed[0]]

                    elif len(keep_fixed) == 2:

                        # register names need to be sorted
                        if keep_fixed[0] > keep_fixed[1]:

                            _swapvar = keep_fixed[0]
                            keep_fixed[0] = keep_fixed[1]
                            keep_fixed[1] = _swapvar

                        load_ct_submap = load_ct_map[(keep_fixed[0], keep_fixed[1])]

                    for trans_ct in load_ct_submap[ct][r_sub]:
                        if trans_ct.get_stack_size() <= local_max_ss:

                            for trans_suffix, suffix_ss in _get_transition(ordered_rc_list, substitution, local_max_ss - trans_ct.get_stack_size()):
                                yield [trans_ct] + trans_suffix, trans_ct.get_stack_size() + suffix_ss

        def _get_transition_dest(dest_reg: str, dest_substitution: str, local_max_ss: int) -> Tuple[List[ROP_gadget_x86_64 | ROP_chain_x86_64], int]:
            '''
                Yield all possible transitions for the destination register, as a list of gadgets (chains)
            '''

            if len(fixed_reg_list) == 0:

                trans_subgraph = trans_graph[""]
                subgraph_path_from = path_from[""]

            elif len(fixed_reg_list) == 1:

                trans_subgraph = trans_graph[fixed_reg_list[0]]
                subgraph_path_from = path_from[fixed_reg_list[0]]

            elif len(fixed_reg_list) >= 2:

                trans_subgraph = trans_graph[(fixed_reg_list[0], fixed_reg_list[1])]
                subgraph_path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

            for trans_d, ss in self.transition_chain_generator(dest_reg, dest_substitution, trans_subgraph, subgraph_path_from, local_max_ss):
                yield trans_d[::-1], ss

        # ---------------

        _t = self.logger.log_info("Preprocessing R <- CT map for the substitution of constants", start_timer=True)
        _populate_load_ct_map(wanted_effect.params[0])
        self.logger.log_info("Preprocessing of R <- CT map done", end_timer=_t)

        wef_rcs, wef_dest_reg = _find_used_rcs(wanted_effect)

        if len(fixed_reg_list) > 2:
            self.logger.log_warning("running substitution-based search that violates recommended constraint of " + \
                                    f"|fixed regs| <= 2 ({len(fixed_reg_list)} detected); " + \
                                    "note that the running time increases exponentially - check the documentation for more info")

        if len(wef_rcs) + len(fixed_reg_list) > 3:
            self.logger.log_warning("running substitution-based search that violates recommended constraint of " + \
                                    "|register parameters and constants inside the wanted effect| + |fixed regs| <= 3" + \
                                    f"({len(wef_rcs) + len(fixed_reg_list)} detected); " + \
                                    "note that the running time increases exponentially - check the documentation for more info")

        # for each substitution order possible
        for ordered_rc_list in _get_rclist_permutation(wef_rcs):
            
            # for each substitution possible
            for subst in _get_substitution(ordered_rc_list, []):
                for subst_dest in _get_substitution_dest(wef_dest_reg):
                    
                    # apply substitution on the wanted effect
                    wef_subst = _apply_substitutions(wanted_effect, subst, subst_dest)

                    wef_subst_gs = self.filter_gadgets(wef_subst, max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=[], max_search_cnt=2 ** 63)

                    # if substituted wanted effect cannot be satisfied
                    # try the next substitution
                    if len(wef_subst_gs) == 0:
                        continue
                    
                    # (used to break from all the loops inside the try block for whatever reason)
                    break_ = False

                    # (wrap in try block to delete temporary gadgets in a "finally" block)
                    try:
                    
                        # for each gadget that satisfies the substituted wanted effect
                        for wef_subst_g in wef_subst_gs:
                            
                            # for each transition that implements the substitution
                            for trans, trans_ss in _get_transition(ordered_rc_list, subst, 
                                                                max_stack_size - wef_subst_g.get_stack_size()):
                                for trans_dest, trans_dest_ss in _get_transition_dest(wef_dest_reg, subst_dest, 
                                                                                    max_stack_size - wef_subst_g.get_stack_size() - trans_ss):
                                    
                                    # join the gadgets, 
                                    # validate the properties of the resulting chain, 
                                    # and yield it

                                    if wef_subst_g.get_stack_size() + trans_ss + trans_dest_ss > max_stack_size:
                                        break_ = True
                                        break

                                    to_join = trans + [wef_subst_g] + trans_dest

                                    if ROP_searcher_x86_64._check_if_duplicate(to_join, b_cache) is True:
                                        continue

                                    candidate_ch = ROP_chain_x86_64.convert(to_join[0].duplicate()[0])
                                    for g_aux in to_join[1:]:
                    
                                        candidate_ch_aux = candidate_ch.join(g_aux)
                                        candidate_ch.remove_stack_ids()
                                        candidate_ch = candidate_ch_aux
                                
                                    if candidate_ch.get_stack_size() > max_stack_size:
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    b = candidate_ch.get_bytes()
                                    if b in b_cache.keys():
                                        candidate_ch.remove_stack_ids()
                                        continue
                                    
                                    b_cache.update({b: False})

                                    wanted_effect_cpy = deepcopy(wanted_effect)

                                    to_check_effect: Effect_old = None
                                    for ef in candidate_ch.effects:

                                        if ef.destination_element.info["reg_name"] == wef_dest_reg:
                                            to_check_effect = ef
                                            break
                                    
                                    if (to_check_effect is None) or (wanted_effect_cpy.match(to_check_effect) is False):
                                        self.logger.log_debug(f"Effect not matched (X86_64 subst adv), when expected to match. Please report this to the creator of this tool.")
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    if candidate_ch.check_fixed_regs(fixed_reg_list, 'complete') is False:
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    b_cache[b] = True
                                    yield candidate_ch

                                if break_ is True:
                                    break

                            if break_ is True:
                                break

                    finally:

                        # delete temporary gadgets
                        for wef_subst_g in wef_subst_gs: 
                            wef_subst_g.remove_stack_ids()

    def search_by_bruteforce(self, wanted_effect: Effect_old, max_stack_size: int = 2**63, 
                                fixed_reg_list: List[str] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains by bruteforce with limited depth
        '''

        max_g_cnt = self.BRUTEFORCE_DEPTH
        if max_g_cnt > 3:
            self.logger.log_warning(f"Running bruteforce with maximum depth {max_g_cnt}. Consider changing the depth to at most 3")

        if max_g_cnt < 1:
            return

        # function that creates a rop chain
        # from a copy of a given gadget input,
        # and taking into account reg start values 
        def _prepare(g: ROP_gadget_x86_64) -> ROP_chain_x86_64:

            cpy_g, _ = g.duplicate()
            return ROP_chain_x86_64.convert(cpy_g)

        # all the gadgets converted to atomic chains
        base_gs: List[ROP_chain_x86_64] = [_prepare(g) for g in self.gadgets]

        # yields all different arrangements of gadgets of length k
        def _get_paths(k: int):
            
            if k == 0:
                yield [], 0

            else:
                for suf, stack_size in _get_paths(k - 1):
                    for g in base_gs:
                        yield [g] + suf, stack_size + g.get_stack_size()

        try:

            for l in range(max_g_cnt):
                for path, stack_size in _get_paths(l + 1):

                    if stack_size > max_stack_size:
                        continue    

                    if ROP_searcher_x86_64._check_if_duplicate(path, b_cache) is True:
                        continue

                    candidate_ch: ROP_chain_x86_64 = path[-1].duplicate()[0]
                    for g in path[-2::-1]:

                        candidate_ch_aux = candidate_ch.join(g)
                        candidate_ch.remove_stack_ids()
                        candidate_ch = candidate_ch_aux

                    b = candidate_ch.get_bytes()
                    if b in b_cache.keys():
                        candidate_ch.remove_stack_ids()
                        continue

                    b_cache.update({b: False})

                    wanted_effect_cpy = deepcopy(wanted_effect)

                    to_check_effect: Effect_old = None
                    for ef in candidate_ch_aux.effects:
                        if ef.destination_element.info["reg_name"] == wanted_effect_cpy.destination_element.info["reg_name"]:
                            to_check_effect = ef
                            break

                    if to_check_effect is None:
                        candidate_ch.remove_stack_ids()
                        continue

                    if wanted_effect_cpy.match(to_check_effect) is False:
                        candidate_ch.remove_stack_ids()
                        continue

                    if candidate_ch_aux.check_fixed_regs(fixed_reg_list) is False:
                        candidate_ch.remove_stack_ids()
                        continue

                    b_cache[b] = True
                    yield candidate_ch
        
        finally:

            for ch in base_gs:
                ch.remove_stack_ids()

class ROP_payload_x86_64:
    '''
        Class that implements the payload building API for x86_64
    '''

    class _alignment:

        # default alignment at the beginning of a payload
        DEFAULT_ALIGNMENT = 8

        SUPPORTED_ALIGNMENTS = [8, 16, 32, 64]
        
        def __init__(self, bound: int, is_aligned = False):

            self.bound = bound
            self.is_aligned = is_aligned

    class _addr:

        def __init__(self, addr: int):
            self.addr = addr

    def __init__(self, rop_searcher, output_handle = stdout):

        self.logger = Logger(session_name = "PAYLOAD BUILDER", output_handle = output_handle)
        self.rop_searcher: ROP_searcher_x86_64 = rop_searcher
        
        self.pad_sequence = b'A'
        self.max_b_size = 2**63
        self.forbidden_bytes: List[bytes] = []

        self._raw_payload: List[ROP_payload_x86_64._addr | bytes | ROP_payload_x86_64._alignment | ROP_chain_x86_64] = []

    def set_forbidden_bytes(self, forbidden_bytes: List[bytes] = []) -> None:
        '''
            Specify the forbidden bytes that should not be found inside the payload bytes
        '''
        self.forbidden_bytes = forbidden_bytes

    def set_pad_sequence(self, pad_sequence = b'A') -> None:
        '''
            Set what padding sequence to use (default 'A' byte)\n
            For example, for the sequence b'1234', the padding of length 9 bytes will be b'123412341'
        '''
        self.pad_sequence = pad_sequence

    def set_max_size(self, max_byte_size: int = 2**63) -> None:
        '''
            Set the maximum payload byte length (default infinite)
        '''
        self.max_b_size = max_byte_size

    def add_chain(self, ch: ROP_chain_x86_64) -> None:
        '''
            Add a chain to the payload
        '''
        self._raw_payload.append(ch)

    def add_bytes(self, b: bytes) -> None:
        '''
            Add custom bytes inside the payload
        '''
        self._raw_payload.append(b)

    def add_padding(self, pad_len: int)-> None:
        '''
            Add padding bytes of specified length
        '''
        l = 1 + (pad_len // len(self.pad_sequence))
        pad = self.pad_sequence * l
        self._raw_payload.append(pad[:pad_len])

    def add_addr(self, addr: int) -> None:
        '''
            Add an address to the final payload\n
            Standard method of adding the address at the end of the chain\n
            NOTE: addresses added this way are not changed by the offset provided when building the payload
        '''
        self._raw_payload.append(ROP_payload_x86_64._addr(addr))

    def is_aligned_as(self, bound: int = 8) -> None:
        '''
            Overwrite automatically determined alignment with the value given in 'bound' argument\n
            It marks that the stack is aligned to that value, useful at the beginning of the payload, 
            when it is considered aligned to 8 byte boundary by default
        '''
        if bound not in ROP_payload_x86_64._alignment.SUPPORTED_ALIGNMENTS:
            raise RuntimeError(f"Requested stack alignment of {bound} bytes is not supported")

        self._raw_payload.append(ROP_payload_x86_64._alignment(bound, is_aligned = True))

    def align_as(self, bound: int = 8) -> None:
        '''
            Align the payload to a specific boundary (8, 16, 32, 64)\n
            It does that by adding 'RET'-only gadgets
        '''
        if bound not in ROP_payload_x86_64._alignment.SUPPORTED_ALIGNMENTS:
            raise RuntimeError(f"Requested stack alignment of {bound} bytes is not supported")

        self._raw_payload.append(ROP_payload_x86_64._alignment(bound, is_aligned = False))

    def remove_last_added(self) -> None:
        '''
        Remove the last added element
        '''
        if len(self._raw_payload) > 0:
            self._raw_payload.pop()

    def build(self, chain_addr_offset: int = 0) -> bytes:
        '''
            Build payload bytes from this object\n
            Observations:
            * chain_addr_offset is added only to chain addresses, NOT to addresses added manually with add_addr()
        '''

        _t = self.logger.log_info("Building payload...", start_timer = True)
        
        payload = b''

        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in self.forbidden_bytes:
                    return False

            return True

        # returns the (biggest) alignment
        def _check_alignment(to_check_len: int):
            
            for al in ROP_payload_x86_64._alignment.SUPPORTED_ALIGNMENTS[::-1]:
                if to_check_len % al == 0:
                    return al

            return 0

        # searches for return address 
        # that does not contain forbidden bytes
        _cached_ret_addr = None
        def _get_ret_addr():

            nonlocal _cached_ret_addr
            
            if _cached_ret_addr is None:
                for ret_addr in self.rop_searcher.retonly_gadget.get_current_addrs():

                    b_ret_addr = to_bytes(ret_addr + chain_addr_offset)
                    if _check_bytes(b_ret_addr) is True:

                        _cached_ret_addr = b_ret_addr
                        break

            return _cached_ret_addr

        # preprocess the payload:
        #   * join adjacent chains
        def _preprocess():

            preproc_payload = [self._raw_payload[0]]

            for i in range(1, len(self._raw_payload)):

                if (type(preproc_payload[-1]) != ROP_chain_x86_64) or (type(self._raw_payload[i]) != ROP_chain_x86_64):
                    preproc_payload.append(self._raw_payload[i])

                elif (type(preproc_payload[-1]) == ROP_chain_x86_64) and (type(self._raw_payload[i]) == ROP_chain_x86_64):

                    aux_ch = preproc_payload[-1].join(self._raw_payload[i])
                    preproc_payload[-1].remove_stack_ids()
                    preproc_payload[-1] = aux_ch

                else:
                    raise RuntimeError(f"Encountered element of unknown type {type(self._raw_payload[i])} while trying to make payload")

            return preproc_payload

        preproc_payload = _preprocess()

        b_mss = self.max_b_size
        alignment_aux = ROP_payload_x86_64._alignment.DEFAULT_ALIGNMENT
        
        for item in preproc_payload:

            if type(item) == bytes:

                if _check_bytes(item) is True:

                    payload += item
                    b_mss -= len(item)

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += len(item)
                    alignment_aux %= ROP_payload_x86_64._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("Some given bytes for building payload contains forbidden bytes", end_timer = _t)
                    return None

            elif type(item) == ROP_payload_x86_64._addr:

                b_item = to_bytes(item.addr)

                if _check_bytes(b_item) is True:

                    payload += b_item
                    b_mss -= 8

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += 8
                    alignment_aux %= ROP_payload_x86_64._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("A given address for building payload contains forbidden bytes", end_timer = _t)
                    return None

            elif type(item) == ROP_payload_x86_64._alignment:

                if item.is_aligned is False:
                    
                    current_alignment = _check_alignment(alignment_aux)
                    while current_alignment < item.bound:

                        b_ret_addr = _get_ret_addr()
                        if b_ret_addr is None:

                            self.logger.log_warning("Could not find return address for alignment that does not contain forbidden bytes", end_timer = _t)
                            return None

                        payload += b_ret_addr
                        b_mss -= 8

                        if b_mss < 0:
                            self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                            return None

                        alignment_aux += 8
                        alignment_aux %= ROP_payload_x86_64._alignment.SUPPORTED_ALIGNMENTS[-1]
                        current_alignment = _check_alignment(alignment_aux)

                else:
                    alignment_aux = item.bound

            elif type(item) == ROP_chain_x86_64:

                if b_mss < 8:
                    self.logger.log_warning(f"Not enough payload length for constructing payload for a given chain: only {b_mss} bytes left", end_timer = _t)
                
                payload_ = item._make_payload(max_stack_size = b_mss // 8, forbidden_bytes = self.forbidden_bytes, 
                                                addr_offset = chain_addr_offset, pad_sequence = self.pad_sequence)
                if payload_ is not None:

                    payload += payload_
                    b_mss -= len(payload_)

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += len(payload_)
                    alignment_aux %= ROP_payload_x86_64._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("Creating payload for a given rop chain failed", end_timer = _t)
                    return None

        self.logger.log_success("Successfully built the payload", end_timer = _t)

        return payload

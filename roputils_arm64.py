from __future__ import annotations
from typing import Dict, Generator, List, Tuple, Set
# both above imports only for type hints

from copy import deepcopy
from rand import random
from sys import stdout
from time import time

from parsebin import *
from utils import to_bytes
from logger import Logger

from rop_platform import Platform
from stackview import Stack_view
from structured_element import Structured_element
from effect import Effect

from capstone import *
import z3

class ROP_gadget:
    '''
        Gadget class that has associated a stack view and its effects\n
        A gadget object can store two identical gadgets, but at different addresses
    '''

    MAX_GADGET_BYTE_LEN = 60
    '''Maximum gadget byte length to be searched for'''

    def __init__(self):

        self.stack = Stack_view()
        '''
            The projection of the runtime stack that is used by this gadget (chain)
        '''

        self.effects: List[Effect] = []
        '''
            The list of independent effects for this gadget (chain)
        '''

        self.b: bytes = None 
        '''
            Instruction bytes corresponding to this gadget (chain)\n
            Useful for identification (hashing) of a gadget (chain)
        '''

        self.addrs: List[int] = []
        '''
            Addresses of all gadgets (chains) identical with this one\n
            Used only at payload generation
        '''
    
        self.eq_g: List[ROP_gadget] = []
        '''
            Gadgets that differ by stack padding or nop instructions\n
            Used only at payload generation
            FIXME: incompat arm vs x86????
        '''

        self.end_sp_pos: int = 0
        '''
            Location of the stack pointer on the stack after executing the gadget (chain), 
            relative to its position when entering the gadget (chain)\n
            (i.e. start sp pos == 0)
        '''

        self.valid_stack_access: bool = False
        '''
            Does this gadget (chain) have all stack accesses valid?
        '''

        self.valid_jump: bool = False
        '''
            Does this gadget (chain) have all jumps valid?
        '''

        self.unresolved_derefs: List[Effect] = []
        '''
            Internal attribute, used to store every unresolved deref\n
            Used only in the preprocessing phase, up to stack accesses validation
        '''

    def get_bytes(self):
        '''
            Get the instruction bytes of this gadget
        '''
        return self.b

    def get_stack_size(self):
        '''
            Get the stack size, in 8 byte chunks\n
            NOTE: if end sp is beyond the stack view, that offset is not included
        '''
        # return max(len(self.stack.elements), self.end_sp_pos + 1)
        return len(self.stack.elements)
        
    def get_current_addrs(self):
        '''
            Return current addresses where this gadget can be found\n
            By default, it contains the addresses without ASLR offsets
        '''
        return [Stack_view.stack_values[addr] for addr in self.addrs]

    def show(self, capstone_handle: Cs, show_addr = True, show_stack = True, output_handle = stdout):
        '''
            Prints gadget contents in a human-readable form
        '''

        if len(self.addrs) == 0:
            print("(empty gadget)", file = output_handle)
            return

        print(f"valid_stack_access = {self.valid_stack_access}", file = output_handle)
        print(f"valid_jump = {self.valid_jump}\n", file = output_handle)

        disas_instr_generator = capstone_handle.disasm(self.b, self.get_current_addrs()[0])
        for ins in disas_instr_generator:

            if show_addr is True:
                print(f"{hex(ins.address)}: {ins.mnemonic} {ins.op_str}", file = output_handle)
            else:
                print(f"{ins.mnemonic} {ins.op_str}", file = output_handle)

        if show_stack is True:

            _s = f"----- STACK ({self.get_stack_size()} ELEMENTS) -----"
            print(_s, file = output_handle)

            self._show_stack_values(output_handle)

            print("-" * len(_s), file = output_handle)

    def _show_stack_values(self, output_handle):

        for idx, el in enumerate(self.stack.elements):

            if idx == self.end_sp_pos:
                suffix = "<---- end SP"
            else:
                suffix = ""

            if el.type == "64b_stack_val":

                val = Stack_view.stack_values[el.info['id']]
                jmp = Stack_view.related_jump[el.info['id']]

                if jmp is not None:
                    suffix = f"(jump {jmp}) {suffix}"

                if val is not None:
                    print(f"(+{hex(idx * 8)}) id {el.info['id']}: {hex(val)} {suffix}", file = output_handle)
                else:
                    print(f"(+{hex(idx * 8)}) id {el.info['id']}: EMPTY {suffix}", file = output_handle)
            else:
                print(f"(+{hex(idx * 8)}) ====PAD==== {suffix}", file = output_handle)

        print(f"\nend SP offset: +{hex(8 * self.end_sp_pos)}")

    def add_current_addr(self, addr: int):
        '''
            Add another address where this gadget could be found (without ASLR offset)
        '''

        new_addr_id = Stack_view.get_elem_id()
        self.addrs.append(new_addr_id)
        Stack_view.stack_values[new_addr_id] = addr

    def _duplicate_stack(self, cpy: ROP_chain | ROP_chain, copy_stack_associated_values):
        '''
            Auxiliary internal method for duplication
        '''

        old_new_id: Dict[int, int] = {}
        def _get_new_id(old_id: int):
            
            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # recursive search for stack elements that need to be replaced
        def _recursive_replace(op_element: Structured_element):
            
            if op_element.type == "64b_stack_val":
                op_element.info["id"] = _get_new_id(op_element.info["id"])

            elif op_element.is_op():
                
                if op_element.info["term_1"] is not None:
                    _recursive_replace(op_element.info["term_1"])

                if op_element.info["term_2"] is not None:
                    _recursive_replace(op_element.info["term_2"])

        for stack_elem in self.stack.elements:

            if stack_elem.type == "64b_stack_pad":
                cpy.stack.push(Structured_element.instantiate_structured_element("64b_stack_pad"))

            elif stack_elem.type == "64b_stack_val":

                cpy_stack_elem = Structured_element.instantiate_structured_element("64b_stack_val")

                cpy_id = _get_new_id(stack_elem.info["id"])
                if cpy_id is not None:
                    raise Exception(f"double stack id found when duplicating stack {cpy_id}")
                    
                cpy_stack_elem.info["id"] = Stack_view.get_elem_id()
                old_new_id.update({stack_elem.info["id"]: cpy_stack_elem.info["id"]})

                if copy_stack_associated_values is True:

                    Stack_view.stack_values[cpy_stack_elem.info["id"]] = Stack_view.stack_values[stack_elem.info["id"]] 
                    Stack_view.related_jump[cpy_stack_elem.info["id"]] = Stack_view.related_jump[stack_elem.info["id"]] 

                cpy.stack.push(cpy_stack_elem)

        cpy.effects = deepcopy(self.effects)
        for ef in cpy.effects:

            if ef.type in ["ARITH", "LOAD_S", "JUMP"]:
                _recursive_replace(ef.params[0])

        # unresolved derefs might directly access stack, too
        cpy.unresolved_derefs = deepcopy(self.unresolved_derefs)
        for el in cpy.unresolved_derefs:
            _recursive_replace(el)

        return cpy, old_new_id

    def duplicate(self, copy_stack_associated_values = True):
        '''
            Copy constructor that automatically manages stack ids\n
            It returns the new copy and the old-to-new ids list
        '''

        cpy = ROP_gadget()

        cpy.b = self.b

        cpy.eq_g = self.eq_g.copy()

        cpy.valid_stack_access = self.valid_stack_access
        cpy.valid_jump = self.valid_jump

        cpy.end_sp_pos = self.end_sp_pos
  
        cpy.addrs = self.addrs.copy()
        for i in range(len(cpy.addrs)):

            # no related jump for self.addrs IDs
            
            addr_val = Stack_view.stack_values[cpy.addrs[i]]
            addr_id_cpy = Stack_view.get_elem_id()
            Stack_view.stack_values[addr_id_cpy] = addr_val            
            cpy.addrs[i] = addr_id_cpy

        return self._duplicate_stack(cpy, copy_stack_associated_values)
    
    def remove_stack_ids(self):
        '''
            Method that clears stack ids\n
            Call it when a gadget (chain) is not needed anymore, to prevent memory leaks\n
            NOTE: does not remove anything from eq_g
        '''
        
        self.b = None
        self.effects = None

        for addr_id in self.addrs:
            Stack_view.del_id(addr_id)

        for stack_elem in self.stack.elements:
            if stack_elem.type == "64b_stack_val":
                Stack_view.del_id(stack_elem.info["id"])

        self.stack = None
        self.end_sp_pos = None

        self.valid_jump = None
        self.valid_stack_access = None

    def check_fixed_regs(self, fixed_reg_list: List[str], mode='complete'):
        ''' 
            Function to check whether the given registers remain unchanged or not\n
            mode: 
            * fast - only checks destination_element for each effect
            * complete - checks match with identity effect R <- R when R is found as a destination element
        '''

        if mode == 'complete':

            for fixed_r in fixed_reg_list:
                for ef in self.effects:

                    if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == fixed_r: 

                        if ef.type in ["LOAD_CT", "MOV_RR", "LOAD_S"]:
                            return False

                        elif ef.type == "ARITH":
                            
                            nop_mov = Effect.make_mov_rr_effect(fixed_r, fixed_r)
                            if Effect._match_arith(nop_mov, ef) is False:
                                return False

            return True

        elif mode == 'fast':

            for fixed_r in fixed_reg_list:
                for ef in self.effects:
                    if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == fixed_r:
                        return False

            return True

        else:
            raise RuntimeError(f"unknown mode for fixed registers checking: {mode}")

    @staticmethod
    def _join_ef_stk(fst: ROP_chain | ROP_chain, snd: ROP_chain | ROP_chain):
        '''
            Auxiliary internal method for joining gadgets / chains 
            NOTE: it also handles validation checks / updates
        '''
        
        # NOTE: returns old_id if not replaced
        def _get_new_id(old_id: int):
            
            if old_id in old_new_id.keys():
                return old_new_id[old_id]
            else:
                return old_id

        # recursive search for stack elements that need to be replaced
        def _recursive_replace(op_element: Structured_element):
            
            if op_element.type == "64b_stack_val":
                op_element.info["id"] = _get_new_id(op_element.info["id"])

            elif op_element.is_op():
                
                if op_element.info["term_1"] is not None:
                    _recursive_replace(op_element.info["term_1"])

                if op_element.info["term_2"] is not None:
                    _recursive_replace(op_element.info["term_2"])

            elif op_element.type == "deref":

                if op_element.info["expr"] is None:
                    raise Exception("dereferencing None found")

                _recursive_replace(op_element.info["expr"])

        fst_cpy, _ = fst.duplicate(copy_stack_associated_values=True)
        snd_cpy, _ = snd.duplicate(copy_stack_associated_values=True)

        joined_effects = Effect.join_effects(fst_cpy.effects, snd_cpy.effects)
        joined_unres_derefs = Effect.join_unresolved_derefs(fst_cpy.effects, fst_cpy.unresolved_derefs,
                                                                    snd_cpy.unresolved_derefs)
        joined_stack, old_new_id, new_end_sp_pos = Stack_view.join_stacks(fst_cpy.stack, snd_cpy.stack, 
                                                                                    fst.end_sp_pos, snd.end_sp_pos)
        if joined_stack is None:

            fst_cpy.remove_stack_ids()
            snd_cpy.remove_stack_ids()
            
            return None, None, None

        # invalidate them to be sure
        # they are not used anymore, after stack joining
        fst_cpy.stack = None
        snd_cpy.stack = None

        for ef in joined_effects:
            _recursive_replace(ef.params[0])

        for el in joined_unres_derefs:
            _recursive_replace(el)

        valid_stack_access = True
        if fst.valid_stack_access is False or snd.valid_stack_access is False:

            for ef in joined_effects:

                resolved = Effect.resolve_stack_access(ef.params[0], joined_stack)
                if resolved is None:

                    for el in joined_stack.elements:
                        if el.type == "64b_stack_val":
                            Stack_view.del_id(el.info["id"])
                    
                    return None, None, None

                valid_stack_access = valid_stack_access and resolved

            old_joined_derefs = joined_unres_derefs
            joined_unres_derefs = []

            for el in old_joined_derefs:

                resolved = Effect.resolve_stack_access(el, joined_stack)
                if resolved is None:

                    for el_ in joined_stack.elements:
                        if el_.type == "64b_stack_val":
                            Stack_view.del_id(el_.info["id"])
                    
                    return None, None, None

                if resolved is False:
                    joined_unres_derefs.append(el)

                valid_stack_access = valid_stack_access and resolved

        valid_jump = True
        if fst.valid_jump is False or snd.valid_jump is False:

            for ef in joined_effects:
                
                if ef.type == "JUMP":

                    valid = Effect.resolve_jump(ef.params[0], ef.destination_element.info["value"])
                    if valid is None:

                        for el in joined_stack.elements:
                            if el.type == "64b_stack_val":
                                Stack_view.del_id(el.info["id"])
                        
                        return None, None, None

                    valid_jump = valid_jump and valid

        res_chain = ROP_chain()

        res_chain.stack = joined_stack
        res_chain.effects = joined_effects

        res_chain.valid_stack_access = valid_stack_access
        res_chain.valid_jump = valid_jump

        res_chain.end_sp_pos = new_end_sp_pos

        res_chain.unresolved_derefs = joined_unres_derefs

        return res_chain, fst_cpy, snd_cpy

    def join(self, snd: ROP_chain | ROP_chain) -> ROP_chain:
        '''
            Join two gadgets (chains)
        '''

        fst_cpy: ROP_chain
        res_chain, fst_cpy, snd_cpy = ROP_chain._join_ef_stk(self, snd)

        if res_chain is None:
            return None

        if type(snd) == ROP_chain:

            res_chain.b = [fst_cpy.b] + snd_cpy.b
            res_chain.addrs = [fst_cpy.addrs] + snd_cpy.addrs
            res_chain.eq_g = [fst_cpy.eq_g] + snd_cpy.eq_g

        else:

            res_chain.b = [fst_cpy.b, snd_cpy.b]
            res_chain.addrs = [fst_cpy.addrs, snd_cpy.addrs]
            res_chain.eq_g = [fst_cpy.eq_g, snd_cpy.eq_g]

        return res_chain

    # mostly for debugging purposes
    def __str__(self):
        return f"ROP gadget with stack {self.stack}, addresses are {self.get_current_addrs()}, effects {[str(ef) for ef in self.effects]}"

class ROP_chain(ROP_gadget):
    '''
        Chain class\n
        Stores the entire abstract representation of every possible chain
    '''

    def __init__(self):

        self.stack: Stack_view = Stack_view()
        '''
            The projection of the runtime stack that is used by this gadget (chain)
        '''

        self.effects: List[Effect] = []
        '''
            The list of independent effects for this gadget (chain)
        '''

        self.b: List[bytes] = []
        '''
            Instruction bytes corresponding to this gadget (chain)\n
            Useful for identification (hashing) of a gadget (chain)
        '''

        self.addrs: List[List[int]] = []
        '''
            Addresses of all gadgets (chains) identical with this one\n
            Used only at payload generation
        '''

        self.eq_g: List[List[ROP_chain]] = []
        '''
            Gadgets that differ by stack padding or nop instructions\n
            Used only at payload generation
            FIXME: incompat arm vs x86????
        '''

        self.end_sp_pos: int = 0
        '''
            Location of the stack pointer on the stack after executing the gadget (chain), 
            relative to its position when entering the gadget (chain)\n
            (i.e. start sp pos == 0)
        '''

        self.valid_stack_access: bool = False
        '''
            Does this gadget (chain) have all stack accesses valid?
        '''

        self.valid_jump: bool = False
        '''
            Does this gadget (chain) have all jumps valid?
        '''

        self.unresolved_derefs: List[Effect] = []
        '''
            Internal attribute, used to store every unresolved deref\n
            Used only in the preprocessing phase, up to stack accesses validation
        '''

    @staticmethod
    def convert(gadget: ROP_gadget) -> ROP_chain:
        '''
            Converts a gadget to a chain with only one gadget WITHOUT copying
        '''

        # no conversion needed
        if type(gadget) == ROP_chain:
            return gadget

        chain = ROP_chain()

        chain.effects = gadget.effects
        chain.stack = gadget.stack

        chain.b = [gadget.b]
        chain.addrs = [gadget.addrs]
        chain.eq_g = [gadget.eq_g]

        chain.end_sp_pos = gadget.end_sp_pos

        chain.valid_jump = gadget.valid_jump
        chain.valid_stack_access = gadget.valid_stack_access

        return chain

    def get_bytes(self):
        '''
            Get the instruction bytes for this chain
        '''
        
        acc_b = b''
        for b_ in self.b:
            acc_b += b_

        return acc_b

    def get_gadget_cnt(self):
        '''
            Get the gadget count for this chain
        '''
        return len(self.b)

    def get_current_addrs(self): 
        '''
            Return current addresses where the gadgets from this chain can be found\n
            By default, it contains the addresses without ASLR offsets\n
            NOTE: it is a generator
        '''
        for i in range(self.get_gadget_cnt()):
            yield [Stack_view.stack_values[addr_id] for addr_id in self.addrs[i]]

    def show(self, capstone_handle: Cs, show_addr = True, show_stack = True, output_handle = stdout):
        '''
            Prints chain contents in a human-readable form
        '''
        
        if len(self.addrs) == 0:
            print("(empty chain)", file = output_handle)
            return

        print(f"valid_stack_access = {self.valid_stack_access}", file = output_handle)
        print(f"valid_jump = {self.valid_jump}\n", file = output_handle)

        _i = 0
        for addrs in self.get_current_addrs():

            disas_instr_generator = capstone_handle.disasm(self.b[_i], addrs[0])
            for ins in disas_instr_generator:

                if show_addr is True:
                    print(f"{hex(ins.address)}: {ins.mnemonic} {ins.op_str}")
                else:
                    print(f"{ins.mnemonic} {ins.op_str}")

            _i += 1

        if show_stack is True:

            _s = f"----- STACK ({self.get_stack_size()} ELEMENTS) -----"
            print(_s, file = output_handle)

            self._show_stack_values(output_handle)
            
            print("-" * len(_s), file = output_handle)

    def add_current_addr(self, addr: int, idx: int):
        '''
            Add another address where gadget with index idx could be found (without ASLR offset)
        '''
        
        new_addr_id = Stack_view.get_elem_id()
        self.addrs[idx].append(new_addr_id)
        Stack_view.stack_values[new_addr_id] = addr

    def duplicate(self, copy_stack_associated_values = True):
        '''
            Copy constructor that automatically manages stack ids\n
            It returns the new copy and the old-to-new ids list
        '''

        cpy = ROP_chain()

        cpy.b = self.b.copy()
        cpy.eq_g = [l.copy() for l in self.eq_g]

        cpy.valid_stack_access = self.valid_stack_access
        cpy.valid_jump = self.valid_jump

        cpy.end_sp_pos = self.end_sp_pos

        cpy.addrs = deepcopy(self.addrs)
        for i in range(self.get_gadget_cnt()):
            for j in range(len(cpy.addrs[i])):
            
                addr_val = Stack_view.stack_values[cpy.addrs[i][j]]
                addr_id_cpy = Stack_view.get_elem_id()
                Stack_view.stack_values[addr_id_cpy] = addr_val            
                cpy.addrs[i][j] = addr_id_cpy

        return self._duplicate_stack(cpy, copy_stack_associated_values)
    
    def remove_stack_ids(self):
        '''
            Method that clears stack ids\n
            Call it when a gadget (chain) is not needed anymore, to prevent memory leaks\n
            NOTE: does not remove anything from eq_g
        '''
        
        for i in range(self.get_gadget_cnt()):
            for addr in self.addrs[i]:
                Stack_view.del_id(addr)

        for stack_elem in self.stack.elements:
            if stack_elem.type == "64b_stack_val":
                Stack_view.del_id(stack_elem.info["id"])

        self.b = None
        self.effects = None
        self.stack = None

        self.end_sp_pos = None

        self.valid_jump = None
        self.valid_stack_access = None

    def join(self, snd: ROP_chain | ROP_chain) -> ROP_chain:
        '''
            Join two gadgets (chains)
        '''

        fst_cpy: ROP_chain
        res_chain, fst_cpy, snd_cpy = ROP_chain._join_ef_stk(self, snd)

        if res_chain is None:
            return None
        
        if type(snd) == ROP_chain:

            res_chain.b = fst_cpy.b + snd_cpy.b

            res_chain.addrs = fst_cpy.addrs + snd_cpy.addrs
            res_chain.eq_g = fst_cpy.eq_g + snd_cpy.eq_g

        else:

            res_chain.b = fst_cpy.b
            res_chain.b.append(snd_cpy.b)
            res_chain.addrs = fst_cpy.addrs
            res_chain.addrs.append(snd_cpy.addrs)
            res_chain.eq_g = fst_cpy.eq_g
            res_chain.eq_g.append(snd_cpy.eq_g)

        return res_chain
    
    def _make_payload(self, max_stack_size: int, forbidden_bytes: List[bytes] = [], 
                        addr_offset: int = 0, pad_sequence = b'A', last_jump: bytes = b'\x00' * 8) -> bytes:
        '''
            Internal method that builds the payload for this chain
        '''

        if self.valid_jump is not True or self.valid_stack_access is not True:
            raise RuntimeError(f"cannot build payload for an invalid chain: {self}")

        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in forbidden_bytes:
                    return False

            return True

        jmp_addrs = {}
        # jump addresses for each gadget's jump

        # yield every jump address combinations
        # (more of them might be needed due to forbidden bytes
        #   either in the addresses themselves, or in the resulted payload)
        def _get_jmp_addrs():
            
            jmp_addrs_ids = [jid for jid in jmp_addrs.keys()]
            for i in range(len(jmp_addrs_ids)):
                assert(i == jmp_addrs_ids[i] - 1)

            def _get_addrs(arr):

                if len(arr) == 0:
                    yield []

                else:

                    for addr in jmp_addrs[arr[0]]:
                        for suffix in _get_addrs(arr[1:]):

                            yield [addr] + suffix

            try:
                for y in _get_addrs(jmp_addrs_ids):
                    yield [None] + y    # jump ids begin from 1, list from 0, 
                                        # so the first None is for index alignment

            except StopIteration:
                return None

        def _fix_jmp_addr(g: ROP_gadget | ROP_chain, jmp_ef: Effect,
                            jmp_addr: int, jmp_id: int):

            jmp_stack_ids = set()

            free_stack_elements = {}
            reg_in_elements = {}

            # in case of stack assignments, z3 solver is used
            z3_solver = z3.Solver()
            
            # function that folds over the ARITH expression tree 
            # and updates the z3 solver
            _aux_id = 0
            def _convert_to_z3_expr(el: Structured_element):
                
                nonlocal _aux_id

                if el.type == "64b_stack_val":

                    if el.info["id"] in jmp_stack_ids:
                        return z3.BitVec(f"stack{el.info['id']}", 64)

                    val = Stack_view.stack_values[el.info["id"]]
                    if val is None:
                        val = free_stack_elements[el.info["id"]]

                    conv_el = z3.BitVec(f"c{_aux_id}", 64)
                    _aux_id += 1
                    z3_solver.add(conv_el == val)

                    return conv_el

                else:

                    conv_el = z3.BitVec(f"c{_aux_id}", 64)
                    _aux_id += 1
                    
                    if el.type == "ct_val":
                        z3_solver.add(conv_el == el.info["value"])

                    elif el.type == "reg_in":
                        z3_solver.add(conv_el == reg_in_elements[el.info["reg_name"]])

                    elif el.type == "neg":
                        
                        t = _convert_to_z3_expr(el.info["term_1"])
                        z3_solver.add(conv_el == ~t)

                    elif el.is_op():

                        t1 = _convert_to_z3_expr(el.info["term_1"])
                        t2 = _convert_to_z3_expr(el.info["term_2"])

                        if el.type == "add":
                            z3_solver.add(conv_el == t1 + t2)

                        elif el.type == "sub":
                            z3_solver.add(conv_el == t1 - t2)

                        elif el.type == "and":
                            z3_solver.add(conv_el == t1 & t2)

                        elif el.type == "or":
                            z3_solver.add(conv_el == t1 | t2)

                        elif el.type == "xor":
                            z3_solver.add(conv_el == t1 ^ t2)

                        elif el.type == "mul":
                            z3_solver.add(conv_el == t1 * t2)

                        elif el.type == "lsh":
                            z3_solver.add(conv_el == t1 << t2)

                        elif el.type == "rsh":
                            z3_solver.add(conv_el == z3.LShR(t1, t2))

                    return conv_el

            def _check_stack_elements(el: Structured_element):

                if el is None:
                    return False

                if el.type == "64b_stack_val":
                    
                    val = Stack_view.stack_values[el.info["id"]]
                    jmp = Stack_view.related_jump[el.info["id"]]
                    
                    if jmp is not None:
                        
                        if jmp == jmp_id:

                            if val is None:

                                jmp_stack_ids.add(el.info["id"])
                                return True

                            else:
                                raise RuntimeError("Unexpected jump stack element != None when building payload")

                        return False

                    else:

                        if val is None:
                            free_stack_elements.update({el.info["id"]: None})

                        return False

                elif el.type == "reg_in":

                    reg_in_elements.update({el.info["reg_name"]: None})
                    return False

                elif el.type == "ct_val":
                    return False

                elif el.is_op():

                    checked_1 = _check_stack_elements(el.info["term_1"])
                    checked_2 = _check_stack_elements(el.info["term_2"])

                    return checked_1 or checked_2

                elif el.type == "deref":
                    raise Exception("deref found while matching arith")

                raise RuntimeError(f"unknown element type {el.type} when building payload")

            jmp_stack_elements_found = _check_stack_elements(jmp_ef.params[0])

            if jmp_stack_elements_found is False:
                raise RuntimeError("Could not find jump associated stack element when building payload")

            for _ in range(Effect.ARITH_P_TEST_CNT):

                for reg_in in reg_in_elements.keys():
                    reg_in_elements[reg_in] = random.randint(0, 2 ** 64)

                for s_id in free_stack_elements.keys():
                    free_stack_elements[s_id] = random.randint(0, 2 ** 64)

                z3_expr = _convert_to_z3_expr(jmp_ef.params[0])
                z3_solver.add(z3_expr == jmp_addr)

            if z3_solver.check() == z3.sat:

                sm = z3_solver.model()
                for stack_elem_id in jmp_stack_ids:

                    z3_stack_elem = z3.BitVec(f"stack{stack_elem_id}", 64)
                    val = sm[z3_stack_elem]

                    if val is not None:
                        Stack_view.stack_values[stack_elem_id] = val.as_long()

                return True

            else:
                return False
            
        # fix jump addresses

        for ef in self.effects:
            if ef.type == "JUMP":

                jmp_id = ef.destination_element.info["value"]
                if jmp_id is None or jmp_id < 1:
                    raise RuntimeError(f"Unexpected jump id {jmp_id} when building payload")
                
                if jmp_id < len(self.addrs):
                    jmp_addrs[jmp_id] = [Stack_view.stack_values[addr] for addr in self.addrs[jmp_id]]

                elif jmp_id > len(self.addrs):
                    raise RuntimeError(f"Unexpected jump id {jmp_id}, len(self.addrs) == {len(self.addrs)}")

        jmp_addrs[len(self.addrs)] = [last_jump]

        # determine the entry address for this chain
        entry_addr = None
        for addr_ in self.addrs[0]:

            addr = Stack_view.stack_values[addr_] + addr_offset

            if _check_bytes(to_bytes(addr)) is True:
                entry_addr = addr
                break

        if entry_addr is None:
            return None, None

        payload = b''
        
        payload_ok = True
        for addrs in _get_jmp_addrs():

            payload = b''

            self_fixed, _ = self.duplicate()

            for ef in self_fixed.effects:
                if ef.type == "JUMP":

                    jmp_id = ef.destination_element.info["value"]
                    to_fix_addr = addrs[jmp_id] + addr_offset

                    if _check_bytes(to_bytes(to_fix_addr)) is False:
                        payload_ok = False
                        break

                    payload_ok = _fix_jmp_addr(self_fixed, ef, to_fix_addr, jmp_id)

            if payload_ok is False:
                self_fixed.remove_stack_ids()
                continue
        
            for max_s_idx in range(len(self_fixed.stack.elements) - 1, -1, -1):

                elem = self_fixed.stack.elements[max_s_idx]
                if elem.type == "64b_stack_val" and \
                    Stack_view.stack_values[elem.info["id"]] is not None:

                    break
                
            for idx, el in enumerate(self_fixed.stack.elements):

                if idx > max_s_idx:
                    break

                if el.type == "64b_stack_pad":
                    payload += (pad_sequence * 8)[:8]

                elif el.type == "64b_stack_val":
                    
                    val = Stack_view.stack_values[el.info["id"]]
                    if val is None:
                        val = (pad_sequence * 8)[:8]
                    else:
                        val = to_bytes(val)

                        if _check_bytes(val) is False:
                            payload_ok = False
                            self_fixed.remove_stack_ids()
                            break

                    payload += val

                else:
                    raise RuntimeError(f"Unexpected stack element type {el.type} when building payload")

            if len(payload) > max_stack_size:
                payload_ok = False
                self_fixed.remove_stack_ids()
                break

            if payload_ok is True:
                break

        if payload_ok is False:
            return None, None

        if len(payload) % 8 != 0:
            raise RuntimeError(f"Payload is not 8-byte aligned (length: {len(payload)})")
                        
        return payload, entry_addr

    # TODO use it to redesign make payload or remove
    def _oldx86_make_payload(self, max_stack_size: int, forbidden_bytes: List[bytes] = [], 
                                addr_offset: int = 0, pad_sequence = b'A') -> bytes:
        '''
            Internal method that builds the payload for this chain
        '''
        
        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in forbidden_bytes:
                    return False

            return True

        payload = b''

        for i in range(self.get_gadget_cnt()):

            found = False

            stack_offset = self.gadgets_stackview_offset[i]

            stack_end = 0
            if i == self.get_gadget_cnt() - 1:
                stack_end = len(self.stack.elements)
            else:
                stack_end = self.gadgets_stackview_offset[i + 1]

            stacks = [self.stack.elements[stack_offset: stack_end]] + [g.stack.elements for g in self.eq_g[i]]
            addrs = [self.addrs[i]] + [g.addrs for g in self.eq_g[i]]

            for j in range(len(stacks)):
                if len(stacks[j]) <= max_stack_size:

                    for k in range(len(addrs[j])):
                        
                        b_addr = to_bytes(Stack_view.stack_values[addrs[j][k]] + addr_offset)

                        if _check_bytes(b_addr) is True:

                            payload += b_addr
                            
                            found = True
                            for el in stacks[j][:-1]:

                                if el.type == "64b_stack_pad":
                                    payload += (pad_sequence * 8)[:8]

                                elif el.type == "64b_stack_val":
                                    
                                    val = Stack_view.stack_values[el.info["id"]]

                                    if val is None:
                                        payload += (pad_sequence * 8)[:8]
                                        continue
                                
                                    b = to_bytes(val)
                                    if _check_bytes(b) is True:
                                        payload += b
                                    else:
                                        return None     # stacks differ only by padding, so if a forbidden byte is found, 
                                                        # it is clear that there is no way of constructing the payload

                            max_stack_size -= len(stacks[j])
                            
                            if found is True:
                                break

                if found is True:
                    break

            if found is False:
                return None

        if len(payload) % 8 != 0:
            raise RuntimeError(f"Payload is not 8-byte aligned (length: {len(payload)})")
                        
        return payload

    # mostly for debugging purposes
    def __str__(self):
        return f"ROP chain with stack {self.stack}, addresses are {'TODO'}, effects {[str(ef) for ef in self.effects]}"

class ROP_searcher:
    '''
        Internal class that implements the search algorithms
    '''

    def __init__(self, filepath: str, platform: Platform, logger: Logger):

        def _find_endpoint_offsets():

            def _find_endpoint_offsets_arm():

                end_offsets = []

                for i in range(len(self.exec_bytes)):
                    
                    xc_offset, xc = self.exec_bytes[i]

                    idx_ = 0

                    self.capstone.skipdata = True
                    disas = self.capstone.disasm(xc, 0)
                    for instr in disas:
                        
                        if instr.mnemonic in platform.ENDPOINTS:
                            end_offsets.append((i, xc_offset + idx_, 4))

                        idx_ += 4

                self.capstone.skipdata = False
                return end_offsets

            def _find_endpoint_offsets_x86():

                jmp_2byte_opcodes = {b"\xff\xe0", b"\xff\xe1", b"\xff\xe2", b"\xff\xe3", b"\xff\xe5", b"\xff\xe6", b"\xff\xe7"}
                jmp_3byte_opcodes = {b"\x41\xff\xe0", b"\x41\xff\xe1", b"\x41\xff\xe2", b"\x41\xff\xe3", b"\x41\xff\xe4", 
                                        b"\x41\xff\xe5", b"\x41\xff\xe6", b"\x41\xff\xe7"}
                
                end_offsets = []

                for i in range(len(self.exec_bytes)):
                    
                    xc_offset, xc = self.exec_bytes[i]
                    for ib in range(len(xc)):

                        if xc[ib: ib + 1] == b'\xc3':
                            end_offsets.append((i, xc_offset + ib, 1))

                        elif xc[ib: ib + 1] == b'\xff' and xc[ib: ib + 2] in jmp_2byte_opcodes:
                            end_offsets.append((i, xc_offset + ib, 2))

                        elif xc[ib: ib + 1] == b'\x41' and xc[ib: ib + 3] in jmp_3byte_opcodes:
                            end_offsets.append((i, xc_offset + ib, 3))

                return end_offsets

            if platform is Platform.X86_64:
                return _find_endpoint_offsets_x86()

            elif platform is self.platform:
                return _find_endpoint_offsets_arm()

        self.platform = platform

        self.logger = logger

        self.exec_bytes = Elf_util(filepath).load_x_bytes()

        if self.platform is Platform.ARM64:
            self.capstone = Cs(CS_ARCH_ARM64, CS_MODE_ARM)

        elif self.platform is Platform.X86_64:
            self.capstone = Cs(CS_ARCH_X86, CS_MODE_64)

        # constant, can be changed, but 3 is the maximum recommended value
        self.BRUTEFORCE_DEPTH = 2

        self.endpoint_offsets: List[Tuple[int, int, int]] = _find_endpoint_offsets()

        self.raw_gadgets: Set[ROP_gadget] = set()
        self.raw_effects_to_gadgets: Dict[str, Dict[str, List[ROP_chain]]] = \
            {
                ef_t: 
                {
                    reg: [] 
                    for reg in self.platform.SUPPORTED_REGS
                } 
                for ef_t in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]
            }

        if self.platform is Platform.X86_64:
            self.retonly_gadget = ROP_gadget()
            '''
                Gadget used for padding\n
                Currently unimplemented for ARM64
            '''

        self.gadgets: Set[ROP_chain] = set()
        self.effects_to_gadgets: Dict[str, Dict[str, List[ROP_chain]]] = \
            {
                ef_t: 
                {
                    reg: [] 
                    for reg in self.platform.SUPPORTED_REGS
                } 
                for ef_t in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]
            }

        self.trans_register_graph = None
        self.path_from = None

        if self.platform is Platform.ARM64:
            self.stack_pointer_name = "sp"

        elif self.platform is Platform.X86_64:
            self.stack_pointer_name = "rsp"

    def find_gadgets(self):

        '''
            dict to help identify gadget duplicates
            helps identify gadgets that differ only by ignored instructions
        '''
        opstr_to_gadgets: Dict[str, Tuple[ROP_gadget, bool]] = {}

        '''
            helps identify gadgets that are identical
        '''
        bytes_to_gadgets: Dict[str, Tuple[ROP_gadget, bool]] = {}

        def _get_opstr(b_instr: bytes):

            opstr = ''
            
            for instr in self.capstone.disasm(b_instr, 0):

                if instr.mnemonic in self.platform.IGNORED_INSTR_MNEMONICS or \
                    instr.mnemonic == "nop": 

                    continue

                opstr += instr.mnemonic
                opstr += instr.op_str

            return opstr

        def _stack_id_sync(g: ROP_gadget, eg: ROP_gadget):
            
            s_g = g.stack.elements
            s_eg = eg.stack.elements

            i = 0
            j = 0
            while (i < len(s_g)) and (j < len(s_eg)):

                while (i < len(s_g)) and (s_g[i].type == "64b_stack_pad"):
                    i += 1

                while (j < len(s_eg)) and (s_eg[j].type == "64b_stack_pad"):
                    j += 1

                if i == len(s_g):
                    assert(j == len(s_eg))

                if (i < len(s_g)) and (j < len(s_eg)):

                    Stack_view.del_id(s_eg[j].info["id"])
                    s_eg[j] = s_g[i]

                    i += 1
                    j += 1

                if i == len(s_g):
                    assert(j == len(s_eg))
        
        if self.platform is Platform.X86_64:

            '''
                Initialize the ret-only gadget
                further on, this gadget will be populated
                with the addresses of all ret instructions
            '''

            self.retonly_gadget.stack.push(Structured_element.instantiate_structured_element("64b_stack_val"))
            self.retonly_gadget.stack.elements[0].info["id"] = Stack_view.get_elem_id()
            self.retonly_gadget.b = b'\xc3'

        '''
            Used to check in constant time if the basse address
            of a current gadget candidate actually steps over another gadget
        '''
        endpoint_onlyoffsets = set(r[1] for r in self.endpoint_offsets)

        if self.platform is Platform.X86_64:
            neg_offset_dx = 1

        elif self.platform is Platform.ARM64:
            neg_offset_dx = 4

        else:
            raise RuntimeError(f"Requested platform {self.platform} unknown or not supported")

        for xc_index, endg_offset, endpoint_len in self.endpoint_offsets: 
            
            # for ARM64,
            #
            # -4k                        0           +4
            # |........|........|...  ...|    jump    |
            # g                     endpoint off
            #
            #
            # for x86_64, analogous

            if self.platform is Platform.X86_64 and endpoint_len == 1:
                self.retonly_gadget.add_current_addr(endg_offset)

            neg_offset = neg_offset_dx
            while (endg_offset - neg_offset >= 0) and ((endg_offset - neg_offset) not in endpoint_onlyoffsets):

                b_vaddr = self.exec_bytes[xc_index][0]
                b_instr = self.exec_bytes[xc_index][1][endg_offset - neg_offset - b_vaddr: endg_offset - b_vaddr + endpoint_len]

                stop = False

                if b_instr in bytes_to_gadgets.keys():
                    
                    # if prev gadget is also valid
                    if bytes_to_gadgets[b_instr][1] is True:
                        bytes_to_gadgets[b_instr][0].add_current_addr(endg_offset - neg_offset)

                else:
                    
                    opstr = _get_opstr(b_instr)
                    if (opstr not in opstr_to_gadgets.keys()) or (opstr_to_gadgets[opstr][1] is True):

                        disas_instr_generator = self.capstone.disasm(b_instr, endg_offset - neg_offset)
                        g, stop = self.create_gadget(disas_instr_generator, b_instr, endg_offset - neg_offset)
                        
                        if (g is not None) and (len(g.effects) > 0):
                                
                            bytes_to_gadgets.update({b_instr: (g, True)})

                            if opstr in opstr_to_gadgets.keys():
                                opstr_to_gadgets[opstr][0].eq_g.append(g)

                            else:
                                opstr_to_gadgets.update({opstr: (g, True)})

                                for ef in g.effects:
                                
                                    if ef.type != "JUMP" and ef.destination_element.info["reg_name"] != self.stack_pointer:
                                        self.raw_effects_to_gadgets[ef.type][ef.destination_element.info["reg_name"]].append(g)

                                self.raw_gadgets.add(g)

                        else:
                            bytes_to_gadgets.update({b_instr: (None, False)})
                            opstr_to_gadgets.update({opstr: (None, False)})

                if stop is True:
                    break
                    
                neg_offset += neg_offset_dx

        for g in self.raw_gadgets:
            for eg in g.eq_g:

                assert(len(g.effects) == len(eg.effects))
                _stack_id_sync(g, eg)
  
        for ef in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]:
            for reg in self.platform.SUPPORTED_REGS:
                self.raw_effects_to_gadgets[ef][reg].sort(key = lambda g: len(g.stack.elements))

    def create_gadget(self, instr_generator: Generator[CsInsn, None, None], b_instr: bytes, addr: int = None) -> Tuple[ROP_gadget, bool]:
        '''
            Main (internal) method to create gadgets from raw bytes
        '''

        def _gadget_end_arm(instr: CsInsn):
            return instr.mnemonic in self.platform.ENDPOINTS

        def _gadget_end_x86(instr: CsInsn):
            return (instr.mnemonic == "ret" and len(instr.op_str) == 0) \
                    or instr.mnemonic == "jmp"

        if len(b_instr) > ROP_gadget.MAX_GADGET_BYTE_LEN:
            return None, True

        effects_per_instruction: List[List[Effect]] = []

        if self.platform is Platform.ARM64:

            _gadget_end = _gadget_end_arm
            _stop_flag = True
        
        elif self.platform is Platform.X86_64:

            _gadget_end = _gadget_end_x86
            _stop_flag = False
            
        else:
            raise RuntimeError(f"Requested platform {self.platform} unknown or not supported")

        ends_correctly = False
        for instr in instr_generator:

            instr_effects = Effect.analyse_instr(instr)
            if instr_effects is None:
                return None, _stop_flag

            effects_per_instruction.append(instr_effects)

            if _gadget_end(instr) is True:
                ends_correctly = True      
                break
        
        if ends_correctly is False:
            return None, _stop_flag

        new_stack, new_effects, valid_stack_access, valid_jump, end_sp_pos, unres_derefs = \
            Effect.join_instr_effects(effects_per_instruction)

        if new_stack is None:
            return None, False

        candidate_gadget = ROP_gadget()
        candidate_gadget.stack = new_stack
        candidate_gadget.effects = new_effects

        candidate_gadget.valid_stack_access = valid_stack_access
        candidate_gadget.valid_jump = valid_jump

        candidate_gadget.end_sp_pos = end_sp_pos

        candidate_gadget.unresolved_derefs = unres_derefs

        candidate_gadget.add_current_addr(addr)
        candidate_gadget.b = b_instr

        return candidate_gadget, False

    # DEBUG-only?
    def valid_stats(self):

        valid_jmp_cnt = 0
        valid_acc_cnt = 0
        valid_cnt = 0
        valid_only_jmp_cnt = 0
        valid_only_acc_cnt = 0
        full_invalid_cnt = 0

        for g in self.raw_gadgets:

            if g.valid_jump is True:
                valid_jmp_cnt += 1
            if g.valid_stack_access is True:
                valid_acc_cnt += 1
            if g.valid_jump is True and g.valid_stack_access is True:
                valid_cnt += 1
            if g.valid_jump is True and g.valid_stack_access is False:
                valid_only_jmp_cnt += 1
            if g.valid_jump is False and g.valid_stack_access is True:
                valid_only_acc_cnt += 1
            if g.valid_jump is False and g.valid_stack_access is False:
                full_invalid_cnt += 1

            assert(g.valid_jump in [True, False])
            assert(g.valid_stack_access in [True, False])
            assert(g.end_sp_pos % 2 == 0)

        assert(valid_only_acc_cnt + valid_only_jmp_cnt + \
                valid_cnt + full_invalid_cnt == len(self.raw_gadgets))

        print(" ----> stats from self.raw_gadgets:")
        print(f"\ntotal gadgets {len(self.raw_gadgets)}, full valid {valid_cnt}, " + \
                f"valid jump {valid_jmp_cnt}, " + \
                f"valid stack access {valid_acc_cnt}, " + \
                f"valid jump only {valid_only_jmp_cnt}, " + \
                f"valid stack access only {valid_only_acc_cnt}, " + \
                f"full invalid {valid_only_jmp_cnt}\n")

        for g in self.gadgets:
            assert(g.valid_jump is True)
            assert(g.valid_stack_access is True)

        print(" ----> stats from self.gadgets:")
        print(f"\nvalid gadgets (and chains): {len(self.gadgets)}\n")

    def validate_raw_gadgets(self, q0 = 1, q1 = 1):
        '''Method that filters the valid gadgets from invalid gadgets
            and also tries to validate some of the invalid ones.
            It is the implementation of the algortihm described in 
            documentation in section "Gadget validation"'''

        # returns ok_to_advertise, contains_sp (both bool)
        # used for both stack access validation, and jump validation
        def _advertisement_check(elem: Structured_element):

            if elem is None:
                return True, False

            if elem.type == "reg_in":

                if elem.info["reg_name"] == self.stack_pointer:
                    return True, True

                return False, False

            if elem.type == "ct_val":
                return True, False

            if elem.type == "64b_stack_val":
                return True, False

            if elem.type == "deref":
                raise Exception("deref found in a supposedly valid gadget / chain")

            if elem.is_op():
                
                l1, l2 = _advertisement_check(elem.info["term_1"])
                r1, r2 = _advertisement_check(elem.info["term_2"])

                return l1 and r1, l2 or r2

            raise Exception(f"unexpected element {elem}")

        def _extract_stk_requests(elem: Structured_element, regs: list, inside_deref: bool):

            if elem is None:
                return
        
            if elem.type == "reg_in" and elem.info["reg_name"] != self.stack_pointer:
                
                if inside_deref is True and elem.info["reg_name"] not in regs:
                    regs.append(elem.info["reg_name"])

            elif elem.is_op():
                _extract_stk_requests(elem.info["term_1"], regs, inside_deref)
                _extract_stk_requests(elem.info["term_2"], regs, inside_deref)

            elif elem.type == "deref":
                
                # even if gadget is invalid, nested derefs are not expected
                # because the gadget has already been checked at join instr
                if inside_deref is True:
                    raise Exception("nested deref")

                _extract_stk_requests(elem.info["expr"], regs, True)

        def _extract_jmp_requests(elem: Structured_element, regs: list):

            if elem is None:
                return
        
            if elem.type == "reg_in" and elem.info["reg_name"] not in regs:
                regs.append(elem.info["reg_name"])

            elif elem.is_op():
                _extract_jmp_requests(elem.info["term_1"], regs)
                _extract_jmp_requests(elem.info["term_2"], regs)

            elif elem.type == "deref":
                raise Exception("unexpected deref inside JUMP expression")

        # step 1)
        # filter out valid from invalid

        valid = []
        invalid = []
        for g in self.raw_gadgets:

            if g.valid_jump is True and g.valid_stack_access is True:
                valid.append(g)
            elif g.valid_stack_access is False:
                invalid.append(g)
        
        # step 2) 
        # try to validate stack access

        valid_stack_acc_only = []
        # stack acc valid, jump invalid

        replace_reg_dict = {reg: [[], [], set(), set()] for reg in (self.platform.SUPPORTED_REGS + [self.stack_pointer])}
        # {reg: [
        #        [list of gadgets whose effect with dest elem == reg does not contain other reg_in arguments),
        #        [list of gadgets whose effect with dest elem == reg does not contain other reg_in arguments, 
        #           but contain SP),
        #        (set of elements from the first list),
        #        (set of elements from the second list)
        #       ]
        # }
        # list is used to be able to execute random.choice()
        # set is used to be able to check for existence in constant time

        # NOTE that some gadgets / chains might actually require less registers to be replaced
        #       for example, Xt <- [SP + 8 + (reg & 0)] does not require reg to be replaced
        #       to have a valid stack access 
        #       still, taking into account these kind of cases require greatly increasing the complexity
        #       of the code, for very little gain
        #       so this kind of "optimizations" are not implemented

        iv_to_requests = {iv: [] for iv in invalid}
        # {invalid gadget: [regs to replace]}

        iv_to_tested = {iv: set() for iv in invalid}
        # {invalid gadget: set((g0, g1, ...), ...)}
        # contains ordered join combinations for the current invalid gadget
        # that were previously tried

        # loop through invalid gadgets 
        # and populate iv_to_requests
        for iv in invalid:

            for ef in iv.effects:
                if ef.type in ["ARITH", "JUMP", "LOAD_S"]:
                    _extract_stk_requests(ef.params[0], iv_to_requests[iv], False)

            for deref_el in iv.unresolved_derefs:
                _extract_stk_requests(deref_el.info["expr"], iv_to_requests[iv], True)

        # generator that tries to yield unbiased sequences 
        # of valid gadgets (or chains) that (hopefully, will) satisfy requests
        # for a specific invalid gadget
        # (round robin + random and fisher-yates)
        # NOTE: currently, only one stack pointer replacement is preferred
        #       this is done to avoid unnecessary checks for validity in situations
        #       like Xt <- [SP + SP << 8] or Xt <- [SP * SP] and so on
        def _serve_stk_request(iv: ROP_gadget):

            reqs = iv_to_requests[iv]

            if len(reqs) == 0:
                while True:
                    yield []

            MAX_CONSECUTIVE_FAILS = 3
            consecutive_fails = 0

            while True:

                # select which reg is to be replaced with an expression containing sp

                sp_choice_idx = 0
                while len(replace_reg_dict[reqs[sp_choice_idx]][1]) == 0:
                    
                    sp_choice_idx += 1
                    sp_choice_idx %= len(reqs)

                sp_choice_reg = reqs[sp_choice_idx]

                # select the rest of the replacements

                seq: List[ROP_chain | ROP_gadget] = []
                seq.append(random.choice(replace_reg_dict[sp_choice_reg][1]))

                for req in reqs:

                    if req == sp_choice_reg:
                        continue 

                    # len(seq) <= len(reqs) which is (very) small, 
                    # so a for in a for is not a problem
                    
                    already_chosen = False
                    for chosen in seq:

                        if chosen in replace_reg_dict[req][3] or \
                            chosen in replace_reg_dict[req][2]:

                            already_chosen = True
                            break

                    if already_chosen is True:
                        continue

                    if len(replace_reg_dict[req][0]) == 0:
                        seq.append(random.choice(replace_reg_dict[req][1]))
                    else:
                        seq.append(random.choice(replace_reg_dict[req][0]))

                # check stack size limits

                stack_size = 0
                for v in seq:
                    stack_size += v.get_stack_size()

                if stack_size > Effect.VALIDATION_SEARCH_MAX_STACK_SIZE:

                    consecutive_fails += 1
                    if consecutive_fails > MAX_CONSECUTIVE_FAILS:
                        return None

                    continue

                # randomize joining order

                for i in range(len(seq) - 1):
                    j = random.randint(i, len(seq) - 1)
                    
                    aux = seq[i]
                    seq[i] = seq[j]
                    seq[j] = aux

                # check if it has been tried before

                tseq = tuple(seq)
                if tseq in iv_to_tested[iv]:

                    consecutive_fails += 1
                    if consecutive_fails > MAX_CONSECUTIVE_FAILS:
                        return None

                    continue
                
                consecutive_fails = 0

                iv_to_tested[iv].add(tseq)
                yield seq

        serve_request = {iv: _serve_stk_request(iv) for iv in invalid}
        # dictionary that contains _serve_request() generators

        # yield (at most) q elements
        def serve_request_q(iv: ROP_gadget, q):
            
            try:

                for _ in range(q):
                    yield next(serve_request[iv])

            except StopIteration:
                return None

        # the gs / chs in this set were already tested for advertisement
        # (only for optimization purposes)
        already_advertised = set()

        new_validated = 1
        while new_validated > 0:

            new_validated = 0

            # loop through valid gadgets / chains, to "advertise" their effects
            for v in valid:
                if v not in already_advertised:

                    for ef in v.effects:
                        if ef.type in ["LOAD_CT", "LOAD_S", "MOV_RR", "ARITH"]:

                            ok_to_advertise, contains_sp = _advertisement_check(ef.params[0])
                            if ok_to_advertise is True:
                                
                                if contains_sp is False:
                                    replace_reg_dict[ef.destination_element.info["reg_name"]][0].append(v)
                                    replace_reg_dict[ef.destination_element.info["reg_name"]][2].add(v)
                                else:
                                    replace_reg_dict[ef.destination_element.info["reg_name"]][1].append(v)
                                    replace_reg_dict[ef.destination_element.info["reg_name"]][3].add(v)

                    already_advertised.add(v)

            # loop through invalid gadgets, try to join with valid gadgets / chains
            iv: ROP_gadget
            validated_idx = set()
            for iv_idx, iv in enumerate(invalid):

                # check if registers can be replaced
                
                replaceable = True
                replaceable_w_sp = False
                
                reqs = iv_to_requests[iv]   
                for req in reqs:

                    if len(replace_reg_dict[req][0]) == 0 and \
                        len(replace_reg_dict[req][1]) == 0:

                        replaceable = False
                        break

                    if len(replace_reg_dict[req][1]) > 0:
                        replaceable_w_sp = True

                if replaceable is False or \
                    replaceable_w_sp is False:

                    continue

                # try to replace regs
                
                seq: List[ROP_gadget | ROP_chain]
                for seq in serve_request_q(iv, q0):
                    
                    if seq is None:
                        break

                    if len(seq) == 0:
                        raise Exception("unexpected len(seq) == 0")

                    candidate_ch = ROP_chain.convert(seq[0].duplicate()[0])
                    for v in seq[1:]:

                        candidate_ch_aux = candidate_ch.join(ROP_chain.convert(v))

                        if candidate_ch_aux is None:
                            candidate_ch = None
                            break

                        candidate_ch.remove_stack_ids()
                        candidate_ch = candidate_ch_aux

                    if candidate_ch is None:
                        continue

                    iv_aux = ROP_chain.convert(iv.duplicate()[0])
                    candidate_ch_aux = candidate_ch.join(iv_aux)

                    if candidate_ch_aux is not None:
                        candidate_ch.remove_stack_ids()

                    candidate_ch = candidate_ch_aux

                    if candidate_ch is None:
                        continue

                    # validity of stack access and jumps have already been recalculated
                    # inside joins
                    
                    # outcome of validity results

                    if candidate_ch.valid_stack_access is True:

                        # assert(len(candidate_ch.unresolved_derefs) == 0)

                        if candidate_ch.valid_jump is True:

                            new_validated += 1
                            valid.append(candidate_ch)

                        elif candidate_ch.valid_jump is False:
                            valid_stack_acc_only.append(candidate_ch)

                        # we are satisfied with at least one validation
                        # per invalid gadget
                        # (to avoid an explosion in the number of new chains)
                        validated_idx.add(iv_idx)

                    else:
                        candidate_ch.remove_stack_ids()

            # eliminate invalid gadgets that participate in at least
            # one newly built valid chain
            old_invalid = invalid
            invalid = []

            for iv_idx in range(len(old_invalid)):

                if iv_idx not in validated_idx:
                    invalid.append(old_invalid[iv_idx])

        # step 3) 
        # try to validate jumps
        # (analogous with step 2, but without treating sp separately)
        
        # actualize invalid (stack acc valid, jump invalid)
        invalid = valid_stack_acc_only
        for g in self.raw_gadgets:

            if g.valid_stack_access is True and g.valid_jump is False:
                invalid.append(g)

        replace_reg_dict = {reg: [[], set()] for reg in self.platform.SUPPORTED_REGS}
        # {reg: [
        #        [list of gadgets whose effect with dest elem == reg does not contain other reg_in arguments),
        #        (set of elements from the previous list)
        #       ]
        # }

        iv_to_requests = {iv: [] for iv in invalid}
        # {invalid gadget: [regs to replace]}

        iv_to_tested = {iv: set() for iv in invalid}
        # {invalid gadget: set((g0, g1, ...), ...)}
        # contains ordered join combinations for the current invalid gadget
        # that were previously tried

        # loop through invalid gadgets 
        # and populate iv_to_requests
        for iv in invalid:

            for ef in iv.effects:
                if ef.type == "JUMP":
                    _extract_jmp_requests(ef.params[0], iv_to_requests[iv])

        # almost the same as the "validate stack access" version
        def _serve_jmp_request(iv: ROP_gadget):

            reqs = iv_to_requests[iv]

            if len(reqs) == 0:
                while True:
                    yield []

            MAX_CONSECUTIVE_FAILS = 3
            consecutive_fails = 0

            while True:

                # select the replacements

                seq: List[ROP_chain | ROP_gadget] = []
                for req in reqs:
                    
                    already_chosen = False
                    for chosen in seq:

                        if chosen in replace_reg_dict[req][1]:

                            already_chosen = True
                            break

                    if already_chosen is True:
                        continue

                    seq.append(random.choice(replace_reg_dict[req][0]))

                # check stack size limits

                stack_size = 0
                for v in seq:
                    stack_size += v.get_stack_size()

                if stack_size > Effect.VALIDATION_SEARCH_MAX_STACK_SIZE:

                    consecutive_fails += 1
                    if consecutive_fails > MAX_CONSECUTIVE_FAILS:
                        return None

                    continue

                # randomize joining order

                for i in range(len(seq) - 1):
                    j = random.randint(i, len(seq) - 1)
                    
                    aux = seq[i]
                    seq[i] = seq[j]
                    seq[j] = aux

                # check if it has been tried before

                tseq = tuple(seq)
                if tseq in iv_to_tested[iv]:

                    consecutive_fails += 1
                    if consecutive_fails > MAX_CONSECUTIVE_FAILS:
                        return None

                    continue
                
                consecutive_fails = 0

                iv_to_tested[iv].add(tseq)
                yield seq

        serve_request = {iv: _serve_jmp_request(iv) for iv in invalid}

        already_advertised = set()

        new_validated = 1
        while new_validated > 0:

            new_validated = 0

            # loop through valid gadgets / chains, to "advertise" their effects
            for v in valid:
                if v not in already_advertised:

                    for ef in v.effects:
                        if ef.type in ["LOAD_CT", "LOAD_S", "MOV_RR", "ARITH"]:

                            ok_to_advertise, contains_sp = _advertisement_check(ef.params[0])
                            if ok_to_advertise is True and contains_sp is False:
                                
                                replace_reg_dict[ef.destination_element.info["reg_name"]][0].append(v)
                                replace_reg_dict[ef.destination_element.info["reg_name"]][1].add(v)

                    already_advertised.add(v)

            # loop through invalid gadgets, try to join with valid gadgets / chains
            iv: ROP_gadget
            validated_idx = set()
            for iv_idx, iv in enumerate(invalid):

                # check if registers can be replaced
                
                replaceable = True
                
                reqs = iv_to_requests[iv]   

                if len(reqs) == 0:
                    raise Exception("unexpected len(reqs) == 0")

                # sp cannot be replaced by anothing else other than sp + offset
                if self.stack_pointer in reqs:
                    continue

                for req in reqs:

                    if len(replace_reg_dict[req][0]) == 0:

                        replaceable = False
                        break

                if replaceable is False:
                    continue

                # try to replace regs
                
                seq: List[ROP_gadget | ROP_chain]
                for seq in serve_request_q(iv, q1):
                    
                    if seq is None:
                        break

                    if len(seq) == 0:
                        raise Exception("unexpected len(seq) == 0")

                    candidate_ch = ROP_chain.convert(seq[0].duplicate()[0])
                    for v in seq[1:]:

                        candidate_ch_aux = candidate_ch.join(ROP_chain.convert(v))

                        if candidate_ch_aux is None:
                            candidate_ch = None
                            break

                        candidate_ch.remove_stack_ids()
                        candidate_ch = candidate_ch_aux

                    if candidate_ch is None:
                        continue

                    iv_aux = ROP_chain.convert(iv.duplicate()[0])
                    candidate_ch_aux = candidate_ch.join(iv_aux)

                    if candidate_ch_aux is not None:
                        candidate_ch.remove_stack_ids()

                    candidate_ch = candidate_ch_aux

                    if candidate_ch is None:
                        continue
                    
                    # outcome of validity results

                    if candidate_ch.valid_jump is True:

                        if candidate_ch.valid_stack_access is False:
                            raise Exception("unexpected only jump valid gadget")

                        # candidate_ch.show()

                        new_validated += 1
                        valid.append(candidate_ch)

                        # we are satisfied with at least one validation
                        # per invalid gadget
                        # (to avoid an explosion in the number of new chains)
                        validated_idx.add(iv_idx)

                    else:
                        candidate_ch.remove_stack_ids()

            # eliminate invalid gadgets that participate in at least
            # one newly built valid chain
            old_invalid = invalid
            invalid = []

            for iv_idx in range(len(old_invalid)):

                if iv_idx not in validated_idx:
                    invalid.append(old_invalid[iv_idx])
        
        # post-processing the valid gadgets
        # and some sanity checks

        # NOTE: self.gadgets also contains chains, 
        #       but are considered "gadgets" in the sense that these chains
        #       are indivisible and (some of) their individual gadgets are invalid
        self.gadgets = set(valid)

        v: ROP_gadget | ROP_chain
        for v in self.gadgets:

            if v.valid_jump is not True or v.valid_stack_access is not True:
                raise Exception(f"corrupted valid gadged / chain {v}")

            for ef in v.effects:

                if ef.type != "JUMP" and ef.destination_element.info["reg_name"] != self.stack_pointer:
                    self.effects_to_gadgets[ef.type][ef.destination_element.info["reg_name"]].append(v)

                if ef.type == "LOAD_S" and ef.params[0].type != "64b_stack_val":

                    if ef.params[0].is_op():
                        ef.type = "ARITH"
                    else:
                        raise Exception(f"unexpected 'valid' LOAD_S effect: {ef}")

        # FIXME use g.get_stack_size() instead of len(g.stack.elements) ???
        # sorting by used stack size
        for ef in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]:
            for reg in self.platform.SUPPORTED_REGS:
                self.effects_to_gadgets[ef][reg].sort(key = lambda g: len(g.stack.elements))

    def get_trans_reg_graph(self):
        '''
            Method that creates the graph for transitioning a value between registers
            * graph without any fixed register restirction
            * sub-graphs for one fixed register restriction, for each register
            * sub-graphs for pairs or 2 fixed registers, for each possible (ordered) pair\n
            NOTE: it does not support register start values
        '''

        if self.trans_register_graph is not None:
            return self.trans_register_graph, self.path_from

        _t = self.logger.log_info("Transition graph absent from memory. Building transition graph (might take minutes)...", start_timer=True)

        if self.platform is Platform.ARM64:

            '''Changes in x30 values are not completely taken into account
                (i.e. when executing a branch link register operation)'''
            rs = deepcopy(self.platform.SUPPORTED_REGS)
            rs.remove("x30")
            rs.sort()

        elif self.platform is Platform.X86_64:

            rs = deepcopy(Platform.X86_64.SUPPORTED_REGS)
            rs.sort()

        else:
            raise RuntimeError(f"Requested platform {self.platform} unknown or not supported")

        # all possible keys for fixed reg field: none(empty string), registers, or tuples of 2 registers
        all_fixedreg_keys = [""] + \
                            [r for r in rs] + \
                            [(rs[ir1], rs[ir2]) for ir1 in range(len(rs) - 1) for ir2 in range(ir1 + 1, len(rs))]

        # trans_reg_graph[fixed regs][dest][src][list of transition gadgets]
        trans_reg_graph: Dict[str | Tuple[str], Dict[str, Dict[str, List[ROP_gadget]]]] = \
                {
                    fixed:
                    {
                        dest: 
                        {
                            src: [] 
                            for src in rs
                        } 
                        for dest in rs
                    }
                    for fixed in all_fixedreg_keys
                }

        # path_from[fixed regs][dest][src][path exists or not]
        path_from: Dict[str | Tuple[str], Dict[str, Dict[str, bool]]] = \
                {
                    fixed:
                    {
                        dest: 
                        {
                            src: False 
                            for src in rs
                        } 
                        for dest in rs
                    }
                    for fixed in all_fixedreg_keys
                }

        for dest in rs:
            for src in rs:

                if dest == src:

                    for fixed_arg in all_fixedreg_keys:
                        path_from[fixed_arg][dest][src] = True

                    continue

                dest_from_src_ef = Effect.make_mov_rr_effect(dest, src)
                dest_from_src_gadgets = self.filter_gadgets(wanted_effect=dest_from_src_ef, max_stack_size=2 ** 63, 
                                                            reg_start_values=[], max_search_cnt=2 ** 63)
                
                if len(dest_from_src_gadgets) != 0:
                    for fixed_arg in all_fixedreg_keys:
                        
                        if fixed_arg == "":

                            trans_reg_graph[""][dest][src] = dest_from_src_gadgets
                            path_from[""][dest][src] = True

                        elif type(fixed_arg) is str:

                            for g in dest_from_src_gadgets:
                                if g.check_fixed_regs([fixed_arg], mode='fast'):

                                    trans_reg_graph[fixed_arg][dest][src].append(g)
                                    path_from[fixed_arg][dest][src] = True

                        elif type(fixed_arg) is tuple:

                            for g in dest_from_src_gadgets:
                                if g.check_fixed_regs([fixed_arg[0], fixed_arg[1]], mode='fast'):

                                    trans_reg_graph[fixed_arg][dest][src].append(g)
                                    path_from[fixed_arg][dest][src] = True

        # completing path_from (Roy-Warshal) for each subgraph

        for fixed_arg in all_fixedreg_keys:

            for k in rs:
                for i in rs:
                    for j in rs:

                        if (path_from[fixed_arg][i][k] is True) and (path_from[fixed_arg][k][j] is True):
                            path_from[fixed_arg][i][j] = True

        self.trans_register_graph = trans_reg_graph
        self.path_from = path_from

        self.logger.log_success("Transition graph successfully built.", end_timer=_t)

        return trans_reg_graph, path_from

    def transition_chain_generator(self, dest: str, src: str, 
                                    trans_subgraph: Dict[str, Dict[str, List[ROP_gadget]]], 
                                    subgraph_path_from: Dict[str, Dict[str, bool]], max_stack_size: int) -> Tuple[List[ROP_gadget | ROP_chain], int]:
        '''
            Generator that yields all possible transition chains that satisfy the effect dest <- src\n
            The transitions are exclusively based on the transition subgraph given as a parameter\n
            TODO; optimize for shortest path for stack size
        '''

        # auxiliary data structure for the graph traversal
        _visited = set()

        # generator that returns a list of gadgets that compose the transfer path, and the accumulated stack size
        def _path_finder(current_reg: str, mss: int):

            _visited.add(current_reg)

            if current_reg == src:
                yield [], 0
                    
            else:

                for src_reg, gs in trans_subgraph[current_reg].items():
                    if (src_reg not in _visited) and (subgraph_path_from[src_reg][src] is True) and (len(gs) > 0):

                        mss_reached = False

                        for path_suffix, stack_size in _path_finder(src_reg, mss - gs[0].get_stack_size()):
                            for trans_g in gs:
                                
                                tgss = trans_g.get_stack_size()

                                if tgss + stack_size <= mss:
                                    yield [trans_g] + path_suffix, tgss + stack_size
                                else:
                                    mss_reached = True
                                    break
                            
                            # not always true
                            # but helpful to limit 
                            # the number of possibilities
                            if mss_reached is True:
                                break
                    
            _visited.remove(current_reg)

        return _path_finder(dest, max_stack_size)

    @staticmethod
    def _check_if_duplicate(gs: List[ROP_gadget | ROP_chain], b_cache: Dict[bytes, bool]):
        '''
            Auxiliary method that checks whether any "subchain" was previously yielded or not
        '''

        def _chunks(l: List[ROP_gadget | ROP_chain]):
            
            if len(l) == 0:
                return

            if len(l) == 1:
                yield l[0].get_bytes() 
                return

            if len(l) == 2:
                yield l[0].get_bytes()
                yield l[1].get_bytes()
                return

            for i in range(1, len(l)):
                yield b''.join([g.get_bytes() for g in l[:i]])
            yield b''.join([g.get_bytes() for g in l[1:]])

            yield from _chunks(l[1:])

        for subchain_b in _chunks(gs):
            if (subchain_b in b_cache.keys()) and (b_cache[subchain_b] is True):
                return True

        return False

    def search_chain(self, wanted_effects: List[Effect], max_stack_size: int = 2**63, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect] = [], only_gadgets = False) -> List[ROP_chain]:
        '''
            Internal method for searching chains with multiple wanted effects
        '''

        if only_gadgets is False and len(reg_start_values) > 0:
            raise RuntimeError("Register start values feature is only supported for gadget-only search (no chains of 2+ gadgets)")

        if only_gadgets is False and len(wanted_effects) > 1:
            raise RuntimeError("Multiple wanted effects (>1) are only supported for gadget-only search (no chains of 2+ gadgets)")

        b_cache: Dict[bytes, bool] = {}

        if only_gadgets is True:

            def _get_new_id(old_new_id: Dict[int, int], old_id: int):

                if old_id in old_new_id.keys():
                    return old_new_id[old_id]

                return None

            for g in self.search_gadgets(wanted_effect = wanted_effects[0], max_stack_size = max_stack_size, fixed_reg_list = fixed_reg_list,
                                            reg_start_values = reg_start_values, b_cache = b_cache):

                g_cpy, org_to_cpyid = g.duplicate()
                start_values_cpy = deepcopy(reg_start_values)
                g_cpy.effects = Effect.join_effects(start_values_cpy, g_cpy.effects)

                wef_sat = True
                for wef in wanted_effects[1:]:

                    wef_cpy = deepcopy(wef)

                    to_check_effect: Effect = None
                    for ef in g_cpy.effects:

                        if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == wef_cpy.destination_element.info["reg_name"]:
                            to_check_effect = ef
                            break
                    
                    if to_check_effect is None:
                        wef_sat = False
                        break

                    if wef_cpy.match(to_check_effect) is False:
                        wef_sat = False
                        break

                    if g_cpy.check_fixed_regs(fixed_reg_list) is False:
                        wef_sat = False
                        break

                if wef_sat is False:
                    g_cpy.remove_stack_ids()
                    continue

                for org_stack_elem in g.stack.elements:
                    if org_stack_elem.type == "64b_stack_val":

                        cpyid = _get_new_id(org_to_cpyid, org_stack_elem.info["id"])

                        if Stack_view.related_jump[org_stack_elem.info["id"]] != Stack_view.related_jump[cpyid]:
                            raise RuntimeError(f"unexpected different associated jump IDs: {Stack_view.related_jump[org_stack_elem.info['id']]} {Stack_view.related_jump[cpyid]}")

                        if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[cpyid]:

                            if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                raise RuntimeError("original chain and cloned chain non-null values are different")

                            Stack_view.stack_values[org_stack_elem.info["id"]] == Stack_view.stack_values[cpyid]

                g_cpy.remove_stack_ids()

                yield g

        elif len(wanted_effects) == 1:

            wanted_effect = wanted_effects[0]
            
            if max_stack_size < 0:
                return

            yield from self.search_gadgets(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                            reg_start_values=reg_start_values, b_cache=b_cache)
            
            if wanted_effect.type == "LOAD_CT":

                yield from self.search_chain_by_substitution(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                                fixed_reg_list=fixed_reg_list, b_cache=b_cache)

                yield from self.search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                        fixed_reg_list=fixed_reg_list, b_cache=b_cache)

            elif wanted_effect.type == "ARITH":
                
                yield from self.search_chain_by_substitution(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                                fixed_reg_list=fixed_reg_list, b_cache=b_cache)

                yield from self.search_chain_by_substitution_adv(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                                    fixed_reg_list=fixed_reg_list, b_cache=b_cache)

                yield from self.search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                        fixed_reg_list=fixed_reg_list, b_cache=b_cache)

            elif wanted_effect.type == "MOV_RR":

                yield from self.search_mov_chains(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                    fixed_reg_list=fixed_reg_list, b_cache=b_cache)

                yield from self.search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, 
                                                        fixed_reg_list=fixed_reg_list, b_cache=b_cache)

            else:
                raise RuntimeError(f"Unrecognised wanted effect type when searching chains: {wanted_effect.type}")

    def filter_gadgets(self, wanted_effect: Effect, max_stack_size: int = 2**63, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect] = [], max_search_cnt: int = 100) -> List[ROP_gadget]:
        '''
            Internal method for searching gadgets that satisfy a single wanted effect\n
            It is usually pretty fast since it does not attemp at building any kind of chain\n
            Note that, unlike other chain searching implementations, this is a FUNCTION, NOT a GENERATOR
        '''

        # as in duplicate method, represents a map 
        # between the original gadget stack ids and the new gadget stack ids
        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # a gadget can be referenced multiple times in the effects_to_gadgets dictionary
        # (when a gadget has multiple effects)
        # so, once a gadget has been checked, there is no need to check it twice
        tried_gadget_cache = set()

        # main function to try a gadget 
        def _try_gadget(candidate_g: ROP_gadget, wanted_effect: Effect, searched_effect_types: List[str]):
            
            if candidate_g in tried_gadget_cache:
                return None

            if candidate_g.get_stack_size() > max_stack_size:

                tried_gadget_cache.add(candidate_g)
                return None
                
            candidate_g_cpy, org_to_fstid = candidate_g.duplicate(copy_stack_associated_values=True)
            wanted_effect_cpy: Effect = deepcopy(wanted_effect)

            start_values_cpy = deepcopy(reg_start_values)
            candidate_g_cpy.effects = Effect.join_effects(start_values_cpy, candidate_g_cpy.effects)

            candidate_effect = None
            for ef in candidate_g_cpy.effects:

                if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == wanted_effect_cpy.destination_element.info["reg_name"]:
                    candidate_effect = ef
                    break

            if candidate_effect.type not in searched_effect_types:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            matched = wanted_effect_cpy.match(candidate_effect)
            if matched is False:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            is_fixed = candidate_g_cpy.check_fixed_regs(fixed_reg_list, 'complete')
            if is_fixed is False:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            if len(reg_start_values) > 0:

                # gadget is accepted, a third copy is created from the original gadget
                # that is not simplified like the first gadget copy, 
                # but does contain all the additional stack ids and their associated value from the first gadget copy
                # then, the first temporary copy has its stack ids and other contents removed

                accepted_gadget, org_to_sndid = candidate_g.duplicate(copy_stack_associated_values=True)

                for org_stack_elem in candidate_g.stack.elements:
                    if org_stack_elem.type == "64b_stack_val":

                        fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])

                        if Stack_view.related_jump[org_stack_elem.info["id"]] != Stack_view.related_jump[fstid]:
                            raise RuntimeError(f"unexpected different associated jump IDs: {Stack_view.related_jump[org_stack_elem.info['id']]} {Stack_view.related_jump[fstid]}")

                        if Stack_view.stack_values[org_stack_elem.info["id"]] != Stack_view.stack_values[fstid]:

                            if Stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                raise RuntimeError("original gadget and cloned gadget non-null values are different")

                            sndid = _get_new_id(org_to_sndid, org_stack_elem.info["id"])
                            Stack_view.stack_values[sndid] = Stack_view.stack_values[fstid]

                        # else, the accepted_gadget already has the original value

                candidate_g_cpy.remove_stack_ids()

            else:
                accepted_gadget = candidate_g_cpy

            tried_gadget_cache.add(candidate_g)
            return accepted_gadget

        # table of possible effect types matching
        # there can be multiple searched effects because, given specific circumstances, some effects can change type
        # NOTE: LOAD_S is intentionally restricted to only other LOAD_S effects, for an efficient/ fast search
        #       if one wants to have all the possible ways of loading a value in a register, LOAD_CT matching should be chosen instead
        # LOAD_S -> LOAD_S
        # LOAD_CT -> LOAD_CT, LOAD_S (always false if max stack size == 0), ARITH
        # MOV_RR -> MOV_RR, ARITH
        # ARITH -> ARITH

        # searched effect type filtering
        # is done in two places: here, less restrictive
        # and inside the try gadget function, more restrictive
        # this is because we still want the search to be optimised
        # but also we need to take into account that the reg start values
        # can change some effect types into other types

        found_g: List[ROP_gadget] = []
        searched_effect_types_snd: List[str] = []
        searched_effect_types_fst: List[str] = []

        if wanted_effect.type == "LOAD_S":

            searched_effect_types_snd.append("LOAD_S")

            searched_effect_types_fst.append("LOAD_S")

        elif wanted_effect.type == "LOAD_CT":

            searched_effect_types_snd.append("LOAD_S")
            searched_effect_types_snd.append("LOAD_CT")
            searched_effect_types_snd.append("ARITH")

            searched_effect_types_fst.append("LOAD_S")
            searched_effect_types_fst.append("LOAD_CT")
            searched_effect_types_fst.append("MOV_RR")
            searched_effect_types_fst.append("ARITH")

        elif wanted_effect.type == "MOV_RR":

            searched_effect_types_snd.append("MOV_RR")
            searched_effect_types_snd.append("ARITH")

            searched_effect_types_fst.append("MOV_RR")
            searched_effect_types_fst.append("ARITH")

        elif wanted_effect.type == "ARITH":

            searched_effect_types_snd.append("ARITH")
            
            searched_effect_types_fst.append("ARITH")
            searched_effect_types_fst.append("MOV_RR")

        for srch_t in searched_effect_types_fst:

            found_per_t_cnt = 0

            candidate_g: ROP_gadget
            for candidate_g in self.effects_to_gadgets[srch_t][wanted_effect.destination_element.info["reg_name"]]:
                
                accepted_gadget = _try_gadget(candidate_g, wanted_effect, searched_effect_types_snd)
                if accepted_gadget is not None:

                    found_g.append(accepted_gadget)

                    found_per_t_cnt += 1
                    if found_per_t_cnt == max_search_cnt:
                        break
        
        found_g.sort(key = lambda g: g.get_stack_size())
        return found_g[:max_search_cnt]

    def search_gadgets(self, wanted_effect: Effect, max_stack_size: int = 2**63, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[Effect] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains formed from one single gadget\n
            Fastest chain search method\n
            (check docs for more details)
        '''

        self.logger.log_debug("search gadgets")

        gadgets = self.filter_gadgets(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                            reg_start_values=reg_start_values, max_search_cnt=2 ** 63)

        for g in gadgets:
            
            b = g.get_bytes()
            if b not in b_cache.keys():

                b_cache.update({b: True})
                yield ROP_chain.convert(g)

    def search_arith_to_mov(self, q = 1):
        '''
            Try to create chains between nodes that have path_from == False\n
            Analogous with the method that validates raw gadgets\n
        '''
        
        def _advertisement_check(elem: Structured_element):

            if elem is None:
                return True

            if elem.type == "reg_in":
                return False

            if elem.type == "ct_val":
                return True

            if elem.type == "64b_stack_val":
                return True

            if elem.type == "deref":
                raise Exception("deref found in a supposedly valid gadget / chain")

            if elem.is_op():
                
                l1 = _advertisement_check(elem.info["term_1"])
                r1 = _advertisement_check(elem.info["term_2"])

                return l1 and r1

            raise Exception(f"unexpected element {elem}")

        def _extract_requests(elem: Structured_element, regs: list):

            if elem is None:
                return
        
            if elem.type == "reg_in" and elem.info["reg_name"] not in regs and \
                elem.info["reg_name"] != self.stack_pointer:

                regs.append(elem.info["reg_name"])

            elif elem.is_op():
                _extract_requests(elem.info["term_1"], regs)
                _extract_requests(elem.info["term_2"], regs)

            elif elem.type == "deref":
                raise Exception("unexpected deref inside JUMP expression")

        _, path_from = self.get_trans_reg_graph()
        path_from = path_from[""]

        to_check = [g for g in self.gadgets]
        new_gs = []
        
        replace_reg_dict = {reg: [[], set()] for reg in self.platform.SUPPORTED_REGS}
        # {reg: [
        #        [list of gadgets whose effect with dest elem == reg does not contain other reg_in arguments),
        #        (set of elements from the first list),
        #       ]
        # }
        # list is used to be able to execute random.choice()
        # set is used to be able to check for existence in constant time

        g_to_requests = {g: [] for g in to_check}
        # {g: [[regs to replace for first arith effect in g.effects], ...]}

        g_to_tested = {g: set() for g in to_check}
        # {gadget: set((g0, g1, ...), ...)}
        # contains ordered join combinations for the current gadget
        # that were previously tried

        efidx_to_realidx = {g: [] for g in to_check}
        # see usage

        to_spare_regs = {g: [] for g in to_check}
        # see usage

        # populate g_to_requests
        for g in to_check:
            for realidx, ef in enumerate(g.effects):

                if ef.type == "ARITH":

                    reg_dest = ef.destination_element.info["reg_name"]

                    if reg_dest == self.stack_pointer:
                        continue
                    
                    g_to_requests[g].append([])
                    efidx_to_realidx[g].append(realidx)

                    _extract_requests(ef.params[0], g_to_requests[g][-1])

                    to_spare_regs[g].append([])

                    for reg_src in g_to_requests[g][-1]:
                        if path_from[reg_dest][reg_src] is False:

                            to_spare_regs[g][-1].append(reg_src)

        def _serve_request(g: ROP_gadget, ef_idx: int):

            reqs = g_to_requests[g][ef_idx]
            to_spare = to_spare_regs[g][ef_idx]

            if len(reqs) == 0:
                while True:
                    yield []

            MAX_CONSECUTIVE_FAILS = 3
            consecutive_fails = 0

            to_spare_idx = 0

            while True:

                to_spare_reg = to_spare[to_spare_idx]
                to_spare_idx += 1
                to_spare_idx %= len(to_spare)

                # select the replacements

                seq: List[ROP_chain | ROP_gadget] = []
                for req in reqs:
                    if req != to_spare_reg:
                    
                        already_chosen = False
                        for chosen in seq:

                            if chosen in replace_reg_dict[req][1]:

                                already_chosen = True
                                break

                        if already_chosen is True:
                            continue

                        seq.append(random.choice(replace_reg_dict[req][0]))

                # check stack size limits

                stack_size = 0
                for v in seq:
                    stack_size += v.get_stack_size()

                if stack_size > Effect.VALIDATION_SEARCH_MAX_STACK_SIZE:

                    consecutive_fails += 1
                    if consecutive_fails > MAX_CONSECUTIVE_FAILS:
                        return None

                    continue

                # randomize joining order

                for i in range(len(seq) - 1):
                    j = random.randint(i, len(seq) - 1)
                    
                    aux = seq[i]
                    seq[i] = seq[j]
                    seq[j] = aux

                # check if it has been tried before

                tseq = tuple(seq)
                if tseq in g_to_tested[g]:

                    consecutive_fails += 1
                    if consecutive_fails > MAX_CONSECUTIVE_FAILS:
                        return None

                    continue
                
                consecutive_fails = 0

                g_to_tested[g].add(tseq)
                yield to_spare_reg, seq

        serve_request = {g: {ef_idx: _serve_request(g, ef_idx) for ef_idx in range(len(g_to_requests[g]))} for g in to_check}
        # dictionary that contains _serve_request() generators

        # yield (at most) q elements
        def serve_request_q(g: ROP_gadget, ef_idx: int, q):
            
            try:

                for _ in range(q):
                    yield next(serve_request[g][ef_idx])

            except StopIteration:
                return None

        # the gs / chs in this set were already tested for advertisement
        # (only for optimization purposes)
        already_advertised = set()

        new_generated = 1
        while new_generated > 0:

            new_generated = 0

            # loop through valid gadgets / chains, to "advertise" their effects
            for g in self.gadgets:
                if g not in already_advertised:

                    for ef in g.effects:
                        if ef.type in ["LOAD_CT", "LOAD_S", "MOV_RR", "ARITH"]:

                            ok_to_advertise = _advertisement_check(ef.params[0])
                            if ok_to_advertise is True:
                                
                                replace_reg_dict[ef.destination_element.info["reg_name"]][0].append(g)
                                replace_reg_dict[ef.destination_element.info["reg_name"]][1].add(g)

                    already_advertised.add(g)

            rem_idx = set()

            g: ROP_gadget
            for g_idx, g in enumerate(to_check):

                satisf = 0
                for ef_idx in range(len(g_to_requests[g])):

                    # check if registers can be replaced

                    if len(to_spare_regs[g][ef_idx]) == 0:
                        continue
                    
                    replaceable = True
                    
                    reqs = g_to_requests[g][ef_idx]  

                    # at least one reg kept, the others are removed
                    if len(reqs) <= 1:
                        continue

                    # sp cannot be replaced by anothing else other than sp + offset
                    if self.stack_pointer in reqs:
                        continue

                    for req in reqs:

                        if len(replace_reg_dict[req][0]) == 0:

                            replaceable = False
                            break

                    if replaceable is False:
                        continue

                    # try to replace regs
                    
                    seq: List[ROP_gadget | ROP_chain]
                    for spared_reg, seq in serve_request_q(g, ef_idx, q):
                        
                        if seq is None:
                            break

                        if len(seq) == 0:
                            raise Exception("unexpected len(seq) == 0")

                        candidate_ch = ROP_chain.convert(seq[0].duplicate()[0])
                        for ch in seq[1:]:

                            candidate_ch_aux = candidate_ch.join(ROP_chain.convert(ch))

                            if candidate_ch_aux is None:
                                candidate_ch = None
                                break

                            candidate_ch.remove_stack_ids()
                            candidate_ch = candidate_ch_aux

                        if candidate_ch is None:
                            continue

                        g_aux = ROP_chain.convert(g.duplicate()[0])
                        candidate_ch_aux = candidate_ch.join(g_aux)

                        if candidate_ch_aux is not None:
                            candidate_ch.remove_stack_ids()

                        candidate_ch = candidate_ch_aux

                        if candidate_ch is None:
                            continue
                        
                        # outcome

                        reg_dest = g.effects[efidx_to_realidx[g][ef_idx]].destination_element.info["reg_name"]

                        mov_effect = Effect.make_mov_rr_effect(reg_dest, spared_reg)

                        to_check_effect = None
                        for ef_ in candidate_ch.effects:

                            if ef_.type != "JUMP" and ef_.destination_element.info["reg_name"] == reg_dest:
                                to_check_effect = ef_
                                break

                        assert(to_check_effect.destination_element.info["reg_name"] == reg_dest)

                        if to_check_effect is None:
                            continue

                        if mov_effect.match(to_check_effect) is False:

                            candidate_ch.remove_stack_ids()
                            continue

                        print(reg_dest, spared_reg)
                        
                        satisf += 1
                        new_generated += 1

                        new_gs.append(candidate_ch)

                if satisf > 0:
                    rem_idx.add(g_idx)

            old_to_check = to_check
            to_check = []

            for g_idx in range(len(old_to_check)):

                if g_idx not in rem_idx:
                    to_check.append(old_to_check[g_idx])

        for g in new_gs:

            assert(g.valid_jump is True)
            assert(g.valid_stack_access is True)

            self.gadgets.add(g)

            for ef in g.effects:
                if ef.type != "JUMP" and ef.destination_element.info["reg_name"] != self.stack_pointer:
                    self.effects_to_gadgets[ef.type][ef.destination_element.info["reg_name"]].append(g)

        # reset trans reg graph cache

        self.path_from = None
        self.trans_register_graph = None
        self.get_trans_reg_graph()

    def search_mov_chains(self, wanted_effect: Effect, max_stack_size: int = 2**63, 
                            fixed_reg_list: List[str] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains that satisfy MOV_RR effects\n
            It makes use of the transition graph\n
            The execution time may increase exponentially if at least one of those conditions are reached:
            * all possible chains are yielded
            * len(fixed register list) > 2\n
            (check docs section 'Substitution based MOV_RR search' for more details)
        '''

        self.logger.log_debug("search mov chains")

        trans_graph, path_from = self.get_trans_reg_graph()

        if len(fixed_reg_list) == 0:

            trans_graph = trans_graph[""]
            path_from = path_from[""]

        elif len(fixed_reg_list) == 1:

            trans_graph = trans_graph[fixed_reg_list[0]]
            path_from = path_from[fixed_reg_list[0]]

        elif len(fixed_reg_list) >= 2:

            fixed_reg_list.sort()
            trans_graph = trans_graph[(fixed_reg_list[0], fixed_reg_list[1])]
            path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

        dest = wanted_effect.destination_element.info["reg_name"]
        src = wanted_effect.params[0].info["reg_name"]

        if path_from[dest][src] is False:
            self.logger.log_warning("(chain searcher): transition path does not exist")
            return

        for path, _ in self.transition_chain_generator(dest, src, trans_graph, path_from, max_stack_size):

            if len(path) == 0:
                continue

            if ROP_searcher._check_if_duplicate(path, b_cache) is True:
                continue

            candidate_ch = ROP_chain.convert(path[-1].duplicate()[0])
            for g in path[-2::-1]:

                candidate_ch_aux = candidate_ch.join(g)
                candidate_ch.remove_stack_ids()
                candidate_ch = candidate_ch_aux

                if candidate_ch is None:
                    break

            if candidate_ch is None:
                continue

            if candidate_ch.get_stack_size() > max_stack_size:
                candidate_ch.remove_stack_ids()
                continue

            b = candidate_ch.get_bytes()
            if b in b_cache.keys():
                candidate_ch.remove_stack_ids()
                continue

            b_cache.update({b: False})

            # prudent check for wanted effect match
            wanted_effect_cpy = deepcopy(wanted_effect)

            to_check_ef: Effect = None
            for ef in candidate_ch.effects:
                
                if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == dest:
                    to_check_ef = ef
                    break

            if (to_check_ef is None) or (wanted_effect_cpy.match(to_check_ef) is False):
                self.logger.log_debug(f"Effect not matched (mov), when expected to match. Please report this to the creator of this tool.")
                candidate_ch.remove_stack_ids()
                continue

            if candidate_ch.check_fixed_regs(fixed_reg_list) is False:
                candidate_ch.remove_stack_ids()
                continue

            b_cache[b] = True
            yield candidate_ch

    def search_chain_by_substitution(self, wanted_effect: Effect, max_stack_size: int = 2**63, 
                                        fixed_reg_list: List[str] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains that satisfy ARITH or LOAD_CT effects, by (register-only) substitutions\n
            The execution time may increase exponentially if at least one of those conditions are reached:
            * all possible chains are yielded
            * number of fixed registers > 2
            * number of fixed registers + number of reg_in elements from the wanted effect > 3
            * max stack size is given\n
            (check docs section 'Substitution (register-only) based ARITH search' for more details)
        '''

        self.logger.log_debug("search by substitution")

        if wanted_effect.type not in ["ARITH", "LOAD_CT"]:
            raise RuntimeError(f"tyring to search chain inside _search_chain_by_substitution for wanted effect type {wanted_effect.type}")

        trans_graph, path_from = self.get_trans_reg_graph()

        fixed_reg_list = deepcopy(fixed_reg_list)
        fixed_reg_list.sort()

        if self.platform is Platform.ARM64:

            '''Changes in x30 values are not completely taken into account
                (i.e. when executing a branch link register operation)'''
            SUPPORTED_SUBSTITUTION_REGS = deepcopy(self.platform.SUPPORTED_REGS)
            SUPPORTED_SUBSTITUTION_REGS.remove("x30")

        elif self.platform is Platform.X86_64:
            SUPPORTED_SUBSTITUTION_REGS = deepcopy(self.platform.SUPPORTED_REGS)
        
        else:
            raise RuntimeError(f"Requested platform {self.platform} unknown or not supported")

        # ---------------

        def _get_bytes(chs: List[ROP_chain]):
            '''
                Auxiliary function
            '''

            b_repr = b''
            for ch in chs:
                b_repr += ch.get_bytes()

            return b_repr

        def _find_used_regs(ef: Effect) -> Tuple[List[str], str]:
            '''
                Find all reg_in used, and the reg_out, for an ARITH / LOAD_CT effect
            '''

            def _rec_find(el: Structured_element):
                
                if el is None:
                    return []

                if el.type == "reg_in":
                    return [el.info["reg_name"]]

                if el.is_op():
                    return _rec_find(el.info["term_1"]) + _rec_find(el.info["term_2"])

                if el.type == "64b_stack_val":
                    raise RuntimeError("wanted effect contains stack elements")

                return []

            if ef.type == "LOAD_CT":
                return [], ef.destination_element.info["reg_name"]

            elif ef.type == "ARITH":
                
                found = _rec_find(ef.params[0])

                to_return = []
                for r in found:
                    if r not in to_return:
                        to_return.append(r)

                return to_return, ef.destination_element.info["reg_name"]

        def _get_substitution(regs_to_replace: List[str], already_replaced: List[str]) -> Dict[str, Tuple[str, List[str]]]:
            '''
                Generator that finds all possible substitutions, without substituting the destination register
            '''

            if len(regs_to_replace) == 0:
                yield {}
                return

            r = regs_to_replace[0]
            regs_to_replace = regs_to_replace[1:]

            keep_fixed = regs_to_replace + already_replaced + fixed_reg_list

            # try to find subgraph for failproof substitutions

            if len(keep_fixed) == 0:
                subgraph_path_from = path_from[""]

            elif len(keep_fixed) == 1:
                subgraph_path_from = path_from[keep_fixed[0]]

            elif len(keep_fixed) >= 2:
                
                # register names need to be sorted
                if keep_fixed[0] > keep_fixed[1]:

                    _swapvar = keep_fixed[0]
                    keep_fixed[0] = keep_fixed[1]
                    keep_fixed[1] = _swapvar

                subgraph_path_from = path_from[(keep_fixed[0], keep_fixed[1])]

            # yield all possible combinations

            for r_sub_candidate in SUPPORTED_SUBSTITUTION_REGS:

                if r_sub_candidate not in keep_fixed and \
                    subgraph_path_from[r_sub_candidate][r] is True:

                    r_sub = r_sub_candidate
                    for sub in _get_substitution(regs_to_replace, already_replaced + [r_sub]):

                        total_sub = {r: (r_sub, keep_fixed)}
                        total_sub.update(sub)
                        yield total_sub

        def _get_substitution_dest(dest_reg: str) -> str:
            '''
                Find all possible substitution for the destination register of the wanted effect
            '''

            if len(fixed_reg_list) == 0:
                subgraph_path_from = path_from[""]

            elif len(fixed_reg_list) == 1:
                subgraph_path_from = path_from[fixed_reg_list[0]]

            elif len(fixed_reg_list) >= 2:
                subgraph_path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

            for r_sub in SUPPORTED_SUBSTITUTION_REGS:
                if r_sub != dest_reg and subgraph_path_from[dest_reg][r_sub] is True:
                    yield r_sub

        def _get_reglist_permutation(rs: List[str]) -> List[str]:
            '''
                Yield all permutations of a list of registers\n
                Used to determine the order for substitutions 
            '''

            def _perm(n, k):

                if k == 0:
                    yield []

                else:
                    for suf in _perm(n, k - 1):
                        for i in range(n):
                            if i not in suf:
                                yield [i] + suf

            for p in _perm(len(rs), len(rs)):
                yield [rs[i] for i in p]

        def _apply_substitutions(ef: Effect, substitution: Dict[str, Tuple[str, List[str]]], dest_substitution: str):
            '''
                Apply a given substitution on an effect
            '''

            def _rec_subst(el: Structured_element):

                if el is None:
                    return None

                if el.type == "reg_in":
                    el.info["reg_name"] = substitution[el.info["reg_name"]][0]

                elif el.is_op():
                    _rec_subst(el.info["term_1"])
                    _rec_subst(el.info["term_2"])

                elif el.type == "64b_stack_val":
                    raise RuntimeError("wanted effect contains stack elements")

            subst_ef = deepcopy(ef)
            subst_ef.destination_element.info["reg_name"] = dest_substitution

            if subst_ef.type == "ARITH":
                _rec_subst(subst_ef.params[0])

            return subst_ef

        def _get_transition(ordered_reg_list: List[str], substitution: Dict[str, Tuple[str, List[str]]], local_max_ss: int) -> Tuple[List[ROP_gadget | ROP_chain], int]:
            '''
                Yield all possible transitions, as a list of gadgets (chains), and the associated (minimum) stack size\n
                NOTE: without dest substitution transition
            '''

            if len(ordered_reg_list) == 0:
                yield [], 0
                return 

            r = ordered_reg_list[0]
            ordered_reg_list = ordered_reg_list[1:]

            r_sub, keep_fixed = substitution[r]

            if len(keep_fixed) == 0:

                trans_subgraph = trans_graph[""]
                subgraph_path_from = path_from[""]

            elif len(keep_fixed) == 1:

                trans_subgraph = trans_graph[keep_fixed[0]]
                subgraph_path_from = path_from[keep_fixed[0]]

            elif len(keep_fixed) >= 2:

                # register names need to be sorted
                if keep_fixed[0] > keep_fixed[1]:

                    _swapvar = keep_fixed[0]
                    keep_fixed[0] = keep_fixed[1]
                    keep_fixed[1] = _swapvar

                trans_subgraph = trans_graph[(keep_fixed[0], keep_fixed[1])]
                subgraph_path_from = path_from[(keep_fixed[0], keep_fixed[1])]

            for trans, current_ss in \
                self.transition_chain_generator(r_sub, r, trans_subgraph, subgraph_path_from, local_max_ss):

                for trans_suffix, suffix_ss in _get_transition(ordered_reg_list, substitution, local_max_ss - current_ss):

                    yield trans[::-1] + trans_suffix, current_ss + suffix_ss

        def _get_transition_dest(dest_reg: str, dest_substitution: str, local_max_ss: int) -> Tuple[List[ROP_gadget | ROP_chain], int]:
            '''
                Yield all possible transitions for the destination register, as a list of gadgets (chains)
            '''

            if len(fixed_reg_list) == 0:

                trans_subgraph = trans_graph[""]
                subgraph_path_from = path_from[""]

            elif len(fixed_reg_list) == 1:

                trans_subgraph = trans_graph[fixed_reg_list[0]]
                subgraph_path_from = path_from[fixed_reg_list[0]]

            elif len(fixed_reg_list) >= 2:

                trans_subgraph = trans_graph[(fixed_reg_list[0], fixed_reg_list[1])]
                subgraph_path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

            for trans_d, ss in self.transition_chain_generator(dest_reg, dest_substitution, trans_subgraph, subgraph_path_from, local_max_ss):
                yield trans_d[::-1], ss

        # ---------------

        wef_in_regs, wef_dest_reg = _find_used_regs(wanted_effect)

        if len(fixed_reg_list) > 2:
            self.logger.log_warning("running substitution-based search that violates recommended constraint of " + \
                                    f"|fixed regs| <= 2 ({len(fixed_reg_list)} detected); " + \
                                    "note that the running time increases exponentially - check the documentation for more info")

        if len(wef_in_regs) + len(fixed_reg_list) > 3:
            self.logger.log_warning("running substitution-based search that violates recommended constraint of " + \
                                    f"|register parameters inside the wanted effect| + |fixed regs| <= 3 ({len(wef_in_regs) + len(fixed_reg_list)} detected); " + \
                                    "note that the running time increases exponentially - check the documentation for more info")

        # for each substitution order possible
        for ordered_reg_list in _get_reglist_permutation(wef_in_regs):
            
            # for each substitution possible
            for subst in _get_substitution(ordered_reg_list, []):
                for subst_dest in _get_substitution_dest(wef_dest_reg):
                    
                    # apply substitution on the wanted effect
                    wef_subst = _apply_substitutions(wanted_effect, subst, subst_dest)

                    wef_subst_gs = self.filter_gadgets(wef_subst, max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=[], max_search_cnt=2 ** 63)

                    # if substituted wanted effect cannot be satisfied
                    # try the next substitution
                    if len(wef_subst_gs) == 0:
                        continue
                    
                    # (used to break from all the loops inside the try block for whatever reason)
                    break_ = False

                    # (wrap in try block to delete temporary gadgets in a "finally" block)
                    try:
                    
                        # for each gadget that satisfies the substituted wanted effect
                        for wef_subst_g in wef_subst_gs:
                            
                            # for each transition that implements the substitution
                            for trans, trans_ss in _get_transition(ordered_reg_list, subst, 
                                                                max_stack_size - wef_subst_g.get_stack_size()):
                                for trans_dest, trans_dest_ss in _get_transition_dest(wef_dest_reg, subst_dest, 
                                                                                    max_stack_size - wef_subst_g.get_stack_size() - trans_ss):

                                    # join the gadgets, 
                                    # validate the properties of the resulting chain, 
                                    # and yield it

                                    if wef_subst_g.get_stack_size() + trans_ss + trans_dest_ss > max_stack_size:
                                        break_ = True
                                        break

                                    to_join = trans + [wef_subst_g] + trans_dest

                                    if ROP_searcher._check_if_duplicate(to_join, b_cache) is True:
                                        continue

                                    candidate_ch = ROP_chain.convert(to_join[0].duplicate()[0])
                                    for g_aux in to_join[1:]:
                    
                                        candidate_ch_aux = candidate_ch.join(g_aux)
                                        candidate_ch.remove_stack_ids()
                                        candidate_ch = candidate_ch_aux

                                        if candidate_ch is None:
                                            break

                                    if candidate_ch is None:
                                        b_cache.update({_get_bytes(trans + [wef_subst_g] + trans_dest): False})
                                        continue

                                    if candidate_ch.get_stack_size() > max_stack_size:
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    b = candidate_ch.get_bytes()
                                    if b in b_cache.keys():
                                        candidate_ch.remove_stack_ids()
                                        continue
                                    
                                    b_cache.update({b: False})

                                    wanted_effect_cpy = deepcopy(wanted_effect)

                                    to_check_effect: Effect = None
                                    for ef in candidate_ch.effects:

                                        if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == wef_dest_reg:
                                            to_check_effect = ef
                                            break
                                    
                                    if (to_check_effect is None) or (wanted_effect_cpy.match(to_check_effect) is False):
                                        self.logger.log_debug(f"Effect not matched (subst), when expected to match. Please report this to the creator of this tool.")
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    if candidate_ch.check_fixed_regs(fixed_reg_list, 'complete') is False:
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    b_cache[b] = True
                                    yield candidate_ch

                                if break_ is True:
                                    break

                            if break_ is True:
                                break

                    finally:

                        # delete temporary gadgets
                        for wef_subst_g in wef_subst_gs: 
                            wef_subst_g.remove_stack_ids()

    def search_chain_by_substitution_adv(self, wanted_effect: Effect, max_stack_size: int = 2**63, 
                                            fixed_reg_list: List[str] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains that satisfy ARITH or LOAD_CT effects, by (register and constants) substitutions\n
            The execution time may increase exponentially if at least one of those conditions are reached:
            * all possible chains are yielded
            * number of fixed registers > 2
            * number of fixed registers + number of reg_in elements from the wanted effect + number of constants from the wanted effect > 3
            * max stack size is given\n
            (check docs section 'Substitution (register and constants) based ARITH search' for more details)
        '''

        self.logger.log_debug("search by substitution advanced")

        if wanted_effect.type not in ["ARITH", "LOAD_CT"]:
            raise RuntimeError(f"tyring to search chain inside _search_chain_by_substitution for wanted effect type {wanted_effect.type}")

        trans_graph, path_from = self.get_trans_reg_graph()

        if self.platform is Platform.ARM64:

            '''Changes in x30 values are not completely taken into account
                (i.e. when executing a branch link register operation)'''
            SUPPORTED_SUBSTITUTION_REGS = deepcopy(self.platform.SUPPORTED_REGS)
            SUPPORTED_SUBSTITUTION_REGS.remove("x30")

        elif self.platform is Platform.X86_64:
            SUPPORTED_SUBSTITUTION_REGS = deepcopy(self.platform.SUPPORTED_REGS)

        else:
            raise RuntimeError(f"Requested platform {self.platform} unknown or not supported")

        rs = deepcopy(SUPPORTED_SUBSTITUTION_REGS)
        rs.sort()

        all_fixedreg_keys = [""] + \
                            [r for r in rs] + \
                            [(rs[ir1], rs[ir2]) for ir1 in range(len(rs) - 1) for ir2 in range(ir1 + 1, len(rs))]

        # load_ct_map[fixed regs][src ct][dest reg][list of transition gadgets]
        load_ct_map: Dict[str | Tuple[str], Dict[int, Dict[str, List[ROP_gadget]]]] = \
                {
                    fixed: {}
                    for fixed in all_fixedreg_keys
                }

        fixed_reg_list = deepcopy(fixed_reg_list)
        fixed_reg_list.sort()

        # ---------------

        def _get_bytes(chs: List[ROP_chain]):
            '''
                Auxiliary function
            '''

            b_repr = b''
            for ch in chs:
                b_repr += ch.get_bytes()

            return b_repr

        def _find_used_rcs(ef: Effect) -> Tuple[List[str | Tuple[int, int]], str]:
            '''
                Find all reg_in and ct_val used, and the reg_out, for an ARITH / LOAD_CT effect\n
            '''

            preorder_ct_idx = -1
            def _rec_find(el: Structured_element):

                nonlocal preorder_ct_idx
                
                if el is None:
                    return []

                if el.type == "reg_in":
                    return [el.info["reg_name"]]

                if el.is_op():

                    r1 = _rec_find(el.info["term_1"])
                    r2 = _rec_find(el.info["term_2"])
                    return r1 + r2

                if el.type == "ct_val":
                    
                    preorder_ct_idx += 1
                    return [(el.info["value"], preorder_ct_idx)]

                if el.type == "64b_stack_val":
                    raise RuntimeError("wanted effect contains stack elements")

                return []

            if ef.type == "LOAD_CT":
                return [(ef.params[0].info["value"], 0)], ef.destination_element.info["reg_name"]

            elif ef.type == "ARITH":
                
                found = _rec_find(ef.params[0])

                to_return = []
                for r in found:

                    if r not in to_return:
                        to_return.append(r)

                return to_return, ef.destination_element.info["reg_name"]
            
        def _populate_load_ct_map(el: Structured_element) -> None:
            '''
                Populate load_ct_map, by searching for constants in the wanted effect
            '''
            
            if el is None:
                return

            if el.is_op():
                _populate_load_ct_map(el.info["term_1"])
                _populate_load_ct_map(el.info["term_2"])

            if el.type == "ct_val":
                
                ct_value = el.info["value"]
                
                if ct_value in load_ct_map[""].keys():
                    return

                for fixed_arg in all_fixedreg_keys:
                    load_ct_map[fixed_arg].update({ct_value: {r: [] for r in SUPPORTED_SUBSTITUTION_REGS}})
                            
                for r in SUPPORTED_SUBSTITUTION_REGS:

                    ct_to_r = Effect.make_load_ct_effect(r, ct_value)
                    load_ct_gs = self.filter_gadgets(ct_to_r, max_stack_size=max_stack_size, 
                                                    fixed_reg_list=[], reg_start_values=[], max_search_cnt=2**64)

                    if len(load_ct_gs) == 0:
                        continue

                    for fixed_arg in all_fixedreg_keys:
                        
                        if fixed_arg == "":
                            load_ct_map[""][ct_value][r] = load_ct_gs

                        elif type(fixed_arg) is str:

                            for g in load_ct_gs:
                                if g.check_fixed_regs([fixed_arg], mode='fast'):

                                    load_ct_map[fixed_arg][ct_value][r].append(g)

                        elif type(fixed_arg) is tuple:

                            for g in load_ct_gs:
                                if g.check_fixed_regs([fixed_arg[0], fixed_arg[1]], mode='fast'):

                                    load_ct_map[fixed_arg][ct_value][r].append(g)

        def _get_substitution(rcs_to_replace: List[str | Tuple[int, int]], already_replaced: List[str]) -> Dict[str | int, Tuple[str, List[str]]]:
            '''
                Generator that finds all possible substitutions, without substituting the destination register
            '''

            if len(rcs_to_replace) == 0:
                yield {}
                return

            rc = rcs_to_replace[0]
            rcs_to_replace = rcs_to_replace[1:]

            keep_fixed = already_replaced + fixed_reg_list

            for reg_or_ct in rcs_to_replace:
                if reg_or_ct in SUPPORTED_SUBSTITUTION_REGS:

                    keep_fixed.append(reg_or_ct)

            # try to find subgraph for failproof substitutions

            if len(keep_fixed) == 0:

                subgraph_path_from = path_from[""]
                load_ct_submap = load_ct_map[""]

            elif len(keep_fixed) == 1:

                subgraph_path_from = path_from[keep_fixed[0]]
                load_ct_submap = load_ct_map[keep_fixed[0]]

            elif len(keep_fixed) >= 2:
                
                # register names need to be sorted
                if keep_fixed[0] > keep_fixed[1]:

                    _swapvar = keep_fixed[0]
                    keep_fixed[0] = keep_fixed[1]
                    keep_fixed[1] = _swapvar

                subgraph_path_from = path_from[(keep_fixed[0], keep_fixed[1])]
                load_ct_submap = load_ct_map[(keep_fixed[0], keep_fixed[1])]

            # yield all possible combinations

            # register
            if rc in SUPPORTED_SUBSTITUTION_REGS:

                for r_sub_candidate in SUPPORTED_SUBSTITUTION_REGS:

                    if r_sub_candidate not in keep_fixed and \
                        subgraph_path_from[r_sub_candidate][rc] is True:

                        r_sub = r_sub_candidate
                        for sub in _get_substitution(rcs_to_replace, already_replaced + [r_sub]):

                            total_sub = {rc: (r_sub, keep_fixed)}
                            total_sub.update(sub)
                            yield total_sub

            # constant 
            else:

                ct, preorder_idx = rc

                # case when constant is not substituted
                for sub in _get_substitution(rcs_to_replace, already_replaced):

                    total_sub = {preorder_idx: (None, keep_fixed)}
                    total_sub.update(sub)
                    yield total_sub
                
                # case when constant is substituted
                for ct_sub_candidate in SUPPORTED_SUBSTITUTION_REGS:

                    if ct_sub_candidate not in keep_fixed and \
                        len(load_ct_submap[ct][ct_sub_candidate]) > 0:

                        ct_sub = ct_sub_candidate
                        for sub in _get_substitution(rcs_to_replace, already_replaced + [ct_sub]):

                            total_sub = {preorder_idx: (ct_sub, keep_fixed)}
                            total_sub.update(sub)
                            yield total_sub

        def _get_substitution_dest(dest_reg: str) -> str:
            '''
                Find all possible substitution for the destination register of the wanted effect
            '''

            if len(fixed_reg_list) == 0:
                subgraph_path_from = path_from[""]

            elif len(fixed_reg_list) == 1:
                subgraph_path_from = path_from[fixed_reg_list[0]]

            elif len(fixed_reg_list) >= 2:
                subgraph_path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

            for r_sub in SUPPORTED_SUBSTITUTION_REGS:
                if r_sub != dest_reg and subgraph_path_from[dest_reg][r_sub] is True:
                    yield r_sub

        def _get_rclist_permutation(rcs: List[str | Tuple[int, int]]) -> List[str]:
            '''
                Yield all permutations of a list of registers and constants\n
                Used to determine the order for substitutions 
            '''

            def _perm(n, k):

                if k == 0:
                    yield []

                else:
                    for suf in _perm(n, k - 1):
                        for i in range(n):
                            if i not in suf:
                                yield [i] + suf

            for p in _perm(len(rcs), len(rcs)):
                yield [rcs[i] for i in p]

        def _apply_substitutions(ef: Effect, substitution: Dict[str | int, Tuple[str, List[str]]], dest_substitution: str):
            '''
                Apply a given substitution on an effect
            '''

            preorder_ct_idx = -1
            def _rec_subst(el: Structured_element):

                nonlocal preorder_ct_idx

                if el is None:
                    return None

                if el.type == "reg_in":
                    el.info["reg_name"] = substitution[el.info["reg_name"]][0]

                elif el.is_op():
                    _rec_subst(el.info["term_1"])
                    _rec_subst(el.info["term_2"])

                elif el.type == "ct_val":

                    preorder_ct_idx += 1

                    r_subst, _ = substitution[preorder_ct_idx]
                    if r_subst is None:
                        return

                    el.type = "reg_in"
                    el.info = {"reg_name": r_subst}

            subst_ef = deepcopy(ef)
            subst_ef.destination_element.info["reg_name"] = dest_substitution

            _rec_subst(subst_ef.params[0])

            return subst_ef

        def _get_transition(ordered_rc_list: List[str | Tuple[int, int]], substitution: Dict[str | int, Tuple[str, List[str]]], local_max_ss: int) \
                                -> Tuple[List[ROP_gadget | ROP_chain], int]:
            '''
                Yield all possible transitions, as a list of gadgets (chains), and the associated (minimum) stack size\n
                NOTE: without dest substitution transition
            '''

            if len(ordered_rc_list) == 0:
                yield [], 0
                return 

            rc = ordered_rc_list[0]
            ordered_rc_list = ordered_rc_list[1:]

            # register
            if rc in SUPPORTED_SUBSTITUTION_REGS:

                r_sub, keep_fixed = substitution[rc]

                if len(keep_fixed) == 0 or len(keep_fixed) > 2:

                    trans_subgraph = trans_graph[""]
                    subgraph_path_from = path_from[""]

                elif len(keep_fixed) == 1:

                    trans_subgraph = trans_graph[keep_fixed[0]]
                    subgraph_path_from = path_from[keep_fixed[0]]

                elif len(keep_fixed) == 2:

                    # register names need to be sorted
                    if keep_fixed[0] > keep_fixed[1]:

                        _swapvar = keep_fixed[0]
                        keep_fixed[0] = keep_fixed[1]
                        keep_fixed[1] = _swapvar
                    
                    trans_subgraph = trans_graph[(keep_fixed[0], keep_fixed[1])]
                    subgraph_path_from = path_from[(keep_fixed[0], keep_fixed[1])]

                for trans, current_ss in \
                    self.transition_chain_generator(r_sub, rc, trans_subgraph, subgraph_path_from, local_max_ss):

                    for trans_suffix, suffix_ss in _get_transition(ordered_rc_list, substitution, local_max_ss - current_ss):

                        yield trans[::-1] + trans_suffix, current_ss + suffix_ss

            # constant
            else:

                ct, preorder_idx = rc
                r_sub, keep_fixed = substitution[preorder_idx]

                # constant is not substituted
                if r_sub is None:
                    yield from _get_transition(ordered_rc_list, substitution, local_max_ss)

                # constant is substituted
                else:

                    if len(keep_fixed) == 0 or len(keep_fixed) > 2:
                        load_ct_submap = load_ct_map[""]

                    elif len(keep_fixed) == 1:
                        load_ct_submap = load_ct_map[keep_fixed[0]]

                    elif len(keep_fixed) == 2:

                        # register names need to be sorted
                        if keep_fixed[0] > keep_fixed[1]:

                            _swapvar = keep_fixed[0]
                            keep_fixed[0] = keep_fixed[1]
                            keep_fixed[1] = _swapvar

                        load_ct_submap = load_ct_map[(keep_fixed[0], keep_fixed[1])]

                    for trans_ct in load_ct_submap[ct][r_sub]:
                        if trans_ct.get_stack_size() <= local_max_ss:

                            for trans_suffix, suffix_ss in _get_transition(ordered_rc_list, substitution, local_max_ss - trans_ct.get_stack_size()):
                                yield [trans_ct] + trans_suffix, trans_ct.get_stack_size() + suffix_ss

        def _get_transition_dest(dest_reg: str, dest_substitution: str, local_max_ss: int) -> Tuple[List[ROP_gadget | ROP_chain], int]:
            '''
                Yield all possible transitions for the destination register, as a list of gadgets (chains)
            '''

            if len(fixed_reg_list) == 0:

                trans_subgraph = trans_graph[""]
                subgraph_path_from = path_from[""]

            elif len(fixed_reg_list) == 1:

                trans_subgraph = trans_graph[fixed_reg_list[0]]
                subgraph_path_from = path_from[fixed_reg_list[0]]

            elif len(fixed_reg_list) >= 2:

                trans_subgraph = trans_graph[(fixed_reg_list[0], fixed_reg_list[1])]
                subgraph_path_from = path_from[(fixed_reg_list[0], fixed_reg_list[1])]

            for trans_d, ss in self.transition_chain_generator(dest_reg, dest_substitution, trans_subgraph, subgraph_path_from, local_max_ss):
                yield trans_d[::-1], ss

        # ---------------

        _t = self.logger.log_info("Preprocessing R <- CT map for the substitution of constants", start_timer=True)
        _populate_load_ct_map(wanted_effect.params[0])
        self.logger.log_info("Preprocessing of R <- CT map done", end_timer=_t)

        wef_rcs, wef_dest_reg = _find_used_rcs(wanted_effect)

        if len(fixed_reg_list) > 2:
            self.logger.log_warning("running substitution-based search that violates recommended constraint of " + \
                                    f"|fixed regs| <= 2 ({len(fixed_reg_list)} detected); " + \
                                    "note that the running time increases exponentially - check the documentation for more info")

        if len(wef_rcs) + len(fixed_reg_list) > 3:
            self.logger.log_warning("running substitution-based search that violates recommended constraint of " + \
                                    "|register parameters and constants inside the wanted effect| + |fixed regs| <= 3" + \
                                    f"({len(wef_rcs) + len(fixed_reg_list)} detected); " + \
                                    "note that the running time increases exponentially - check the documentation for more info")

        # for each substitution order possible
        for ordered_rc_list in _get_rclist_permutation(wef_rcs):
            
            # for each substitution possible
            for subst in _get_substitution(ordered_rc_list, []):
                for subst_dest in _get_substitution_dest(wef_dest_reg):
                    
                    # apply substitution on the wanted effect
                    wef_subst = _apply_substitutions(wanted_effect, subst, subst_dest)

                    wef_subst_gs = self.filter_gadgets(wef_subst, max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=[], max_search_cnt=2 ** 63)

                    # if substituted wanted effect cannot be satisfied
                    # try the next substitution
                    if len(wef_subst_gs) == 0:
                        continue
                    
                    # (used to break from all the loops inside the try block for whatever reason)
                    break_ = False

                    # (wrap in try block to delete temporary gadgets in a "finally" block)
                    try:
                    
                        # for each gadget that satisfies the substituted wanted effect
                        for wef_subst_g in wef_subst_gs:
                            
                            # for each transition that implements the substitution
                            for trans, trans_ss in _get_transition(ordered_rc_list, subst, 
                                                                max_stack_size - wef_subst_g.get_stack_size()):
                                for trans_dest, trans_dest_ss in _get_transition_dest(wef_dest_reg, subst_dest, 
                                                                                    max_stack_size - wef_subst_g.get_stack_size() - trans_ss):
                                    
                                    # join the gadgets, 
                                    # validate the properties of the resulting chain, 
                                    # and yield it

                                    if wef_subst_g.get_stack_size() + trans_ss + trans_dest_ss > max_stack_size:
                                        break_ = True
                                        break

                                    to_join = trans + [wef_subst_g] + trans_dest

                                    if ROP_searcher._check_if_duplicate(to_join, b_cache) is True:
                                        continue

                                    candidate_ch = ROP_chain.convert(to_join[0].duplicate()[0])
                                    for g_aux in to_join[1:]:
                    
                                        candidate_ch_aux = candidate_ch.join(g_aux)
                                        candidate_ch.remove_stack_ids()
                                        candidate_ch = candidate_ch_aux

                                        if candidate_ch is None:
                                            break

                                    if candidate_ch is None:
                                        b_cache.update({_get_bytes(trans + [wef_subst_g] + trans_dest): False})
                                        continue
                                
                                    if candidate_ch.get_stack_size() > max_stack_size:
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    b = candidate_ch.get_bytes()
                                    if b in b_cache.keys():
                                        candidate_ch.remove_stack_ids()
                                        continue
                                    
                                    b_cache.update({b: False})

                                    wanted_effect_cpy = deepcopy(wanted_effect)

                                    to_check_effect: Effect = None
                                    for ef in candidate_ch.effects:

                                        if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == wef_dest_reg:
                                            to_check_effect = ef
                                            break
                                    
                                    if (to_check_effect is None) or (wanted_effect_cpy.match(to_check_effect) is False):
                                        self.logger.log_debug(f"Effect not matched (subst adv), when expected to match. Please report this to the creator of this tool.")
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    if candidate_ch.check_fixed_regs(fixed_reg_list, 'complete') is False:
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    b_cache[b] = True
                                    yield candidate_ch

                                if break_ is True:
                                    break

                            if break_ is True:
                                break

                    finally:

                        # delete temporary gadgets
                        for wef_subst_g in wef_subst_gs: 
                            wef_subst_g.remove_stack_ids()

    def search_by_bruteforce(self, wanted_effect: Effect, max_stack_size: int = 2**63, 
                                fixed_reg_list: List[str] = [], b_cache: Dict[bytes, bool] = {}):
        '''
            Search chains by bruteforce with limited depth
        '''

        max_g_cnt = self.BRUTEFORCE_DEPTH
        if max_g_cnt > 3:
            self.logger.log_warning(f"Running bruteforce with maximum depth {max_g_cnt}. Consider changing the depth to at most 3")

        if max_g_cnt < 1:
            return

        def _get_bytes(chs: List[ROP_chain]):

            b_repr = b''
            for ch in chs:
                b_repr += ch.get_bytes()

            return b_repr

        def _prepare(g: ROP_gadget) -> ROP_chain:

            cpy_g, _ = g.duplicate()
            return ROP_chain.convert(cpy_g)

        # all the gadgets converted to atomic chains
        base_gs: List[ROP_chain] = [_prepare(g) for g in self.gadgets]

        # yields all different arrangements of gadgets of length k
        def _get_paths(k: int):
            
            if k == 0:
                yield [], 0

            else:
                for suf, stack_size in _get_paths(k - 1):
                    for g in base_gs:
                        yield [g] + suf, stack_size + g.get_stack_size()

        try:

            for l in range(max_g_cnt):
                for path, stack_size in _get_paths(l + 1):

                    if stack_size > max_stack_size:
                        continue    

                    if ROP_searcher._check_if_duplicate(path, b_cache) is True:
                        continue

                    candidate_ch: ROP_chain = path[-1].duplicate()[0]
                    for g in path[-2::-1]:

                        candidate_ch_aux = candidate_ch.join(g)
                        candidate_ch.remove_stack_ids()
                        candidate_ch = candidate_ch_aux

                        if candidate_ch is None:
                            break

                    if candidate_ch is None:
                        b_cache.update({_get_bytes(path): False})
                        continue

                    b = candidate_ch.get_bytes()
                    if b in b_cache.keys():
                        candidate_ch.remove_stack_ids()
                        continue

                    b_cache.update({b: False})

                    wanted_effect_cpy = deepcopy(wanted_effect)

                    to_check_effect: Effect = None
                    for ef in candidate_ch_aux.effects:
                        if ef.type != "JUMP" and ef.destination_element.info["reg_name"] == wanted_effect_cpy.destination_element.info["reg_name"]:
                            to_check_effect = ef
                            break

                    if to_check_effect is None:
                        candidate_ch.remove_stack_ids()
                        continue

                    if wanted_effect_cpy.match(to_check_effect) is False:
                        candidate_ch.remove_stack_ids()
                        continue

                    if candidate_ch_aux.check_fixed_regs(fixed_reg_list) is False:
                        candidate_ch.remove_stack_ids()
                        continue

                    b_cache[b] = True
                    yield candidate_ch
        
        finally:

            for ch in base_gs:
                ch.remove_stack_ids()

class ROP_payload:
    '''
        Class that implements the payload building API
    '''

    class _addr:

        def __init__(self, addr: int):
            self.addr = addr

    def __init__(self, rop_searcher, output_handle = stdout):

        self.logger = Logger(session_name = "PAYLOAD BUILDER", output_handle = output_handle)
        self.rop_searcher: ROP_searcher = rop_searcher
        
        self.pad_sequence = b'A'
        self.max_b_size = 2**63
        self.forbidden_bytes: List[bytes] = []

        self._raw_payload: List[ROP_payload._addr | bytes | ROP_chain] = []

    def set_forbidden_bytes(self, forbidden_bytes: List[bytes] = []) -> None:
        '''
            Specify the forbidden bytes that should not be found inside the payload bytes
        '''
        self.forbidden_bytes = forbidden_bytes

    def set_pad_sequence(self, pad_sequence = b'A') -> None:
        '''
            Set what padding sequence to use (default 'A' byte)\n
            For example, for the sequence b'1234', the padding of length 9 bytes will be b'123412341'
        '''
        self.pad_sequence = pad_sequence

    def set_max_size(self, max_byte_size: int = 2**63) -> None:
        '''
            Set the maximum payload byte length (default infinite)
        '''
        self.max_b_size = max_byte_size

    def add_chain(self, ch: ROP_chain) -> None:
        '''
            Add a chain to the payload
        '''
        self._raw_payload.append(ch)

    def add_bytes(self, b: bytes) -> None:
        '''
            Add custom bytes inside the payload
        '''
        self._raw_payload.append(b)

    def add_padding(self, pad_len: int)-> None:
        '''
            Add padding bytes of specified length
        '''
        l = 1 + (pad_len // len(self.pad_sequence))
        pad = self.pad_sequence * l
        self._raw_payload.append(pad[:pad_len])

    def add_addr(self, addr: int) -> None:
        '''
            Add an address to the final payload\n
            Standard method of adding the address at the end of the chain\n
            NOTE: addresses added this way are not changed by the offset provided when building the payload
        '''
        self._raw_payload.append(ROP_payload._addr(addr))

    def remove_last_added(self) -> None:
        '''
        Remove the last added element
        '''
        if len(self._raw_payload) > 0:
            self._raw_payload.pop()

    def build(self, chain_addr_offset: int = 0) -> bytes:
        '''
            Build payload bytes from this object\n
            Observations:
            * chain_addr_offset is added only to chain addresses, NOT to addresses added manually with add_addr()
        '''

        _t = self.logger.log_info("Building payload...", start_timer = True)

        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in self.forbidden_bytes:
                    return False

            return True

        replace_with_bytes = []
        # [(start index in final payload, custom bytes)]

        end_addrs = []
        # [end address for chain 0, ... end address for last chain]

        # preprocess the payload:
        #   * join adjacent chains
        #   * absorb padding, custom bytes, and addresses
        def _preprocess():

            _pad_total_offset = 0

            preproc_payload = []

            acc_chain: ROP_chain = None
            for item in self._raw_payload:

                if type(item) == ROP_payload._addr:

                    if acc_chain is None:
                        self.logger.log_warning("cannot associate address with a chain when building payload")
                        return None

                    end_addrs.append(item)
                    preproc_payload.append(acc_chain)

                    _pad_total_offset += acc_chain.end_sp_pos
                    acc_chain = None

                elif type(item) == ROP_chain:

                    if acc_chain is None:
                        acc_chain = item.duplicate()[0]

                    else:
                        acc_chain_aux = acc_chain.join(item)
                        acc_chain.remove_stack_ids()
                        acc_chain = acc_chain_aux

                        if acc_chain is None:
                            return None

                elif type(item) == bytes:

                    pad_offset = acc_chain.end_sp_pos + _pad_total_offset
                    pad_len = len(item)

                    pad_chain = ROP_chain()
                    pad_chain.effects.append(Effect.make_arith_ct_effect("add", "sp", pad_len))
                    pad_chain.valid_jump = True
                    pad_chain.valid_stack_access = True
                    pad_chain.end_sp_pos = len(item)

                    if acc_chain is None:
                        acc_chain = pad_chain

                    else:
                        acc_chain_aux = acc_chain.join(pad_chain)
                        acc_chain.remove_stack_ids()
                        acc_chain = acc_chain_aux

                        if acc_chain is None:
                            return None

                    replace_with_bytes.append((pad_offset, item))

            return preproc_payload

        preproc_payload = _preprocess()

        if preproc_payload is None:
            self.logger.log_warning(f"Could not join given chains (most likely, incompatible stacks)", end_timer = _t)
            return None, None

        b_mss = self.max_b_size

        payload = b''
        chain_start_addr = 0
        
        for idx in range(len(preproc_payload)):

            item = preproc_payload[idx]

            if type(item) is not ROP_chain:
                raise RuntimeError(f"unexpected item {item} when building payload")

            if b_mss < 8:
                self.logger.log_warning(f"Not enough payload length for constructing payload for a given chain: only {b_mss} bytes left", end_timer = _t)
            
            if len(end_addrs) == idx:
                self.logger.log_warning("Payload builder could not find an end address for the chain; returning chain with last jump unassigned...", end_timer = _t)
                return payload

            last_jump_addr = to_bytes(end_addrs[idx].addr)

            if _check_bytes(last_jump_addr) is False:
                self.logger.log_warning("Provided jump address contains forbidden bytes", end_timer = _t)
                return None, None

            payload_, start_addr = item._make_payload(max_stack_size = b_mss, forbidden_bytes = self.forbidden_bytes, 
                                                        addr_offset = chain_addr_offset, pad_sequence = self.pad_sequence, last_jump = end_addrs[idx].addr)
            if payload_ is not None:

                payload += payload_
                b_mss -= len(payload_)

                if b_mss < 0:
                    self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                    return None, None

                if idx == 0:
                    chain_start_addr = start_addr

            else:
                self.logger.log_warning("Creating payload for a given rop chain failed", end_timer = _t)
                return None, None

        # TODO check for incompatibility on the stack ?????
        # current implementation does not know whether it stepped over useful payload or not

        # replace pad with bytes
        for off_, content in replace_with_bytes:
            payload = payload[:off_] + content + payload[off_ + len(content):]

        self.logger.log_success("Successfully built the payload", end_timer = _t)

        return payload, chain_start_addr

# TODO reuse parts of it and remove
class _old_ROP_payload_x86_64:
    '''
        Class that implements the payload building API for x86_64
    '''

    class _alignment:

        # default alignment at the beginning of a payload
        DEFAULT_ALIGNMENT = 8

        SUPPORTED_ALIGNMENTS = [8, 16, 32, 64]
        
        def __init__(self, bound: int, is_aligned = False):

            self.bound = bound
            self.is_aligned = is_aligned

    class _addr:

        def __init__(self, addr: int):
            self.addr = addr

    def __init__(self, rop_searcher, output_handle = stdout):

        self.logger = Logger(session_name = "PAYLOAD BUILDER", output_handle = output_handle)
        self.rop_searcher: ROP_searcher = rop_searcher
        
        self.pad_sequence = b'A'
        self.max_b_size = 2**63
        self.forbidden_bytes: List[bytes] = []

        self._raw_payload: List[ROP_payload._addr | bytes | ROP_payload._alignment | ROP_chain] = []

    def set_forbidden_bytes(self, forbidden_bytes: List[bytes] = []) -> None:
        '''
            Specify the forbidden bytes that should not be found inside the payload bytes
        '''
        self.forbidden_bytes = forbidden_bytes

    def set_pad_sequence(self, pad_sequence = b'A') -> None:
        '''
            Set what padding sequence to use (default 'A' byte)\n
            For example, for the sequence b'1234', the padding of length 9 bytes will be b'123412341'
        '''
        self.pad_sequence = pad_sequence

    def set_max_size(self, max_byte_size: int = 2**63) -> None:
        '''
            Set the maximum payload byte length (default infinite)
        '''
        self.max_b_size = max_byte_size

    def add_chain(self, ch: ROP_chain) -> None:
        '''
            Add a chain to the payload
        '''
        self._raw_payload.append(ch)

    def add_bytes(self, b: bytes) -> None:
        '''
            Add custom bytes inside the payload
        '''
        self._raw_payload.append(b)

    def add_padding(self, pad_len: int)-> None:
        '''
            Add padding bytes of specified length
        '''
        l = 1 + (pad_len // len(self.pad_sequence))
        pad = self.pad_sequence * l
        self._raw_payload.append(pad[:pad_len])

    def add_addr(self, addr: int) -> None:
        '''
            Add an address to the final payload\n
            Standard method of adding the address at the end of the chain\n
            NOTE: addresses added this way are not changed by the offset provided when building the payload
        '''
        self._raw_payload.append(ROP_payload._addr(addr))

    def is_aligned_as(self, bound: int = 8) -> None:
        '''
            Overwrite automatically determined alignment with the value given in 'bound' argument\n
            It marks that the stack is aligned to that value, useful at the beginning of the payload, 
            when it is considered aligned to 8 byte boundary by default
        '''
        if bound not in ROP_payload._alignment.SUPPORTED_ALIGNMENTS:
            raise RuntimeError(f"Requested stack alignment of {bound} bytes is not supported")

        self._raw_payload.append(ROP_payload._alignment(bound, is_aligned = True))

    def align_as(self, bound: int = 8) -> None:
        '''
            Align the payload to a specific boundary (8, 16, 32, 64)\n
            It does that by adding 'RET'-only gadgets
        '''
        if bound not in ROP_payload._alignment.SUPPORTED_ALIGNMENTS:
            raise RuntimeError(f"Requested stack alignment of {bound} bytes is not supported")

        self._raw_payload.append(ROP_payload._alignment(bound, is_aligned = False))

    def remove_last_added(self) -> None:
        '''
        Remove the last added element
        '''
        if len(self._raw_payload) > 0:
            self._raw_payload.pop()

    def build(self, chain_addr_offset: int = 0) -> bytes:
        '''
            Build payload bytes from this object\n
            Observations:
            * chain_addr_offset is added only to chain addresses, NOT to addresses added manually with add_addr()
        '''

        _t = self.logger.log_info("Building payload...", start_timer = True)
        
        payload = b''

        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in self.forbidden_bytes:
                    return False

            return True

        # returns the (biggest) alignment
        def _check_alignment(to_check_len: int):
            
            for al in ROP_payload._alignment.SUPPORTED_ALIGNMENTS[::-1]:
                if to_check_len % al == 0:
                    return al

            return 0

        # searches for return address 
        # that does not contain forbidden bytes
        _cached_ret_addr = None
        def _get_ret_addr():

            nonlocal _cached_ret_addr
            
            if _cached_ret_addr is None:
                for ret_addr in self.rop_searcher.retonly_gadget.get_current_addrs():

                    b_ret_addr = to_bytes(ret_addr + chain_addr_offset)
                    if _check_bytes(b_ret_addr) is True:

                        _cached_ret_addr = b_ret_addr
                        break

            return _cached_ret_addr

        # preprocess the payload:
        #   * join adjacent chains
        def _preprocess():

            preproc_payload = [self._raw_payload[0]]

            for i in range(1, len(self._raw_payload)):

                if (type(preproc_payload[-1]) != ROP_chain) or (type(self._raw_payload[i]) != ROP_chain):
                    preproc_payload.append(self._raw_payload[i])

                elif (type(preproc_payload[-1]) == ROP_chain) and (type(self._raw_payload[i]) == ROP_chain):

                    aux_ch = preproc_payload[-1].join(self._raw_payload[i])
                    preproc_payload[-1].remove_stack_ids()
                    preproc_payload[-1] = aux_ch

                else:
                    raise RuntimeError(f"Encountered element of unknown type {type(self._raw_payload[i])} while trying to make payload")

            return preproc_payload

        preproc_payload = _preprocess()

        b_mss = self.max_b_size
        alignment_aux = ROP_payload._alignment.DEFAULT_ALIGNMENT
        
        for item in preproc_payload:

            if type(item) == bytes:

                if _check_bytes(item) is True:

                    payload += item
                    b_mss -= len(item)

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += len(item)
                    alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("Some given bytes for building payload contains forbidden bytes", end_timer = _t)
                    return None

            elif type(item) == ROP_payload._addr:

                b_item = to_bytes(item.addr)

                if _check_bytes(b_item) is True:

                    payload += b_item
                    b_mss -= 8

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += 8
                    alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("A given address for building payload contains forbidden bytes", end_timer = _t)
                    return None

            elif type(item) == ROP_payload._alignment:

                if item.is_aligned is False:
                    
                    current_alignment = _check_alignment(alignment_aux)
                    while current_alignment < item.bound:

                        b_ret_addr = _get_ret_addr()
                        if b_ret_addr is None:

                            self.logger.log_warning("Could not find return address for alignment that does not contain forbidden bytes", end_timer = _t)
                            return None

                        payload += b_ret_addr
                        b_mss -= 8

                        if b_mss < 0:
                            self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                            return None

                        alignment_aux += 8
                        alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]
                        current_alignment = _check_alignment(alignment_aux)

                else:
                    alignment_aux = item.bound

            elif type(item) == ROP_chain:

                if b_mss < 8:
                    self.logger.log_warning(f"Not enough payload length for constructing payload for a given chain: only {b_mss} bytes left", end_timer = _t)
                
                payload_ = item._make_payload(max_stack_size = b_mss // 8, forbidden_bytes = self.forbidden_bytes, 
                                                addr_offset = chain_addr_offset, pad_sequence = self.pad_sequence)
                if payload_ is not None:

                    payload += payload_
                    b_mss -= len(payload_)

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += len(payload_)
                    alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("Creating payload for a given rop chain failed", end_timer = _t)
                    return None

        self.logger.log_success("Successfully built the payload", end_timer = _t)

        return payload

from __future__ import annotations
from typing import Dict, Generator, List, Tuple, Set
# both above imports only for type hints

from copy import deepcopy
from random import randint
from sys import stdout

from parsebin import *
from utils import to_bytes, _is_int
from logger import Logger

from capstone import *
from z3 import *

# NOTE: this file (currently) only implements functionality for x86_64 ELF files
# NOTE: any "address"-related keyword used does NOT take into accound ASLR / PIE

# TODO: option to create chains from gadgets from different binaries
# TODO: support for AARCH64

class Platform:

    class _Platform:

        def __init__(self, arch):

            self.type = arch

            if arch == "x86_64":
                
                self.SUPPORTED_REGS = ["rax", "rbx", "rcx", "rdx", "rsi", "rdi", "rbp",
                                        "r8", "r9", "r10", "r11", "r12", "r13", "r14", "r15"]

                self.IGNORED_INSTR_MNEMONICS = ["endbr64", "clc", "cld", "cldemote", "clflush", "clflushopt", 
                                                "cli", "clts", "clwb", "cmc", "fnop", "vzeroupper", "nop"]

                self.ENDPOINTS = { b'\xc3': "ret", b'\xff\xe0': "jmp rax", b'\xff\xe3': "jmp rbx", b'\xff\xe1': "jmp rcx", 
                    b'\xff\xe2': "jmp rdx", b'\xff\xe5': "jmp rbp", b'\xff\xe6': "jmp rsi", b'\xff\xe7': "jmp rdi", 
                    b'\x41\xff\xe0': "jmp r8", b'\x41\xff\xe1': "jmp r9", b'\x41\xff\xe2': "jmp r10", b'\x41\xff\xe3': "jmp r11", 
                    b'\x41\xff\xe4': "jmp r12", b'\x41\xff\xe5': "jmp r13", b'\x41\xff\xe6': "jmp r14", b'\x41\xff\xe7': "jmp r15" }

                self.RET_OPCODE = b'\xc3'

            elif arch == "aarch64":

                self.SUPPORTED_REGS = []
                self.IGNORED_INSTR_MNEMONICS = []

                self.ENDPOINTS = {}

                self.RET_OPCODE = b''

            else:
                raise RuntimeError(f"Unsupported platform {arch}")

    X86_64 = _Platform("x86_64")
    AARCH64 = _Platform("aarch64")

# NOT YET USED
# retain the constants found during instruction analysis
# for optimising automatic rop chain generator
_existent_constants = set()

# class that stores any kind of entity that can have a value
# eg. stack bytes, registers, register value "snapshot" at some point of execution, and so on
# the design choice of using such an ambiguous class 
# is based on the fact that the implementation is way easier to understand, to extend, or to modify
# compared to the situation in which every use case of this class would get its own class
class _structured_element:

    # dictionary of currently used structured elements types
    # {"ELEMENT_TYPE": [info param 1 type / info param 1 name, ...]}
    # NOTE: the fields described here only represent the keys of the self.info dict
    #       populating it with the corresponding (valid) values is the programmer's responsability
    ELEMENT_TYPES = {"64b_stack_val": ["id"],               # integer value from the stack, pointed by an id
                        "ct_val": ["value"],                # integer constant (non-stack / non-register) value

                        "reg_in": ["reg_name"],             # register value at the beginning of a gadget / chain
                        "reg_out": ["reg_name"],            # register value after executing a gadget / chain
                        
                        "add": ["term_1", "term_2"],        # arithmetic operations (can be recursive)
                        "sub": ["term_1", "term_2"],                    
                        "and": ["term_1", "term_2"], 
                        "or": ["term_1", "term_2"],
                        "xor": ["term_1", "term_2"],
                        "neg": ["term_1", "term_2"],        # for negation, term2 will always be None

                        "64b_stack_pad": []                 # marks padding (random value) for the stack view
                    }
    
    @staticmethod
    def instantiate_structured_element(element_type: str):

        if element_type not in _structured_element.ELEMENT_TYPES.keys():
            raise RuntimeError(f"Cannot automatically instantiate _structured_element with type {element_type}")
        
        element = _structured_element(element_type)
        for info_field in _structured_element.ELEMENT_TYPES[element_type]:
            element.info.update({info_field: None})

        return element
    
    def __init__(self, element_type: str):
        self.type = element_type
        self.info = {}

    def is_op(self):
        return self.type in ["add", "sub", "and", "or", "xor", "neg"]

    # mostly for debugging purposes
    def __str__(self):
        info_s = {str(k): str(v) for k, v in self.info.items()}
        return f"element type {self.type}, info {info_s}"

# class to simulate the real stack on which a gadget or chain is executed
class _64b_stack_view:

    # retain all the stack elements id's and their value
    # INCLUDING THE RETURN ADDRESSES
    stack_values = {}

    # stack id to uniquely identify the (same) stack values
    # INCLUDING THE RETURN ADDRESSES
    stack_id_cnt = 0

    def __init__(self):
        self.elements: List[_structured_element] = []

    def push(self, element: _structured_element):
        self.elements.append(element)

    @staticmethod
    def get_elem_id():

        to_deliver = _64b_stack_view.stack_id_cnt

        _64b_stack_view.stack_id_cnt += 1
        _64b_stack_view.stack_values.update({to_deliver: None})
        
        return to_deliver

    # returns a joined stack
    # does NOT deepcopy
    @staticmethod
    def join_stacks(fst: _64b_stack_view, snd: _64b_stack_view):

        res = _64b_stack_view()
        res.elements = fst.elements + snd.elements
        return res
            
    # mostly for debugging purposes
    def __str__(self):
        return f"stack view with elements {[str(el) for el in self.elements]}"

# class to store the semantics of all the gadgets
# again, some ambiguity is intentionally provided, for same reasoning as the above mentioned classes
# but it has some constrains:
#   * every effect has an id that should be part of an implementation convention
#   * the effect, if seen as an operation, stores the result value in a single destination element (currently, by convention, only registers)
class _effect:

    # if true, arith match is done by thecking operation trees, method invariant only to commutativity
    #           no false positives, lots of false negatives, 
    # if false, arith match is done by giving random inputs to registers,
    #           and eventually tring to adjust the checked effect stack values to match
    #           some false positives, no false negatives
    ARITH_EXACT_MATCH = False

    # indicates the number of (random) tests to be done
    # ignored if ARITH_EXACT_MATCH is True
    ARITH_P_TEST_CNT = 30

    # dictionary of currently used effect types
    # {"EFFECT_TYPE": (destination_element type, [param1 type, ...]), ...}
    # NOTE: ARITH type has parameter type configurable: "<op>"
    EFFECT_TYPES = {"LOAD_S": ("reg_out", ["64b_stack_val"]),       # load value in register from the stack (RSP value increase NOT included)
                    "LOAD_CT": ("reg_out", ["ct_val"]),             # load value that is constant (that does not originate from registers or stack)
                    "MOV_RR": ("reg_out", ["reg_in"]),              # copying value from one register to another
                    "ARITH": ("reg_out", []),                       # operations (add, sub, bitewise operations, etc) - the PARAMS are not included
                    "ADD_SP": (None, ["ct_val"]),                  # separate effect indicating incrementing RSP (with a constant value only)
                    "NO_OP": (None, [])                             # no operation
                    }

    @staticmethod
    def instantiate_effect(effect_type: str):
     
        if effect_type not in _effect.EFFECT_TYPES.keys():
            raise RuntimeError(f"Cannot automatically instantiate _effect with type {effect_type}")

        effect = _effect(effect_type, None, [])

        dest_type, param_type_list = _effect.EFFECT_TYPES[effect_type]

        if dest_type is not None:
            effect.destination_element = _structured_element.instantiate_structured_element(dest_type)
        
        for param_type in param_type_list:
            effect.params.append(_structured_element.instantiate_structured_element(param_type))

        return effect

    # common code lines between any location (at least when interpreting instructions)
    # for creating an effect that marks an arithmetic operation with a constant
    # NOTE: no checks are done
    @staticmethod
    def make_arith_ct_effect(op_type: str, dest_reg_name: str, constant: int):

        arith_op_ct_effect = _effect.instantiate_effect("ARITH")
        arith_op_ct_effect.destination_element.info["reg_name"] = dest_reg_name

        arith_op_ct_effect.params.append(_structured_element.instantiate_structured_element(op_type))

        arith_op_ct_effect.params[0].info["term_1"] =  _structured_element.instantiate_structured_element("reg_in")
        arith_op_ct_effect.params[0].info["term_2"] =  _structured_element.instantiate_structured_element("ct_val")
        arith_op_ct_effect.params[0].info["term_1"].info["reg_name"] = dest_reg_name
        arith_op_ct_effect.params[0].info["term_2"].info["value"] = constant

        _existent_constants.add(constant)

        return arith_op_ct_effect

    # same as make_arith_ct_effect but for operations with (only) registers
    # NOTE: no checks are done
    @staticmethod
    def make_arith_reg_effect(op_type: str, dest_reg_name: str, src_reg_name: str):

        arith_op_reg_effect = _effect.instantiate_effect("ARITH")
        arith_op_reg_effect.destination_element.info["reg_name"] = dest_reg_name

        arith_op_reg_effect.params.append(_structured_element.instantiate_structured_element(op_type))

        arith_op_reg_effect.params[0].info["term_1"] =  _structured_element.instantiate_structured_element("reg_in")
        arith_op_reg_effect.params[0].info["term_2"] =  _structured_element.instantiate_structured_element("reg_in")
        arith_op_reg_effect.params[0].info["term_1"].info["reg_name"] = dest_reg_name
        arith_op_reg_effect.params[0].info["term_2"].info["reg_name"] = src_reg_name

        return arith_op_reg_effect

    @staticmethod
    def make_arith_custom_effect(dest_reg_name: str, custom_element: _structured_element):

        arith_effect = _effect.instantiate_effect("ARITH")
        arith_effect.destination_element.info["reg_name"] = dest_reg_name
        arith_effect.params.append(custom_element)

        return arith_effect

    @staticmethod
    def make_load_ct_effect(dest_reg_name: str, constant: int):

        load_ct_effect = _effect.instantiate_effect("LOAD_CT")
        load_ct_effect.destination_element.info["reg_name"] = dest_reg_name
        load_ct_effect.params[0].info["value"] = constant

        _existent_constants.add(constant)

        return load_ct_effect

    @staticmethod
    def make_load_s_effect(dest_reg_name: str):

        load_s_effect = _effect.instantiate_effect("LOAD_S")
        load_s_effect.destination_element.info["reg_name"] = dest_reg_name
        load_s_effect.params[0].info["id"] = _64b_stack_view.get_elem_id()

        return load_s_effect

    @staticmethod
    def make_mov_rr_effect(dest_reg_name: str, src_reg_name: str):

        mov_rr_effect = _effect.instantiate_effect("MOV_RR")
        mov_rr_effect.destination_element.info["reg_name"] = dest_reg_name
        mov_rr_effect.params[0].info["reg_name"] = src_reg_name

        return mov_rr_effect

    @staticmethod
    def make_neg_effect(dest_reg_name: str):

        arith_neg_effect = _effect.instantiate_effect("ARITH")
        arith_neg_effect.destination_element.info["reg_name"] = dest_reg_name

        arith_neg_effect.params.append(_structured_element.instantiate_structured_element("neg"))

        arith_neg_effect.params[0].info["term_1"] =  _structured_element.instantiate_structured_element("reg_in")
        arith_neg_effect.params[0].info["term_1"].info["reg_name"] = dest_reg_name

        return arith_neg_effect

    @staticmethod
    def make_add_rsp_effect(constant: int):

        add_rsp_effect = _effect.instantiate_effect("ADD_SP")
        add_rsp_effect.params[0].info["value"] = constant

        # this constant is NOT added into known constants cache
        # because is limited in interacting only with SP

        return add_rsp_effect

    def __init__(self, effect_type: str, destination_element: _structured_element, params: List[_structured_element]):

        self.type: str = effect_type
        self.destination_element: _structured_element = destination_element
        self.params: List[_structured_element] = params

    # currently uses Z3: https://github.com/Z3Prover/z3
    def _match_arith(self, checked_ef: _effect):

        if self.destination_element.info["reg_name"] != checked_ef.destination_element.info["reg_name"]:
            return False

        # possible type pairs (wanted_ef, checked_ef):
        # ARITH, ARITH
        # MOV_RR, ARITH
        # LOAD_CT, ARITH
        # NOTE: if the WANTED EFFECT is of type ARITH, it is assumed it does NOT contain stack elements

        # match the operation trees, taking into account only commutativity of some operations
        def _tree_match(wanted_ef: _structured_element, checked_ef: _structured_element):

            if (wanted_ef is None) and (checked_ef is None):
                return True

            if wanted_ef.type != checked_ef.type:
                return False
            
            if wanted_ef.type == "64b_stack_val":

                if (_64b_stack_view.stack_values[checked_ef.info["id"]] == _64b_stack_view.stack_values[wanted_ef.info["id"]]) \
                    or (_64b_stack_view.stack_values[checked_ef.info["id"]] is None):

                    if checked_ef.info["id"] != wanted_ef.info["id"]:

                        val = _64b_stack_view.stack_values[wanted_ef.info["id"]]
                        _64b_stack_view.stack_values.pop(wanted_ef.info["id"])
                        
                        wanted_ef.info["id"] = checked_ef.info["id"]
                        _64b_stack_view.stack_values[checked_ef.info["id"]] = val

                    return True

                else:
                    return False

            if wanted_ef.type == "reg_in":
                return wanted_ef.info["reg_name"] == checked_ef.info["reg_name"]

            if wanted_ef.type == "ct_val":
                return wanted_ef.info["value"] == checked_ef.info["value"]

            if wanted_ef.type in ["sub", "neg"]:
                return _tree_match(wanted_ef.info["term_1"], checked_ef.info["term_1"]) and _tree_match(wanted_ef.info["term_2"], checked_ef.info["term_2"])

            if wanted_ef.is_op():
                return (_tree_match(wanted_ef.info["term_1"], checked_ef.info["term_1"]) and _tree_match(wanted_ef.info["term_2"], checked_ef.info["term_2"])) or\
                        (_tree_match(wanted_ef.info["term_2"], checked_ef.info["term_1"]) and _tree_match(wanted_ef.info["term_1"], checked_ef.info["term_2"]))

            raise RuntimeError(f"trying to match trees with unknown types: {wanted_ef.type}")

        # probabilistic match
        def _probabilistic_match(wanted_ef: _effect, checked_ef: _effect):

            stack_ids = set()
            reg_in_elements = {}

            # in case of stack assignments, z3 solver is used
            z3_solver = z3.Solver()
            
            # simulates the execution of the arith effect
            def _simulate(op_element: _structured_element, local_stack_values: Dict[int, int], reg_start_values: Dict[str, int]):
        
                if op_element.type == "64b_stack_val":
                    return local_stack_values[op_element.info["id"]]

                if op_element.type == "ct_val":
                    return op_element.info["value"]

                if op_element.type == "reg_in":
                    return reg_start_values[op_element.info["reg_name"]]

                if op_element.type == "add":
                    return _simulate(op_element.info["term_1"], local_stack_values, reg_start_values) +\
                            _simulate(op_element.info["term_2"], local_stack_values, reg_start_values)
                
                if op_element.type == "sub":
                    return _simulate(op_element.info["term_1"], local_stack_values, reg_start_values) -\
                            _simulate(op_element.info["term_2"], local_stack_values, reg_start_values)

                if op_element.type == "and":
                    return _simulate(op_element.info["term_1"], local_stack_values, reg_start_values) &\
                            _simulate(op_element.info["term_2"], local_stack_values, reg_start_values)

                if op_element.type == "or":
                    return _simulate(op_element.info["term_1"], local_stack_values, reg_start_values) |\
                            _simulate(op_element.info["term_2"], local_stack_values, reg_start_values)

                if op_element.type == "xor":
                    return _simulate(op_element.info["term_1"], local_stack_values, reg_start_values) ^\
                            _simulate(op_element.info["term_2"], local_stack_values, reg_start_values)

                if op_element.type == "neg":
                    return ~(_simulate(op_element.info["term_1"], local_stack_values, reg_start_values))

            # function that folds over the ARITH expression tree 
            # and updates the z3 solver
            _aux_id = 0
            def _convert_to_z3_expr(el: _structured_element):
                
                nonlocal _aux_id

                if el.type == "64b_stack_val":

                    val = _64b_stack_view.stack_values[el.info["id"]]
                    if val is not None:

                        conv_el = BitVec(f"c{_aux_id}", 64)
                        z3_solver.add(conv_el == val)

                        return conv_el
                    
                    else:
                        return BitVec(f"stack{el.info['id']}", 64)

                else:

                    conv_el = BitVec(f"c{_aux_id}", 64)
                    _aux_id += 1
                    
                    if el.type == "ct_val":
                        z3_solver.add(conv_el == el.info["value"])

                    elif el.type == "reg_in":
                        z3_solver.add(conv_el == reg_in_elements[el.info["reg_name"]])

                    elif el.type == "neg":
                        
                        t = _convert_to_z3_expr(el.info["term_1"])
                        z3_solver.add(conv_el == ~t)

                    elif el.is_op():

                        t1 = _convert_to_z3_expr(el.info["term_1"])
                        t2 = _convert_to_z3_expr(el.info["term_2"])

                        if el.type == "add":
                            z3_solver.add(conv_el == t1 + t2)

                        elif el.type == "sub":
                            z3_solver.add(conv_el == t1 - t2)

                        elif el.type == "and":
                            z3_solver.add(conv_el == t1 & t2)

                        elif el.type == "or":
                            z3_solver.add(conv_el == t1 | t2)

                        elif el.type == "xor":
                            z3_solver.add(conv_el == t1 ^ t2)

                    return conv_el

            # method that determines whether the checked expression has unassigned stack elements or not
            # and if it has, initialize them as keys in the stack_elements_assignments dictionary
            # also, it retains the reg_in elements used
            def _check_stack_elements(el: _structured_element):

                if el is None:
                    return False

                if el.type == "64b_stack_val":
                    
                    if _64b_stack_view.stack_values[el.info["id"]] is None:

                        stack_ids.add(el.info["id"])
                        return True

                    return False

                elif el.type == "reg_in":

                    reg_in_elements.update({el.info["reg_name"]: None})
                    return False

                elif el.type == "ct_val":
                    return False

                elif el.is_op():

                    checked_1 = _check_stack_elements(el.info["term_1"])
                    checked_2 = _check_stack_elements(el.info["term_2"])

                    return checked_1 or checked_2

                raise RuntimeError(f"unknown element type {el.type} when trying to match arith")

            stack_elements_found_inwanted = _check_stack_elements(wanted_ef.params[0])
            if stack_elements_found_inwanted is True:
                raise RuntimeError("stack element found in wanted effect")

            stack_elements_found = _check_stack_elements(checked_ef.params[0])

            for _ in range(_effect.ARITH_P_TEST_CNT):

                for reg_in in reg_in_elements.keys():
                    reg_in_elements[reg_in] = randint(0, 2 ** 64)

                wanted_ef_val = 0

                if wanted_ef.type == "MOV_RR":
                    wanted_ef_val = reg_in_elements[wanted_ef.params[0].info["reg_name"]]

                elif wanted_ef.type == "LOAD_CT":
                    wanted_ef_val = wanted_ef.params[0].info["value"]

                elif wanted_ef.type == "ARITH":
                    wanted_ef_val = _simulate(wanted_ef.params[0], _64b_stack_view.stack_values, reg_in_elements)

                # the checked_ef has no stack id to be assigned a value, only to compute the result based on reg_in values
                if stack_elements_found is False:

                    checked_ef_val = _simulate(checked_ef.params[0], _64b_stack_view.stack_values, reg_in_elements)
                    if checked_ef_val != wanted_ef_val:
                        return False

                else:
                    # there are unknown stack values that need to be assigned a value
                    # before proceeding in checking the matching

                    z3_expr = _convert_to_z3_expr(checked_ef.params[0])
                    z3_solver.add(z3_expr == wanted_ef_val)

            # checking for stack element possible assignments 
            # so that checked_ef matches wanted_ef
            if stack_elements_found is True:

                if z3_solver.check() == z3.sat:

                    sm = z3_solver.model()
                    for stack_elem_id in stack_ids:

                        z3_stack_elem = BitVec(f"stack{stack_elem_id}", 64)
                        val = sm[z3_stack_elem]

                        if val is not None:
                            _64b_stack_view.stack_values[stack_elem_id] = val.as_long()
                        #else:
                            # irrelevant element, add some padding
                         #   _64b_stack_view.stack_values[stack_elem_id] = int.from_bytes(b'A' * 8, 'little')

                else:
                    return False

            return True
        
        if _effect.ARITH_EXACT_MATCH is True:
            return _tree_match(self, checked_ef)
        else:
            return _probabilistic_match(self, checked_ef)

    # function that matches two effects
    # NOTE: when matching with LOAD_S effects, self stack element ID is changed
    def match(self, g_effect: _effect):

        if self.destination_element.info["reg_name"] != g_effect.destination_element.info["reg_name"]:
            return False

        if self.type == "ARITH" or g_effect.type == "ARITH":
            return self._match_arith(g_effect)
        
        # LOAD_S is intentionally restricted to only other LOAD_S effects, for an efficient/ fast search
        # if one wants to have all the possible ways of loading a value in a register, LOAD_CT matching should be chosen instead
        if self.type == "LOAD_S":
            
            if g_effect.type != "LOAD_S":
                return False
            
            # either the wanted effect has the same value as the stack element (none or int value)
            # or the vanted effect has a concrete value and the stack element is none, case in which stack value is assigned the wanted one
            # or both the stack and the wanted elements have non-none values, but are different, case in which it fails
            # in any case it succeeds, the wanted value id <- the stack id
            if (_64b_stack_view.stack_values[g_effect.params[0].info["id"]] == _64b_stack_view.stack_values[self.params[0].info["id"]]) \
                or (_64b_stack_view.stack_values[g_effect.params[0].info["id"]] is None):

                if g_effect.params[0].info["id"] != self.params[0].info["id"]:

                    val = _64b_stack_view.stack_values[self.params[0].info["id"]]
                    _64b_stack_view.stack_values.pop(self.params[0].info["id"])

                    self.params[0].info["id"] = g_effect.params[0].info["id"]
                    _64b_stack_view.stack_values[g_effect.params[0].info["id"]] = val

                return True

            else:
                return False

        elif self.type == "LOAD_CT":
            
            if g_effect.type == "LOAD_CT":

                if g_effect.params[0].info["value"] != self.params[0].info["value"]:
                    return False
                return True

            elif g_effect.type == "LOAD_S":

                if (_64b_stack_view.stack_values[g_effect.params[0].info["id"]] == self.params[0].info["value"]) \
                    or (_64b_stack_view.stack_values[g_effect.params[0].info["id"]] is None):

                    _64b_stack_view.stack_values[g_effect.params[0].info["id"]] = self.params[0].info["value"]
                    return True
            
                return False

            return False

        elif self.type == "MOV_RR":
            
            if g_effect.type == "MOV_RR":

                if self.params[0].info["reg_name"] != g_effect.params[0].info["reg_name"]:
                    return False
                return True

            return False

        raise RuntimeError(f"trying to match types {self.type}, {g_effect.type}")
    
    # method that converts each dissasembled instruction provided by Capstone into effects
    # it is also responsible for checking the validity of the instruction
    @staticmethod
    def analyse_instr(instr: CsInsn, platform: Platform):

        def _analyse_x86_64_instr():

            # separate the arguments from instr.op_str
            def _get_2_args(op_str: str):

                mov_args = op_str.split(",")
                    
                if len(mov_args) != 2:
                    return None, None

                dest = mov_args[0].strip()
                src = mov_args[1].strip()

                return dest, src

            # checks whether the instruction effects 
            # are ignored (from the point of view of this algorithm)
            # and are treated as NOP
            def _ignored_instr(instr: CsInsn):

                if instr.mnemonic in platform.IGNORED_INSTR_MNEMONICS:
                    return True

                return False
            
            try:

                instr_effects = []

                mnemonic = instr.mnemonic

                if mnemonic == "pop":

                    if instr.op_str not in platform.SUPPORTED_REGS:
                        return None

                    load_s_effect = _effect.make_load_s_effect(instr.op_str)
                    add_rsp_effect = _effect.make_add_rsp_effect(8)

                    instr_effects.append(load_s_effect)
                    instr_effects.append(add_rsp_effect)

                elif mnemonic == "mov":
                    
                    dest, src = _get_2_args(instr.op_str)

                    if dest not in platform.SUPPORTED_REGS:
                        return None

                    # TODO: add mov r, rsp support
                    # TODO: add 32b / 16b registers support (at least for some cases)

                    if src not in platform.SUPPORTED_REGS:

                        int_src = _is_int(src)
                        if int_src is None:
                            
                            if src == "qword ptr [rsp]":
                                load_s_effect = _effect.make_load_s_effect(dest)
                                instr_effects.append(load_s_effect)
                            else:
                                return None
                        else:
                            load_ct_effect = _effect.make_load_ct_effect(dest, int_src)
                            instr_effects.append(load_ct_effect)

                    else:
                        mov_rr_effect = _effect.make_mov_rr_effect(dest, src)
                        instr_effects.append(mov_rr_effect)

                elif mnemonic == "xchg":

                    r1, r2 = _get_2_args(instr.op_str)

                    if (r1 not in platform.SUPPORTED_REGS) or (r2 not in platform.SUPPORTED_REGS):
                        return None

                    if r1 == r2:

                        nop_effect = _effect.instantiate_effect("NO_OP")
                        instr_effects.append(nop_effect)

                    else:
                    
                        mov_rr_effect1 = _effect.make_mov_rr_effect(r1, r2)
                        mov_rr_effect2 = _effect.make_mov_rr_effect(r2, r1)

                        instr_effects.append(mov_rr_effect1)
                        instr_effects.append(mov_rr_effect2)

                elif mnemonic in ["add", "sub"]:

                    dest, src = _get_2_args(instr.op_str)

                    if (dest not in platform.SUPPORTED_REGS) and (dest != "rsp"):
                        return None

                    if dest == "rsp":

                        if mnemonic != "add":
                            return None

                        int_src = _is_int(src)

                        if (int_src is None) or (int_src % 8 != 0):
                            return None

                        add_rsp_effect = _effect.make_add_rsp_effect(int_src)
                        instr_effects.append(add_rsp_effect)

                    elif src in platform.SUPPORTED_REGS:
                        
                        arith_add_reg_effect = _effect.make_arith_reg_effect(mnemonic, dest, src)
                        instr_effects.append(arith_add_reg_effect)
                        
                    else:
                        
                        int_src = _is_int(src)

                        if int_src is None:
                            return None

                        op_type = "add"
                        if (int_src < 0 and mnemonic == "add") or (int_src >= 0 and mnemonic == "sub"):
                            op_type = "sub"

                        arith_add_ct_effect = _effect.make_arith_ct_effect(op_type, dest, int_src)
                        instr_effects.append(arith_add_ct_effect)

                elif mnemonic in ["dec", "inc"]:
                    
                    dest = instr.op_str

                    if dest not in platform.SUPPORTED_REGS:
                        return None

                    op_type = "sub"
                    if mnemonic == "inc":
                        op_type = "add"

                    arith_1_effect = _effect.make_arith_ct_effect(op_type, dest, 1)
                    instr_effects.append(arith_1_effect)

                elif mnemonic == "neg":
                    
                    if instr.op_str not in platform.SUPPORTED_REGS:
                        return None

                    arith_neg_effect = _effect.make_neg_effect(instr.op_str)
                    instr_effects.append(arith_neg_effect)

                elif mnemonic in ["and", "or", "xor"]:
                    
                    dest, src = _get_2_args(instr.op_str)

                    if dest not in platform.SUPPORTED_REGS:
                        return None

                    if src not in platform.SUPPORTED_REGS:

                        int_src = _is_int(src)

                        if int_src is None:
                            return None
                        
                        arith_bitwise_ct_effect = _effect.make_arith_ct_effect(mnemonic, dest, int_src)
                        instr_effects.append(arith_bitwise_ct_effect)

                    else:
                        # particular case xor r, r <=> mov r, 0
                        if dest == src:

                            load_0_effect = _effect.make_load_ct_effect(dest, 0)
                            instr_effects.append(load_0_effect)

                        else:
                            arith_bitwise_reg_effect = _effect.make_arith_reg_effect(mnemonic, dest, src)
                            instr_effects.append(arith_bitwise_reg_effect)
                        
                elif mnemonic == "nop" or _ignored_instr(instr):
                    
                    nop_effect = _effect.instantiate_effect("NO_OP")
                    instr_effects.append(nop_effect)

                else:
                    return None

                return instr_effects          

            except Exception:
                return None

        if platform is Platform.X86_64:
            return _analyse_x86_64_instr()

        elif platform is Platform.AARCH64:
            raise RuntimeError("not yet implemented")

        else:
            raise RuntimeError(f"unsupported platform {platform}")

    # method responsible for creating a gadget from separate (but ordered) instruction effects
    # the joining should resemble joining effects when building (yet to be implemented) rop chains from gadgets
    @staticmethod
    def join_instr_effects(ordered_effects: List[List[_effect]]):
        
        # depth-first exploration of <op>-type _structured_element arithmetic tree
        # yielding every _structured_element of type "reg_in"
        def _recursive_arith_exploration(element: _structured_element):
        
            if element.type == "reg_in":
                yield element

            elif element.is_op():
                
                if element.info["term_1"] is not None:
                    for reg_in_elem in _recursive_arith_exploration(element.info["term_1"]):
                        yield reg_in_elem

                if element.info["term_2"] is not None:
                    for reg_in_elem in _recursive_arith_exploration(element.info["term_2"]):
                        yield reg_in_elem
        
        # eliminate from the joined list effects such as NO_OP or "move r_i, r_i"
        def _ignored_effect(ef: _effect):

            if ef.type in ["NO_OP", "ADD_SP"]:
                return True

            if ef.type == "MOV_RR" and ef.destination_element.info["reg_name"] == ef.params[0].info["reg_name"]:
                return True

            return False

        if len(ordered_effects) == 0:
            return None

        # position of rsp in the stack view, considering 64 bit elements (real rsp byte offset = sp_pos * 8 bytes)
        sp_pos = 0
        acc_effects: List[_effect] = []
        acc_stack = _64b_stack_view()

        # the joining (currently) has 7 steps
        #
        #   1) initialize the joined effects list with the second effects list
        #   2) update the stack by analysing LOAD_S and ADD_SP effects
        #   3) for every instruction in the joined effects list, 
        #       replace every "reg_in" with the corresponding "reg_out" from the first effects list
        #   4) copy every effect from the first effects list into the joined effects list, that has the destination reg
        #       different from any other destination reg from the joined effects list,
        #       and also skip NO_OP and ADD_SP effects
        #   5) (optionally) iterate over all effects from the joined effects list and filter them
        #       so that effects of type move ri, ri are eliminated, or for simplifying arithmetic effects
        #   6) the first effects list is assigned the newly created joined effects list, and the loop continues 
        #       until all effect lists are processed
        #   7) a new gadget is created with the final effects list and the obtained stack, some validity constraints are imposed
        #       and, optionally, other optimizations

        # NOTE: no two effects from a single effect list contain the same destination register
        #       proof by induction: base case assured by the analyse_instr, 
        #                           induction step proven by the rest of the current algorithm's steps

        for i in range(len(ordered_effects)):
            
            # step 1)
            new_acc_effect_list = deepcopy(ordered_effects[i])

            # step 2)
            for ef in new_acc_effect_list:

                if ef.type == "LOAD_S":
                    
                    if sp_pos == len(acc_stack.elements):

                        acc_stack.push(_structured_element.instantiate_structured_element("64b_stack_val"))
                        acc_stack.elements[sp_pos].info["id"] = ef.params[0].info["id"]

                    else:
                        ef.params[0].info["id"] = acc_stack.elements[sp_pos].info["id"]

                elif ef.type == "ADD_SP":
                    
                    inc_pos_cnt = ef.params[0].info["value"] // 8

                    while inc_pos_cnt > 0:

                        if sp_pos == len(acc_stack.elements):
                            acc_stack.push(_structured_element.instantiate_structured_element("64b_stack_pad"))

                        sp_pos += 1
                        inc_pos_cnt -= 1

            # step 3)
            for ef in new_acc_effect_list:

                if ef.type == "MOV_RR":
                    
                    reg_in_name = ef.params[0].info["reg_name"]

                    corresp_before_ef = None
                    for before_ef in acc_effects:

                        if before_ef.destination_element.info["reg_name"] == reg_in_name:
                            corresp_before_ef = before_ef
                            break

                    if corresp_before_ef is not None:
                        
                        if corresp_before_ef.type == "MOV_RR":
                            ef.params[0].info["reg_name"] = corresp_before_ef.params[0].info["reg_name"]

                        elif corresp_before_ef.type in ["ARITH", "LOAD_S", "LOAD_CT"]:
                            
                            # example for ARITH, analogous for rest
                            # r1 = t1 <op> t2
                            # r2 = r1
                            # joined (for r2): r2 = t1 <op> t2

                            ef.type = corresp_before_ef.type
                            ef.params = deepcopy(corresp_before_ef.params)

                elif ef.type == "ARITH":
                    
                    expr = ef.params[0]
                    for reg_in_elem in _recursive_arith_exploration(expr):
                        
                        reg_in_name = reg_in_elem.info["reg_name"]

                        corresp_before_ef = None
                        for before_ef in acc_effects:

                            if before_ef.destination_element.info["reg_name"] == reg_in_name:
                                corresp_before_ef = before_ef
                                break

                        if corresp_before_ef is not None:

                            if corresp_before_ef.type == "LOAD_S":

                                reg_in_elem.type = "64b_stack_val"
                                reg_in_elem.info = {"id": corresp_before_ef.params[0].info["id"]}

                            elif corresp_before_ef.type == "LOAD_CT":
                                
                                reg_in_elem.type = "ct_val"
                                reg_in_elem.info = {"value": corresp_before_ef.params[0].info["value"]}

                            elif corresp_before_ef.type == "MOV_RR":
                                reg_in_elem.info["reg_name"] = corresp_before_ef.params[0].info["reg_name"]

                            elif corresp_before_ef.type == "ARITH":
                                
                                reg_in_elem.type = corresp_before_ef.params[0].type
                                reg_in_elem.info = deepcopy(corresp_before_ef.params[0].info)
        
            # step 4) and 5)
            for before_ef in acc_effects:
                if before_ef.destination_element is not None:

                    before_ef_dest_reg_name = before_ef.destination_element.info["reg_name"]

                    overridden = False
                    for ef in new_acc_effect_list:

                        if (ef.destination_element is not None) and (ef.destination_element.info["reg_name"] == before_ef_dest_reg_name):
                            overridden = True

                    if overridden is False:
                        new_acc_effect_list.append(before_ef)
                    
            # step 5) and 6)
            acc_effects.clear()
            for ef in new_acc_effect_list:
                
                if _ignored_effect(ef) is False:
                    acc_effects.append(ef)

        # step 7)
        acc_effects_filtered = []
        for ef in acc_effects:
            
            if _ignored_effect(ef) is False:
                acc_effects_filtered.append(ef)
                
        # the rsp must be at the end of the stack view, 
        # so that the return address of the gadget can be added
        if sp_pos != len(acc_stack.elements):
            return None

        gadget = ROP_gadget()

        # return address for the next gadget / function
        acc_stack.push(_structured_element.instantiate_structured_element("64b_stack_val"))
        acc_stack.elements[sp_pos].info["id"] = _64b_stack_view.get_elem_id()
        sp_pos += 1

        gadget.stack = acc_stack
        gadget.effects = acc_effects_filtered

        return gadget

    # method responsible for joining two effects list
    # does NOT make any deep copy - fst and snd should be created copies
    # resembles join_instr_effects, but:
    #   * does not take any stack into consideration
    #   * returns a list of effects, not a gadget
    #   * only two effects list can be joined at a time
    @staticmethod
    def join_effects(fst: List[_effect], snd: List[_effect]):

        if len(fst) == 0 or len(snd) == 0:
            return fst + snd

        # depth-first exploration of <op>-type _structured_element arithmetic tree
        # yielding every _structured_element of type "reg_in"
        def _recursive_arith_exploration(element: _structured_element):
        
            if element.type == "reg_in":
                yield element

            elif element.is_op():
                
                if element.info["term_1"] is not None:
                    for reg_in_elem in _recursive_arith_exploration(element.info["term_1"]):
                        yield reg_in_elem

                if element.info["term_2"] is not None:
                    for reg_in_elem in _recursive_arith_exploration(element.info["term_2"]):
                        yield reg_in_elem
        
        # eliminate from the joined list effects such as NO_OP or "move r_i, r_i"
        def _ignored_effect(ef: _effect):

            if ef.type in ["NO_OP", "ADD_SP"]:
                return True

            if ef.type == "MOV_RR" and ef.destination_element.info["reg_name"] == ef.params[0].info["reg_name"]:
                return True

            return False
            
        res = snd

        # replacing every reg_in from res(=snd) with corresponding reg_out from fst
        for ef in res:

            if ef.type == "MOV_RR":
                
                reg_in_name = ef.params[0].info["reg_name"]

                corresp_before_ef = None
                for before_ef in fst:

                    if before_ef.destination_element.info["reg_name"] == reg_in_name:
                        corresp_before_ef = before_ef
                        break

                if corresp_before_ef is not None:
                    
                    if corresp_before_ef.type == "MOV_RR":
                        ef.params[0].info["reg_name"] = corresp_before_ef.params[0].info["reg_name"]

                    elif corresp_before_ef.type in ["ARITH", "LOAD_S", "LOAD_CT"]:

                        ef.type = corresp_before_ef.type
                        ef.params = deepcopy(corresp_before_ef.params)

            elif ef.type == "ARITH":
                
                expr = ef.params[0]
                for reg_in_elem in _recursive_arith_exploration(expr):
                    
                    reg_in_name = reg_in_elem.info["reg_name"]

                    corresp_before_ef = None
                    for before_ef in fst:

                        if before_ef.destination_element.info["reg_name"] == reg_in_name:
                            corresp_before_ef = before_ef
                            break

                    if corresp_before_ef is not None:

                        if corresp_before_ef.type == "LOAD_S":

                            reg_in_elem.type = "64b_stack_val"
                            reg_in_elem.info = {"id": corresp_before_ef.params[0].info["id"]}

                        elif corresp_before_ef.type == "LOAD_CT":
                            
                            reg_in_elem.type = "ct_val"
                            reg_in_elem.info = {"value": corresp_before_ef.params[0].info["value"]}

                        elif corresp_before_ef.type == "MOV_RR":
                            reg_in_elem.info["reg_name"] = corresp_before_ef.params[0].info["reg_name"]

                        elif corresp_before_ef.type == "ARITH":
                            
                            reg_in_elem.type = corresp_before_ef.params[0].type
                            reg_in_elem.info = deepcopy(corresp_before_ef.params[0].info)
    
        # copying every effect from fst that has reg_out which is not in any reg_out from res
        for before_ef in fst:
            if before_ef.destination_element is not None:

                before_ef_dest_reg_name = before_ef.destination_element.info["reg_name"]

                overridden = False
                for ef in res:

                    if (ef.destination_element is not None) and (ef.destination_element.info["reg_name"] == before_ef_dest_reg_name):
                        overridden = True

                if overridden is False:
                    res.append(before_ef)
                
        # filtering
        res_filtered = []
        for ef in res:
            
            if _ignored_effect(ef) is False:
                res_filtered.append(ef)

        return res_filtered

    # mostly for debugging purposes
    def __str__(self):
        return f"effect type {self.type}, destination element {self.destination_element}, params {[str(el) for el in self.params]}"

# gadget class that has associated a stack view and its effects (currently, operating on registers and/or stack popping)
# a gadget object can store two identical gadgets, but at different addresses
class ROP_gadget:

    # maximum gadget byte length to be searched for
    MAX_GADGET_BYTE_LEN = 30

    def __init__(self):

        self.stack = _64b_stack_view()
        self.effects: List[_effect] = []

        self.b: bytes = None

        # self.addrs - addresses of identical gadgets
        # used only at payload generation
        self.addrs: List[int] = []
    
        # self.eq_g - gadgets that differ by stack padding or nop instructions
        # used only at payload generation
        self.eq_g: List[ROP_gadget] = []

    def get_bytes(self):
        return self.b

    def get_stack_size(self):
        return len(self.stack.elements)

    def get_next_addr(self):
        return _64b_stack_view.stack_values[self.stack.elements[-1].info["id"]]

    def set_next_addr(self, addr: int):
        _64b_stack_view.stack_values[self.stack.elements[-1].info["id"]] = addr

    # by default, it contains the addresses without ASLR/PIE offsets
    def get_current_addrs(self):
        return [_64b_stack_view.stack_values[addr] for addr in self.addrs]

    def show(self, capstone_handle: Cs = None, show_addr = True, show_stack = True, output_handle = stdout):
        
        if len(self.addrs) == 0:
            print("(empty gadget)", file = output_handle)
            return

        if capstone_handle is None:
            capstone_handle = Cs(CS_ARCH_X86, CS_MODE_64)

        disas_instr_generator = capstone_handle.disasm(self.b, self.get_current_addrs()[0])
        for ins in disas_instr_generator:

            if show_addr is True:
                print(f"{hex(ins.address)}: {ins.mnemonic} {ins.op_str}", file = output_handle)
            else:
                print(f"{ins.mnemonic} {ins.op_str}", file = output_handle)

        if show_stack is True:

            _s = f"----- STACK ({self.get_stack_size()} ELEMENTS) -----"
            print(_s, file = output_handle)

            self._show_stack_values(output_handle)

            print("-" * len(_s), file = output_handle)

    def _show_stack_values(self, output_handle):

        for el in self.stack.elements:

            if el.type == "64b_stack_val":

                val = _64b_stack_view.stack_values[el.info['id']]
                if val is not None:
                    print(f"id {el.info['id']}: {hex(val)}", file = output_handle)
                else:
                    print(f"id {el.info['id']}: EMPTY", file = output_handle)
            else:
                print("====PAD====", file = output_handle)

    def add_current_addr(self, addr: int):

        new_addr_id = _64b_stack_view.get_elem_id()
        self.addrs.append(new_addr_id)
        _64b_stack_view.stack_values[new_addr_id] = addr

    # auxiliary internal method for duplication
    def _duplicate_stack(self, cpy: ROP_gadget | ROP_chain, copy_stack_associated_values):
        
        old_new_id: Dict[int, int] = {}
        def _get_new_id(old_id: int):
            
            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # recursive search for stack elements that need to be replaced
        def _recursive_replace(op_element: _structured_element):
            
            if op_element.type == "64b_stack_val":
                op_element.info["id"] = _get_new_id(op_element.info["id"])

            elif op_element.is_op():
                
                if op_element.info["term_1"] is not None:
                    _recursive_replace(op_element.info["term_1"])

                if op_element.info["term_2"] is not None:
                    _recursive_replace(op_element.info["term_2"])

        for stack_elem in self.stack.elements:

            if stack_elem.type == "64b_stack_pad":
                cpy.stack.push(_structured_element.instantiate_structured_element("64b_stack_pad"))

            elif stack_elem.type == "64b_stack_val":

                cpy_stack_elem = _structured_element.instantiate_structured_element("64b_stack_val")

                # check whether the current id has already been replaced in a previous stack element instance
                cpy_id = _get_new_id(stack_elem.info["id"])
                if cpy_id is None:
                    
                    cpy_stack_elem.info["id"] = _64b_stack_view.get_elem_id()
                    old_new_id.update({stack_elem.info["id"]: cpy_stack_elem.info["id"]})

                    if copy_stack_associated_values is True:
                        _64b_stack_view.stack_values[cpy_stack_elem.info["id"]] = _64b_stack_view.stack_values[stack_elem.info["id"]]

                else:
                    cpy_stack_elem.info["id"] = cpy_id                    

                cpy.stack.push(cpy_stack_elem)

        cpy.effects = deepcopy(self.effects)
        for ef in cpy.effects:

            if ef.type == "LOAD_S":
                ef.params[0].info["id"] = _get_new_id(ef.params[0].info["id"])

            elif ef.type == "ARITH":
                _recursive_replace(ef.params[0])

        return cpy, old_new_id

    # a gadget has fixed stack element ids that are kept globally
    # so to use multiple times the same gadget,
    # a duplicate method is needed, that automatically 
    # makes a deep copy of the stack elements and ids, and also the effects
    # it returns the new copy and the old_new_id list
    # NOTE: if the old id had an associated value, it also copies it, if chosen so
    # NOTE: does NOT duplicate the elements from eq_g
    def duplicate(self, copy_stack_associated_values = True):

        cpy = ROP_gadget()

        cpy.b = self.b

        cpy.eq_g = self.eq_g.copy()
  
        cpy.addrs = self.addrs.copy()
        for i in range(len(cpy.addrs)):
            
            addr_val = _64b_stack_view.stack_values[cpy.addrs[i]]
            addr_id_cpy = _64b_stack_view.get_elem_id()
            _64b_stack_view.stack_values[addr_id_cpy] = addr_val            
            cpy.addrs[i] = addr_id_cpy

        return self._duplicate_stack(cpy, copy_stack_associated_values)
    
    # this method should ONLY be called when you DO NOT NEED THE GADGET ANYMORE
    # it clears the stack and removes the id s that are also present in the corresponding dictionary
    # so that no memory is leaked
    # NOTE: does not remove anything from eq_g
    def remove_stack_ids(self):
        
        self.b = None
        self.effects = None

        for addr_id in self.addrs:
            _64b_stack_view.stack_values.pop(addr_id, None)

        for stack_elem in self.stack.elements:
            if stack_elem.type == "64b_stack_val":
                _64b_stack_view.stack_values.pop(stack_elem.info["id"], None)   # if the key does not exist, None is returned

        self.stack = None

    # function to check whether the given registers remain unchanged or not
    def check_fixed_regs(self, fixed_reg_list: List[str]):

        for fixed_r in fixed_reg_list:
            for ef in self.effects:

                if ef.destination_element.info["reg_name"] == fixed_r: 

                    if ef.type in ["LOAD_CT", "MOV_RR", "LOAD_S"]:
                        return False

                    elif ef.type == "ARITH":
                        
                        nop_mov = _effect.make_mov_rr_effect(fixed_r, fixed_r)
                        if _effect._match_arith(nop_mov, ef) is False:
                            return False

        return True

    # auxiliary internal method for joining gadgets / chains
    @staticmethod
    def _join_ef_stk(fst: ROP_gadget | ROP_chain, snd: ROP_gadget | ROP_chain):

        fst_cpy, _ = fst.duplicate(copy_stack_associated_values=True)
        snd_cpy, _ = snd.duplicate(copy_stack_associated_values=True)

        joined_effects = _effect.join_effects(fst_cpy.effects, snd_cpy.effects)
        joined_stack = _64b_stack_view.join_stacks(fst_cpy.stack, snd_cpy.stack)

        res_chain = ROP_chain()

        res_chain.stack = joined_stack
        res_chain.effects = joined_effects

        return res_chain, fst_cpy, snd_cpy

    def join(self, snd: ROP_gadget | ROP_chain) -> ROP_chain:

        fst_cpy: ROP_gadget
        res_chain, fst_cpy, snd_cpy = ROP_gadget._join_ef_stk(self, snd)

        if type(snd) == ROP_chain:

            res_chain.b = [fst_cpy.b] + snd_cpy.b
            res_chain.gadgets_stackview_offset = [0] + [off + fst_cpy.get_stack_size() for off in snd_cpy.gadgets_stackview_offset]
            res_chain.addrs = [fst_cpy.addrs] + snd_cpy.addrs
            res_chain.eq_g = [fst_cpy.eq_g] + snd_cpy.eq_g

        else:

            res_chain.b = [fst_cpy.b, snd_cpy.b]
            res_chain.gadgets_stackview_offset = [0, fst_cpy.get_stack_size()]
            res_chain.addrs = [fst_cpy.addrs, snd_cpy.addrs]
            res_chain.eq_g = [fst_cpy.eq_g, snd_cpy.eq_g]

        return res_chain

    # mostly for debugging purposes
    def __str__(self):
        return f"ROP gadget with stack {self.stack}, addresses are {self.get_current_addrs()}, effects {[str(ef) for ef in self.effects]}"

# class to store rop chains, 
# in almost the same way as rop gadgets
class ROP_chain(ROP_gadget):

    def __init__(self):

        self.stack: _64b_stack_view = _64b_stack_view()
        self.effects: List[_effect] = []

        self.b: List[bytes] = []

        self.addrs: List[List[int]] = []
        self.eq_g: List[List[ROP_gadget]] = []

        # self.gadgets_stackview_offset - stack offset for each gadget
        self.gadgets_stackview_offset: List[int] = []

    # converts a gadget to a chain with only one gadget
    # does NOT copy
    @staticmethod
    def convert(gadget: ROP_gadget) -> ROP_chain:

        chain = ROP_chain()

        chain.effects = gadget.effects
        chain.stack = gadget.stack

        chain.b = [gadget.b]
        chain.gadgets_stackview_offset = [0]
        chain.addrs = [gadget.addrs]
        chain.eq_g = [gadget.eq_g]

        return chain

    def get_bytes(self):
        
        acc_b = b''
        for b_ in self.b:
            acc_b += b_

        return acc_b

    def get_gadget_cnt(self):
        return len(self.gadgets_stackview_offset)

    # generator instead of function as in ROP_gadget class
    def get_current_addrs(self): 
        for i in range(self.get_gadget_cnt()):
            yield self.gadgets_stackview_offset[i], [_64b_stack_view.stack_values[addr_id] for addr_id in self.addrs[i]]

    def show(self, capstone_handle: Cs = None, show_addr = True, show_stack = True, output_handle = stdout):
        
        if len(self.addrs) == 0:
            print("(empty chain)", file = output_handle)
            return

        if capstone_handle is None:
            capstone_handle = Cs(CS_ARCH_X86, CS_MODE_64)

        _i = 0
        for _, addrs in self.get_current_addrs():

            disas_instr_generator = capstone_handle.disasm(self.b[_i], addrs[0])
            for ins in disas_instr_generator:

                if show_addr is True:
                    print(f"{hex(ins.address)}: {ins.mnemonic} {ins.op_str}")
                else:
                    print(f"{ins.mnemonic} {ins.op_str}")

            _i += 1

        if show_stack is True:

            _s = f"----- STACK ({self.get_stack_size()} ELEMENTS) -----"
            print(_s, file = output_handle)

            self._show_stack_values(output_handle)
            
            print("-" * len(_s), file = output_handle)

    def add_current_addr(self, addr: int, idx: int):
        
        new_addr_id = _64b_stack_view.get_elem_id()
        self.addrs[idx].append(new_addr_id)
        _64b_stack_view.stack_values[new_addr_id] = addr

    def duplicate(self, copy_stack_associated_values = True):

        cpy = ROP_chain()

        cpy.b = self.b.copy()
        cpy.gadgets_stackview_offset = self.gadgets_stackview_offset.copy()
        cpy.eq_g = [l.copy() for l in self.eq_g]

        cpy.addrs = deepcopy(self.addrs)
        for i in range(self.get_gadget_cnt()):
            for j in range(len(cpy.addrs[i])):
            
                addr_val = _64b_stack_view.stack_values[cpy.addrs[i][j]]
                addr_id_cpy = _64b_stack_view.get_elem_id()
                _64b_stack_view.stack_values[addr_id_cpy] = addr_val            
                cpy.addrs[i][j] = addr_id_cpy

        return self._duplicate_stack(cpy, copy_stack_associated_values)
    
    def remove_stack_ids(self):
        
        for i in range(self.get_gadget_cnt()):
            for addr in self.addrs[i]:
                _64b_stack_view.stack_values.pop(addr, None)

        for stack_elem in self.stack.elements:
            if stack_elem.type == "64b_stack_val":
                _64b_stack_view.stack_values.pop(stack_elem.info["id"], None)   # if the key does not exist, None is returned

        self.b = None
        self.effects = None
        self.gadgets_stackview_offset = None
        self.stack = None

    def join(self, snd: ROP_gadget | ROP_chain) -> ROP_chain:

        fst_cpy: ROP_chain
        res_chain, fst_cpy, snd_cpy = ROP_gadget._join_ef_stk(self, snd)
        
        if type(snd) == ROP_chain:

            res_chain.b = fst_cpy.b + snd_cpy.b
            res_chain.gadgets_stackview_offset = fst_cpy.gadgets_stackview_offset
            res_chain.gadgets_stackview_offset += [off + fst_cpy.get_stack_size() for off in snd_cpy.gadgets_stackview_offset]
            res_chain.addrs = fst_cpy.addrs + snd_cpy.addrs
            res_chain.eq_g = fst_cpy.eq_g + snd_cpy.eq_g

        else:

            res_chain.b = fst_cpy.b
            res_chain.b.append(snd_cpy.b)
            res_chain.gadgets_stackview_offset = fst_cpy.gadgets_stackview_offset
            res_chain.gadgets_stackview_offset.append(fst_cpy.get_stack_size())
            res_chain.addrs = fst_cpy.addrs
            res_chain.addrs.append(snd_cpy.addrs)
            res_chain.eq_g = fst_cpy.eq_g
            res_chain.eq_g.append(snd_cpy.eq_g)

        return res_chain
    
    # method responsible for building payload for a single chain
    # addr_offset - to be added to (all) original addresses from this chain (eg. because of ASLR)
    # forbidden_bytes - list of forbidden bytes, that can force replacing current gadgets with alternatives
    # NOTE: payload can only be built from a chain, and not a gadget (for implementation simplicity)
    #       if a gadget is needed, it can be converted to a chain and then the payload can be built
    # NOTE: gadgets from eq_g are expected to be sorted by stack size
    def _make_payload(self, max_stack_size: int, forbidden_bytes: List[bytes] = [], 
                        addr_offset: int = 0, pad_byte = b'A') -> bytes:
        
        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in forbidden_bytes:
                    return False

            return True

        payload = b''

        for i in range(self.get_gadget_cnt()):

            found = False

            stack_offset = self.gadgets_stackview_offset[i]

            stack_end = 0
            if i == self.get_gadget_cnt() - 1:
                stack_end = len(self.stack.elements)
            else:
                stack_end = self.gadgets_stackview_offset[i + 1]

            stacks = [self.stack.elements[stack_offset: stack_end]] + [g.stack.elements for g in self.eq_g[i]]
            addrs = [self.addrs[i]] + [g.addrs for g in self.eq_g[i]]

            for j in range(len(stacks)):
                if len(stacks[j]) <= max_stack_size:

                    for k in range(len(addrs[j])):
                        
                        b_addr = to_bytes(_64b_stack_view.stack_values[addrs[j][k]] + addr_offset)

                        if _check_bytes(b_addr) is True:

                            payload += b_addr
                            
                            found = True
                            for el in stacks[j][:-1]:

                                if el.type == "64b_stack_pad":
                                    payload += pad_byte * 8

                                elif el.type == "64b_stack_val":
                                    
                                    val = _64b_stack_view.stack_values[el.info["id"]]

                                    if val is None:
                                        payload += pad_byte * 8
                                        continue
                                
                                    b = to_bytes(val)
                                    if _check_bytes(b) is True:
                                        payload += b
                                    else:
                                        return None     # stacks differ only by padding, so if a forbidden byte is found, 
                                                        # it is clear that there is no way of constructing the payload

                            max_stack_size -= len(stacks[j])
                            
                            if found is True:
                                break

                if found is True:
                    break

            if found is False:
                return None

        if len(payload) % 8 != 0:
            raise RuntimeError(f"Payload is not 8-byte aligned (length: {len(payload)})")
                        
        return payload

    # mostly for debugging purposes
    def __str__(self):
        return f"ROP chain with stack {self.stack}, addresses are {'TODO'}, effects {[str(ef) for ef in self.effects]}"

# class that is responsible for implementing gadget/chain searching
# also has a cache of found and processed gadgets
class _ROP_searcher:

    def __init__(self, filepath: str, platform: Platform):

        def _find_endpoints_offsets():

            endpoints_offsets = []
            
            for i in range(len(self.exec_bytes)):
                
                xc_offset, xc = self.exec_bytes[i]
                for ib in range(len(xc)):

                    if xc[ib: ib + 1] in platform.ENDPOINTS.keys():
                        endpoints_offsets.append((i, xc_offset + ib))
            
            return endpoints_offsets

        def _find_ret_offsets():

            ret_offsets = []

            for i in range(len(self.exec_bytes)):
                
                xc_offset, xc = self.exec_bytes[i]
                for ib in range(len(xc)):

                    if xc[ib: ib + 1] == b'\xc3':
                        ret_offsets.append((i, xc_offset + ib))

            return ret_offsets

        self.exec_bytes = Elf_util(filepath).load_x_bytes()

        self.platform = platform

        if self.platform is Platform.X86_64:
            self.capstone = Cs(CS_ARCH_X86, CS_MODE_64)

        elif self.platform is Platform.AARCH64:
            self.capstone = Cs(CS_ARCH_ARM64, CS_MODE_64)

        # constant, can be changed, but 3 is the maximum recommended value
        self.BRUTEFORCE_DEPTH = 2

        self.ret_offsets: List[Tuple[int, int]] = _find_ret_offsets()
        self.endpoints_offsets: List[Tuple[int, int]] = _find_endpoints_offsets()

        self.gadgets: Set[ROP_gadget] = set()
        self.retonly_gadget: ROP_gadget = ROP_gadget() 
        self.effects_to_gadgets: Dict[str, Dict[str, List[ROP_gadget]]] = {ef_t: {reg: [] for reg in self.platform.SUPPORTED_REGS} for ef_t in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]}

    def find_ret_gadgets(self):

        # dict to help identify gadget duplicates
        # helps identify gadgets that differ only by stack padding or ignored instructions
        opstr_to_gadgets: Dict[str, Tuple[ROP_gadget, bool]] = {}
        # helps identify gadgets that are identical
        bytes_to_gadgets: Dict[str, Tuple[ROP_gadget, bool]] = {}

        def _get_opstr(b_instr: bytes):

            opstr = ''
            
            for instr in self.capstone.disasm(b_instr, 0):

                if (instr.mnemonic in self.platform.IGNORED_INSTR_MNEMONICS) or (instr.mnemonic == "nop") \
                    or (instr.mnemonic == "add" and "rsp, 0x" in instr.op_str):
                    continue

                opstr += instr.mnemonic
                opstr += instr.op_str

            return opstr

        # auxiliary method to synchronize stack ids
        def _stack_id_sync(g: ROP_gadget, eg: ROP_gadget):
            
            s_g = g.stack.elements
            s_eg = eg.stack.elements

            i = 0
            j = 0
            while (i < len(s_g)) and (j < len(s_eg)):

                while (i < len(s_g)) and (s_g[i].type == "64b_stack_pad"):
                    i += 1

                while (j < len(s_eg)) and (s_eg[j].type == "64b_stack_pad"):
                    j += 1

                if i == len(s_g):
                    assert(j == len(s_eg))

                if (i < len(s_g)) and (j < len(s_eg)):

                    _64b_stack_view.stack_values.pop(s_eg[j], None)
                    s_eg[j] = s_g[i]

                    i += 1
                    j += 1

                if i == len(s_g):
                    assert(j == len(s_eg))
        
        # initialize ret-only gadget
        self.retonly_gadget.stack.push(_structured_element.instantiate_structured_element("64b_stack_val"))
        self.retonly_gadget.stack.elements[0].info["id"] = _64b_stack_view.get_elem_id()
        self.retonly_gadget.b = self.platform.RET_OPCODE
        
        # to check in constant time if the basse address
        # of a current gadget candidate actually steps over another ret
        ret_onlyoffsets = set(r[1] for r in self.ret_offsets)

        for xc_index, ret_offset in self.ret_offsets:

            self.retonly_gadget.add_current_addr(ret_offset)
            
            neg_offset = 1
            while (ret_offset - neg_offset > 0) and ((ret_offset - neg_offset) not in ret_onlyoffsets):
                
                b_vaddr = self.exec_bytes[xc_index][0]
                b_instr = self.exec_bytes[xc_index][1][ret_offset - neg_offset - b_vaddr: ret_offset - b_vaddr + 1]

                stop = False

                if b_instr in bytes_to_gadgets.keys():

                    if bytes_to_gadgets[b_instr][1] is True:
                        bytes_to_gadgets[b_instr][0].add_current_addr(ret_offset - neg_offset)

                else:

                    opstr = _get_opstr(b_instr)
                    if (opstr not in opstr_to_gadgets.keys()) or (opstr_to_gadgets[opstr][1] is True):
                        
                        disas_instr_generator = self.capstone.disasm(b_instr, ret_offset - neg_offset)
                        g, stop = self.create_gadget(disas_instr_generator, b_instr, self.platform, ret_offset - neg_offset)

                        if (g is not None) and (len(g.effects) > 0):
                            
                            bytes_to_gadgets.update({b_instr: (g, True)})

                            if opstr in opstr_to_gadgets.keys():
                                opstr_to_gadgets[opstr][0].eq_g.append(g)

                            else:
                                opstr_to_gadgets.update({opstr: (g, True)})

                                for ef in g.effects:
                                    self.effects_to_gadgets[ef.type][ef.destination_element.info["reg_name"]].append(g)

                                self.gadgets.add(g)

                        else:
                            bytes_to_gadgets.update({b_instr: (None, False)})
                            opstr_to_gadgets.update({opstr: (None, False)})
                
                if stop is True:
                    break
                    
                neg_offset += 1

        # for each g, synchronize stack ids between g and gadgets from g.eq_g
        # so that stacks can be interchanged, having (at most) the padding size different
        for g in self.gadgets:
            for eg in g.eq_g:
                _stack_id_sync(g, eg)
  
        # from all eq_g per gadget, select the gadget with the smallest stack size
        # by swapping everything except the effects, which are identical
        # and then sort the eq_g gadgets
        for g in self.gadgets:
            for eg in g.eq_g:
                
                # assert(len(g.effects) == len(eg.effects))
                
                if eg.get_stack_size() < g.get_stack_size():

                    swap_aux = g.b
                    g.b = eg.b
                    eg.b = swap_aux

                    swap_aux = g.stack
                    g.stack = eg.stack
                    eg.stack = swap_aux

                    swap_aux = g.addrs
                    g.addrs = eg.addrs
                    eg.addrs = swap_aux

            g.eq_g.sort(key = lambda gadget: len(gadget.stack.elements))

        # sorting by used stack size
        for ef in ["LOAD_S", "LOAD_CT", "MOV_RR", "ARITH"]:
            for reg in self.platform.SUPPORTED_REGS:
                self.effects_to_gadgets[ef][reg].sort(key = lambda g: len(g.stack.elements))

    # creates a graph for transitioning a value between registers
    # NOTE: it does NOT support register start values
    def get_trans_reg_graph(self):

        # dict to retain all gadgets for moving a value from a register to another
        trans_reg_graph: Dict[str, Dict[str, List[ROP_gadget]]] = {dest: {src: [] for src in self.platform.SUPPORTED_REGS} for dest in self.platform.SUPPORTED_REGS}

        # whether there is a path from [reg_dest][reg_src] or not
        path_from: Dict[str, Dict[str, bool]] = {dest: {src: False for src in self.platform.SUPPORTED_REGS} for dest in self.platform.SUPPORTED_REGS}

        for dest in self.platform.SUPPORTED_REGS:
            for src in self.platform.SUPPORTED_REGS:

                if dest == src:
                    path_from[dest][src] = True
                    continue

                dest_from_src_ef = _effect.make_mov_rr_effect(dest, src)
                dest_from_src_gadgets = self.search_gadget(wanted_effect=dest_from_src_ef, max_stack_size=2 ** 63, 
                                                            reg_start_values=[], max_search_cnt=2 ** 63)

                if len(dest_from_src_gadgets) != 0:

                    trans_reg_graph[dest][src] = dest_from_src_gadgets
                    path_from[dest][src] = True

        # completing path_from (Roy-Warshal)
        for k in self.platform.SUPPORTED_REGS:
            for i in self.platform.SUPPORTED_REGS:
                for j in self.platform.SUPPORTED_REGS:

                    if (path_from[i][k] is True) and (path_from[k][j] is True):
                        path_from[i][j] = True

        return trans_reg_graph, path_from
    
    # auxiliary method that checks
    # whether any "subchain" was previously yielded or not
    @staticmethod
    def _check_if_duplicate(gs: List[ROP_gadget | ROP_chain], b_cache: Dict[bytes, bool]):

        def _chunks(l: List[ROP_gadget | ROP_chain]):
            
            if len(l) == 0:
                return

            if len(l) == 1:
                yield l[0].get_bytes() 
                return

            if len(l) == 2:
                yield l[0].get_bytes()
                yield l[1].get_bytes()
                return

            for i in range(1, len(l)):
                yield b''.join([g.get_bytes() for g in l[:i]])
            yield b''.join([g.get_bytes() for g in l[1:]])

            yield from _chunks(l[1:])

        for subchain_b in _chunks(gs):
            if (subchain_b in b_cache.keys()) and (b_cache[subchain_b] is True):
                return True

        return False

    # internal method for searching a gadget
    # receives the wanted effect, max stack size, the fixed registers list (optional) and the register start values (optional)
    # it also receives a filter function as argument, to filter all found gadgets, by default it is the identity
    # NOTE: it is a FUNCTION, NOT a GENERATOR
    # NOTE: fixed registers may actually be used, as long as at the end of the gadget they contain their initial value
    # NOTE: the arguments are assumed to be valid
    # NOTE: max stack size is measured internally as the number of 64bit elements (max stack size in bytes // 8)
    def search_gadget(self, wanted_effect: _effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[_effect] = [], max_search_cnt: int = 100) -> List[ROP_gadget]:

        # as in duplicate method, represents a map 
        # between the original gadget stack ids and the new gadget stack ids
        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # a gadget can be referenced multiple times in the effects_to_gadgets dictionary
        # (when a gadget has multiple effects)
        # so, once a gadget has been checked, there is no need to check it twice
        tried_gadget_cache = set()

        # main function to try a gadget 
        def _try_gadget(candidate_g: ROP_gadget, wanted_effect: _effect, searched_effect_types: List[str]):
            
            if candidate_g in tried_gadget_cache:
                return None

            if candidate_g.get_stack_size() > max_stack_size:

                tried_gadget_cache.add(candidate_g)
                return None
                
            # copies that can be manipulated without changing the original objects
            candidate_g_cpy, org_to_fstid = candidate_g.duplicate(copy_stack_associated_values=True)
            wanted_effect_cpy: _effect = deepcopy(wanted_effect)

            start_values_cpy = deepcopy(reg_start_values)
            candidate_g_cpy.effects = _effect.join_effects(start_values_cpy, candidate_g_cpy.effects)

            # every entry in effects_to_gadgets has a corresponding effect
            # it is not kept in the dict, but can be found
            # by searching in the gadget's effect list, by the reg_out name
            # NOTE: the type is not checked, because it can be changed by the simplifly calls from before
            #       and even if they did not, the check would be redundant (only one effect with the corresponding reg_name as destination)
            candidate_effect = None
            for ef in candidate_g_cpy.effects:

                if ef.destination_element.info["reg_name"] == wanted_effect_cpy.destination_element.info["reg_name"]:
                    candidate_effect = ef
                    break

            if candidate_effect.type not in searched_effect_types:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            matched = wanted_effect_cpy.match(candidate_effect)
            if matched is False:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            is_fixed = candidate_g_cpy.check_fixed_regs(fixed_reg_list)
            if is_fixed is False:

                tried_gadget_cache.add(candidate_g)
                candidate_g_cpy.remove_stack_ids()
                return None

            # gadget is accepted, a third copy is created from the original gadget
            # that is not simplified like the first gadget copy, 
            # but does contain all the additional stack ids and their associated value from the first gadget copy
            # then, the first temporary copy has its stack ids and other contents removed

            accepted_gadget, org_to_sndid = candidate_g.duplicate(copy_stack_associated_values=True)

            for org_stack_elem in candidate_g.stack.elements:
                if org_stack_elem.type == "64b_stack_val":

                    fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                    if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != _64b_stack_view.stack_values[fstid]:

                        if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != None:
                            raise RuntimeError("original gadget and cloned gadget non-null values are different")

                        sndid = _get_new_id(org_to_sndid, org_stack_elem.info["id"])
                        _64b_stack_view.stack_values[sndid] = _64b_stack_view.stack_values[fstid]

                    # else, the accepted_gadget already has the original value

            candidate_g_cpy.remove_stack_ids()

            tried_gadget_cache.add(candidate_g)
            return accepted_gadget

        # table of possible effect types matching
        # there can be multiple searched effects because, given specific circumstances, some effects can change type
        # NOTE: LOAD_S is intentionally restricted to only other LOAD_S effects, for an efficient/ fast search
        #       if one wants to have all the possible ways of loading a value in a register, LOAD_CT matching should be chosen instead
        # LOAD_S -> LOAD_S
        # LOAD_CT -> LOAD_CT, LOAD_S (always false if max stack size == 0), ARITH
        # MOV_RR -> MOV_RR, ARITH
        # ARITH -> ARITH

        # searched effect type filtering
        # is done in two places: here, less restrictive
        # and inside the try gadget function, more restrictive
        # this is because we still want the search to be optimised
        # but also we need to take into account that the reg start values
        # can change some effect types into other types

        found_g: List[ROP_gadget] = []
        searched_effect_types_snd: List[str] = []
        searched_effect_types_fst: List[str] = []

        if wanted_effect.type == "LOAD_S":

            searched_effect_types_snd.append("LOAD_S")

            searched_effect_types_fst.append("LOAD_S")

        elif wanted_effect.type == "LOAD_CT":

            searched_effect_types_snd.append("LOAD_S")
            searched_effect_types_snd.append("LOAD_CT")
            searched_effect_types_snd.append("ARITH")

            searched_effect_types_fst.append("LOAD_S")
            searched_effect_types_fst.append("LOAD_CT")
            searched_effect_types_fst.append("MOV_RR")
            searched_effect_types_fst.append("ARITH")

        elif wanted_effect.type == "MOV_RR":

            searched_effect_types_snd.append("MOV_RR")
            searched_effect_types_snd.append("ARITH")

            searched_effect_types_fst.append("MOV_RR")
            searched_effect_types_fst.append("ARITH")

        elif wanted_effect.type == "ARITH":

            searched_effect_types_snd.append("ARITH")
            
            searched_effect_types_fst.append("ARITH")
            searched_effect_types_fst.append("MOV_RR")

        for srch_t in searched_effect_types_fst:

            found_per_t_cnt = 0

            candidate_g: ROP_gadget
            for candidate_g in self.effects_to_gadgets[srch_t][wanted_effect.destination_element.info["reg_name"]]:
                
                accepted_gadget = _try_gadget(candidate_g, wanted_effect, searched_effect_types_snd)
                if accepted_gadget is not None:

                    found_g.append(accepted_gadget)

                    found_per_t_cnt += 1
                    if found_per_t_cnt == max_search_cnt:
                        break
        
        found_g.sort(key = lambda g: g.get_stack_size())
        return found_g[:max_search_cnt]

    # main method of parsing instruction chunks and creating gadgets
    # here it is decided whether the gadget is valid / accepted / supported, what effects is has and so on
    # NOTE: addr parameter contains the default address, when ASLR/PIE is NOT enabled
    def create_gadget(self, instr_generator: Generator[CsInsn, None, None], b_instr: bytes, platform: Platform, addr: int = None) -> Tuple[ROP_gadget, bool]:
        
        # decide here whether to send signal to the caller procedure
        # so that it stops appending preffixes to the same "gadget"
        def _send_stop_flag():
            return len(b_instr) > ROP_gadget.MAX_GADGET_BYTE_LEN

        def _gadget_end(instr: CsInsn):

            if platform is Platform.X86_64:
                return (instr.mnemonic == "ret") and (len(instr.op_str) == 0)

            else:
                raise RuntimeError("other arch not yet implemented")

        # first, each instruction is analysed semantically and translated in some effects
        # then, the effects will be cumulated from first to last instruction, to obtain the gadget
        effects_per_instruction: List[List[_effect]] = []

        is_ret = False
        for instr in instr_generator:

            if _gadget_end(instr) is True:
                is_ret = True       # check whether the gedget ends with "ret" or not
                break

            instr_effects = _effect.analyse_instr(instr, platform)
            if instr_effects is None:
                return None, _send_stop_flag()

            effects_per_instruction.append(instr_effects)
        
        if is_ret is False:
            return None, _send_stop_flag()

        candidate_gadget = _effect.join_instr_effects(effects_per_instruction)
        if candidate_gadget is None:
            return None, _send_stop_flag()

        candidate_gadget.add_current_addr(addr)
        candidate_gadget.b = b_instr

        return candidate_gadget, _send_stop_flag()

    # function that automatically finds a chain that satisfies the effect R_dest <- R_src
    # based on max stack size and a trans graph
    # NOTE: inside this function, no other constraints or checks are implemented
    def transition_chain_generator(self, dest: str, src: str, trans_graph: Dict[str, Dict[str, List[ROP_gadget]]], max_stack_size: int):

        # auxiliary data structure for the graph traversal
        _visited = set()

        # generator that returns a list of gadgets that compose the transfer path, and the accumulated stack size
        def _path_finder(current_reg: str, mss: int):

            _visited.add(current_reg)

            if current_reg == src:
                yield [], 0
                    
            else:

                for src_reg, gs in trans_graph[current_reg].items():
                    if (src_reg not in _visited) and (len(gs) > 0):

                        mss_reached = False

                        for path_suffix, stack_size in _path_finder(src_reg, mss - gs[0].get_stack_size()):
                
                            for trans_g in gs:
                                
                                tgss = trans_g.get_stack_size()

                                if tgss + stack_size <= mss:
                                    yield [trans_g] + path_suffix, tgss + stack_size
                                else:
                                    mss_reached = True
                                    break
                                    
                            if mss_reached is True:
                                break
                    
            _visited.remove(current_reg)

        return _path_finder(dest, max_stack_size)

    # method responsible for automatically constructing rop chains
    # for only one wanted effect
    # based on gadgets from effects_to_gadgets dict
    # and on the different methods implemented
    # NOTE: based on different searching methods called, reg start values might be ignored
    def _search_chain(self, wanted_effect: _effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[_effect] = [], only_gadgets = False) -> List[ROP_chain]:

        if max_stack_size < 0:
            return

        # every sequence of bytes is analysed exactly once
        # also, if a chain is yielded, 
        # then no chain with this current chain as a "subchain" will be analysed 
        # (this mechanism avoids chains that satisfy the wanted effect, but have junk preffixes / suffixes)
        b_cache: Dict[bytes, bool] = {}

        yield from self._search_gadgets(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                    reg_start_values=reg_start_values, b_cache=b_cache)

        if only_gadgets is False:
        
            if wanted_effect.type == "LOAD_CT":

                yield from self._search_chain_by_substitution(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list, 
                                                                reg_start_values=reg_start_values, b_cache=b_cache)

                yield from self._search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=reg_start_values, b_cache=b_cache)

            elif wanted_effect.type == "ARITH":

                yield from self._search_chain_by_substitution(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list, 
                                                                reg_start_values=reg_start_values, b_cache=b_cache)
                
                yield from self._search_chain_by_substitution_adv(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list, 
                                                                    reg_start_values=reg_start_values, b_cache=b_cache)

                yield from self._search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=reg_start_values, b_cache=b_cache)

            elif wanted_effect.type == "MOV_RR":

                yield from self._search_mov_chains(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                                    reg_start_values=reg_start_values, b_cache=b_cache)

                yield from self._search_by_bruteforce(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                                        reg_start_values=reg_start_values, b_cache=b_cache)

            else:
                raise RuntimeError(f"Unrecognised wanted effect type when searching chains: {wanted_effect.type}")
    
    # search chains with multiple wanted effects
    def search_chain(self, wanted_effects: List[_effect], max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[_effect] = [], only_gadgets = False) -> List[ROP_chain]:
            
        b_cache: Dict[bytes, bool] = {}
        def _get_bytes(chs: List[ROP_chain]):

            b_repr = b''
            for ch in chs:
                b_repr += ch.get_bytes()

            return b_repr

        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        r_to_wef: Dict[str, _effect] = {}

        def _map_r_to_wef():

            for wef in wanted_effects:
                
                r = wef.destination_element.info["reg_name"]

                if r in r_to_wef.keys():
                    raise RuntimeError("same destination register found in more than one wanted effect")

                r_to_wef.update({r: wef})

        r_to_gen: Dict[str, Generator] = {}
        r_to_startgen: Dict[str, Generator] = {}

        r_gen_mss: Dict[str, List[int]] = {}
        r_startgen_mss: Dict[str, List[int]] = {}

        def _update_generator(r: str, start: bool):

            wef = r_to_wef[r]

            if start is True:

                if len(r_startgen_mss[r]) == 0:
                    return False

                mss = r_startgen_mss[r][0]
                r_startgen_mss[r] = r_startgen_mss[r][1:]

                r_to_startgen.update({r: self._search_chain(wanted_effect = wef, max_stack_size = mss, fixed_reg_list = fixed_reg_list,
                                                            reg_start_values = reg_start_values, only_gadgets = False)})
            else:

                if len(r_gen_mss[r]) == 0:
                    return False

                mss = r_gen_mss[r][0]
                r_gen_mss[r] = r_gen_mss[r][1:]

                r_to_gen.update({r: self._search_chain(wanted_effect = wef, max_stack_size = mss, fixed_reg_list = fixed_reg_list,
                                                            reg_start_values = [], only_gadgets = False)})

            return True

        chs: List[Tuple[ROP_chain, Set[str], Set[str]]] = []
        startchs: List[Tuple[ROP_chain, Set[str], Set[str]]] = []

        # cache of bytes of generated chains
        ch_b_cache: Set[bytes] = set()
        startch_b_cache: Set[bytes] = set()

        def _generate_chs(qty: int):
            
            def _get_v_i(ch: ROP_chain, r: str):

                validate = {r}
                invalidate = set()

                for r_, wef_ in r_to_wef.items():
                    if r_ != r:
                        
                        wef_cpy = deepcopy(wef_)
                        ch_cpy, ch_to_chcpy_ids = ch.duplicate(copy_stack_associated_values = True)

                        to_match_ef: _effect = None
                        for ef in ch_cpy.effects:

                            if ef.destination_element.info["reg_name"] == r_:
                                to_match_ef = ef
                                break

                        if to_match_ef is None:
                            continue

                        if wef_cpy.match(to_match_ef) is False:
                            ch_cpy.remove_stack_ids()
                            invalidate.add(r_)
                            continue

                        for org_stack_elem in ch.stack.elements:
                            if org_stack_elem.type == "64b_stack_val":

                                cpyid = _get_new_id(ch_to_chcpy_ids, org_stack_elem.info["id"])
                                if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != _64b_stack_view.stack_values[cpyid]:

                                    if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                        raise RuntimeError("original chain and cloned chain non-null values are different")

                                    _64b_stack_view.stack_values[org_stack_elem.info["id"]] = _64b_stack_view.stack_values[cpyid]

                        ch_cpy.remove_stack_ids()
                        validate.add(r_)

                return validate, invalidate

            total_gen = 0

            for r, _ in r_to_wef.items():
                
                gen = r_to_gen[r]
                
                _gen_cnt = 0
                while _gen_cnt < qty:
                    
                    ch: ROP_chain
                    for ch in gen:

                        b = ch.get_bytes()
                        if b in ch_b_cache:
                            continue

                        ch_b_cache.add(b)

                        validate, invalidate = _get_v_i(ch, r)
                        chs.append((ch, validate, invalidate))

                        _gen_cnt += 1
                        if _gen_cnt == qty:
                            break

                    if _gen_cnt < qty:

                        success = _update_generator(r, False)
                        if success is False:
                            break

                startgen = r_to_startgen[r]

                _startgen_cnt = 0
                while _startgen_cnt < qty:
                    
                    ch: ROP_chain
                    for ch in startgen:

                        b = ch.get_bytes()
                        if b in startch_b_cache:
                            continue

                        startch_b_cache.add(b)

                        validate, invalidate = _get_v_i(ch, r)
                        startchs.append((ch, validate, invalidate))

                        _startgen_cnt += 1
                        if _startgen_cnt == qty:
                            break

                    if _startgen_cnt < qty:

                        success = _update_generator(r, False)
                        if success is False:
                            break    

                    total_gen += _startgen_cnt + _gen_cnt

            if total_gen == 0:
                return False            

            return True
                
        # cache of a state (mv + ci)
        state_cache: Dict[str, int] = {}

        def _get_state_str(mv: Set[str], ci: Set[str]):

            mvl = [s for s in mv]
            cil = [s for s in ci]
            mvl.sort()
            cil.sort()

            return f"{''.join(mvl)}|{''.join(cil)}"

        def _path_search(mv: Set[str], ci: Set[str], mss: int, start: bool):

            if len(mv) == 0:
                yield [], 0
                return
            
            _chs = chs
            if start is True:
                _chs = startchs
            
            # append chains that satisfy a wanted effect from mv
            for ch, validate, invalidate in _chs:
                
                # stack size
                ch_ss = ch.get_stack_size()
                if ch_ss > mss:
                    continue
                
                # ci inclusion
                if invalidate.issubset(ci) is False:
                    continue

                # usefullness
                m0 = validate.difference(mv)
                m1 = validate.intersection(mv)

                if len(m1) == 0:
                    continue

                new_mv = mv.difference(m1)
                new_ci = ci.difference(invalidate).union(m0)

                # already visited
                state_str = _get_state_str(new_mv, new_ci)
                if (state_str in state_cache.keys()) and (state_cache[state_str] >= mss):
                    continue

                if state_str in state_cache.keys():
                    state_cache[state_str] = mss
                else:
                    state_cache.update({state_str: mss})

                for suf, stack_size in _path_search(new_mv, new_ci, mss - ch_ss, False):
                    yield [ch] + suf, stack_size + ch_ss

            # append chains that "guard" some wanted effects
            for ch, validate, invalidate in _chs:
                
                # stack size
                ch_ss = ch.get_stack_size()
                if ch_ss > mss:
                    continue
                
                # ci inclusion
                if invalidate.issubset(ci) is False:
                    continue

                # usefullness
                m0 = validate.difference(mv)
                m1 = validate.intersection(mv)

                if len(m0) == 0:
                    continue

                new_mv = mv.difference(m1)
                new_ci = ci.difference(invalidate).union(m0)

                # already visited
                state_str = _get_state_str(new_mv, new_ci)
                if (state_str in state_cache.keys()) and (state_cache[state_str] >= mss):
                    continue

                if state_str in state_cache.keys():
                    state_cache[state_str] = mss
                else:
                    state_cache.update({state_str: mss})

                for suf, stack_size in _path_search(new_mv, new_ci, mss - ch_ss, False):
                    yield [ch] + suf, stack_size + ch_ss

        if len(wanted_effects) == 1:

            yield from self._search_chain(wanted_effect = wanted_effects[0], max_stack_size = max_stack_size, fixed_reg_list = fixed_reg_list,
                                            reg_start_values = reg_start_values, only_gadgets = only_gadgets)

        elif only_gadgets is True:

            for g in self._search_gadgets(wanted_effect = wanted_effects[0], max_stack_size = max_stack_size, fixed_reg_list = fixed_reg_list,
                                            reg_start_values = reg_start_values, b_cache = b_cache):

                g_cpy, org_to_cpyid = g.duplicate()
                start_values_cpy = deepcopy(reg_start_values)
                g_cpy.effects = _effect.join_effects(start_values_cpy, g_cpy.effects)

                wef_sat = True
                for wef in wanted_effects[1:]:

                    wef_cpy = deepcopy(wef)

                    to_check_effect: _effect = None
                    for ef in g_cpy.effects:

                        if ef.destination_element.info["reg_name"] == wef_cpy.destination_element.info["reg_name"]:
                            to_check_effect = ef
                            break
                    
                    if to_check_effect is None:
                        wef_sat = False
                        break

                    if wef_cpy.match(to_check_effect) is False:
                        wef_sat = False
                        break

                    if g_cpy.check_fixed_regs(fixed_reg_list) is False:
                        wef_sat = False
                        break

                if wef_sat is False:
                    g_cpy.remove_stack_ids()
                    continue

                for org_stack_elem in g.stack.elements:
                    if org_stack_elem.type == "64b_stack_val":

                        cpyid = _get_new_id(org_to_cpyid, org_stack_elem.info["id"])
                        if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != _64b_stack_view.stack_values[cpyid]:

                            if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                raise RuntimeError("original chain and cloned chain non-null values are different")

                            _64b_stack_view.stack_values[org_stack_elem.info["id"]] == _64b_stack_view.stack_values[cpyid]

                g_cpy.remove_stack_ids()

                yield g

        else:

            _map_r_to_wef()

            r_gen_mss: Dict[str, List[int]] = {r: [max_stack_size / len(wanted_effects), max_stack_size] for r in r_to_wef.keys()}
            r_startgen_mss: Dict[str, List[int]] = {r: [max_stack_size / len(wanted_effects), max_stack_size] for r in r_to_wef.keys()}

            for r, _ in r_to_wef.items():
                _update_generator(r, False)
                _update_generator(r, True)

            try:

                qty_gen = 1
                while True:
                    
                    success = _generate_chs(qty_gen)
                    if success is False:
                        break

                    path: List[ROP_chain]
                    for path, stack_size in _path_search(mv = {r for r in r_to_wef.keys()}, ci = set(), mss = max_stack_size, start = True):
                        
                        if stack_size > max_stack_size:
                            raise RuntimeError("max stack size constraint violated")
                        
                        b = _get_bytes(path)
                        if b in b_cache.keys():
                            continue

                        b_cache.update({b: False})

                        if _ROP_searcher._check_if_duplicate(path, b_cache) is True:
                            continue

                        acc_ch, _ = path[-1].duplicate()
                        for ch in path[-2::-1]:

                            ch_aux = acc_ch.join(ch)
                            acc_ch.remove_stack_ids()
                            acc_ch = ch_aux

                        b_cache[b] = True
                        yield acc_ch

                    qty_gen *= 2

            finally:
                
                ch: ROP_chain
                for ch, _, _ in chs:
                    ch.remove_stack_ids()

                for ch, _, _ in startchs:
                    ch.remove_stack_ids()

    # internal method that searches by bruteforce
    # has a maximum chain length parameter
    # and it is limited to chains of 4 gadgets long
    # besides search cache, only one filtering condition: 
    #       * at least a gadget from the chain must have the destination register the destination reg of the wanted effect
    # NOTE: extremely slow
    # NOTE: to disable bruteforce search, set the self.BRUTEFORCE_DEPTH to less than 1
    def _search_by_bruteforce(self, wanted_effect: _effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                                reg_start_values: List[_effect] = [], b_cache: Dict[bytes, bool] = {}):

        max_g_cnt = self.BRUTEFORCE_DEPTH
        if max_g_cnt > 4:
            raise RuntimeError(f"Cannot search chains by bruteforce for depth {max_g_cnt} - max allowed is 6")

        if max_g_cnt < 1:
            return

        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # function that creates a rop chain
        # from a copy of a given gadget input,
        # and taking into account reg start values 
        def _prepare(g: ROP_gadget) -> ROP_chain:

            cpy_g, _ = g.duplicate()
            return ROP_chain.convert(cpy_g)

        # all the gadgets converted to atomic chains
        base_gs: List[ROP_chain] = [_prepare(g) for g in self.gadgets]

        # yields all different arrangements of gadgets of length k
        def _get_paths(k: int):
            
            if k == 0:
                yield [], 0

            else:
                for suf, stack_size in _get_paths(k - 1):
                    for g in base_gs:
                        yield [g] + suf, stack_size + g.get_stack_size()

        try:

            for l in range(max_g_cnt):
                for path, stack_size in _get_paths(l + 1):

                    if stack_size > max_stack_size:
                        continue    

                    if _ROP_searcher._check_if_duplicate(path, b_cache) is True:
                        continue

                    candidate_ch: ROP_chain = path[-1].duplicate()[0]
                    for g in path[-2::-1]:

                        candidate_ch_aux = candidate_ch.join(g)
                        candidate_ch.remove_stack_ids()
                        candidate_ch = candidate_ch_aux

                    b = candidate_ch.get_bytes()
                    if b in b_cache.keys():
                        candidate_ch.remove_stack_ids()
                        continue

                    b_cache.update({b: False})

                    wef_dest_reg_found = False

                    g: ROP_gadget
                    for g in path:
                        for ef in g.effects:
                            if ef.destination_element.info["reg_name"] == wanted_effect.destination_element.info["reg_name"]:
                                wef_dest_reg_found = True

                    if wef_dest_reg_found is False:
                        continue

                    candidate_ch_aux, org_to_fstid = candidate_ch.duplicate()
                    wanted_effect_cpy = deepcopy(wanted_effect)

                    start_values_cpy = deepcopy(reg_start_values)
                    candidate_ch_aux.effects = _effect.join_effects(start_values_cpy, candidate_ch_aux.effects)

                    to_check_effect: _effect = None
                    for ef in candidate_ch_aux.effects:
                        if ef.destination_element.info["reg_name"] == wanted_effect_cpy.destination_element.info["reg_name"]:
                            to_check_effect = ef
                            break

                    if to_check_effect is None:
                        candidate_ch_aux.remove_stack_ids()
                        candidate_ch.remove_stack_ids()
                        continue

                    if wanted_effect_cpy.match(to_check_effect) is False:
                        candidate_ch_aux.remove_stack_ids()
                        candidate_ch.remove_stack_ids()
                        continue

                    if candidate_ch_aux.check_fixed_regs(fixed_reg_list) is False:
                        candidate_ch_aux.remove_stack_ids()
                        candidate_ch.remove_stack_ids()
                        continue

                    for org_stack_elem in candidate_ch.stack.elements:
                        if org_stack_elem.type == "64b_stack_val":

                            fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                            if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != _64b_stack_view.stack_values[fstid]:

                                if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                    raise RuntimeError("original chain and cloned chain non-null values are different")

                                _64b_stack_view.stack_values[org_stack_elem.info["id"]] = _64b_stack_view.stack_values[fstid]

                    candidate_ch_aux.remove_stack_ids()

                    b_cache[b] = True
                    yield candidate_ch
        
        finally:

            for ch in base_gs:
                ch.remove_stack_ids()

    # internal method that searches only gadgets, 
    # and converts the results into ROP_chain objects
    def _search_gadgets(self, wanted_effect: _effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                        reg_start_values: List[_effect] = [], b_cache: Dict[bytes, bool] = {}):

        gadgets = self.search_gadget(wanted_effect=wanted_effect, max_stack_size=max_stack_size, fixed_reg_list=fixed_reg_list,
                                            reg_start_values=reg_start_values, max_search_cnt=2 ** 63)

        for g in gadgets:
            
            b = g.get_bytes()
            if b not in b_cache.keys():

                b_cache.update({b: True})
                yield ROP_chain.convert(g)

    # internal method that searches rop chains for MOV_RR type effect
    # resembles the _search_chain_by_substitution
    def _search_mov_chains(self, wanted_effect: _effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [],
                            reg_start_values: List[_effect] = [], b_cache: Dict[bytes, bool] = {}):

        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None
        
        trans_graph, _ = self.get_trans_reg_graph()

        dest = wanted_effect.destination_element.info["reg_name"]
        src = wanted_effect.params[0].info["reg_name"]

        try:
 
            for path, _ in self.transition_chain_generator(dest, src, trans_graph, max_stack_size):
                
                if len(path) == 0:
                    continue

                if _ROP_searcher._check_if_duplicate(path, b_cache) is True:
                    continue

                candidate_ch = ROP_chain.convert(path[-1].duplicate()[0])
                for g in path[-2::-1]:

                    candidate_ch_aux = candidate_ch.join(g)
                    candidate_ch.remove_stack_ids()
                    candidate_ch = candidate_ch_aux

                b = candidate_ch.get_bytes()
                if b in b_cache.keys():
                    candidate_ch.remove_stack_ids()
                    continue

                b_cache.update({b: False})

                candidate_ch_cpy, org_to_fstid = candidate_ch.duplicate()

                start_values_cpy = deepcopy(reg_start_values)
                candidate_ch_cpy.effects = _effect.join_effects(start_values_cpy, candidate_ch_cpy.effects)

                # because of start values, the wanted effect needs to be checked 
                wanted_effect_cpy = deepcopy(wanted_effect)

                to_check_ef: _effect = None
                for ef in candidate_ch_cpy.effects:
                    
                    if ef.destination_element.info["reg_name"] == dest:
                        to_check_ef = ef
                        break

                if (to_check_ef is None) or (wanted_effect_cpy.match(to_check_ef) is False):
                    candidate_ch_cpy.remove_stack_ids()
                    candidate_ch.remove_stack_ids()
                    continue

                if candidate_ch_cpy.check_fixed_regs(fixed_reg_list) is False:
                    candidate_ch_cpy.remove_stack_ids()
                    candidate_ch.remove_stack_ids()
                    continue

                for org_stack_elem in candidate_ch.stack.elements:
                    if org_stack_elem.type == "64b_stack_val":

                        fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                        if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != _64b_stack_view.stack_values[fstid]:

                            if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                raise RuntimeError("original chain and cloned chain non-null values are different")

                            _64b_stack_view.stack_values[org_stack_elem.info["id"]] != _64b_stack_view.stack_values[fstid]

                candidate_ch_cpy.remove_stack_ids()

                b_cache[b] = True
                yield candidate_ch

        finally:
                
            for _, d in trans_graph.items():
                for _, gs in d.items():
                    if gs is not None:
                        for g in gs:
                            g.remove_stack_ids()

    # internal method responsible for automatically constructing rop chains
    # it searches gadgets based on substituting register operands
    # and then joining the effect-satisfying gadgets with the transition gadgets
    def _search_chain_by_substitution(self, wanted_effect: _effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                                        reg_start_values: List[_effect] = [], b_cache: Dict[bytes, bool] = {}):

        if wanted_effect.type not in ["ARITH", "LOAD_CT"]:
            raise RuntimeError(f"tyring to search chain inside _search_chain_by_substitution for wanted effect type {wanted_effect.type}")

        # graph as a list(dict) of neighbours, and the path existence matrix
        trans_graph, path_from = self.get_trans_reg_graph()

        # auxiliary method
        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # returns a list of all reg_in used, and the reg_out,
        # for an ARITH / LOAD_CT effect
        def _find_used_regs(ef: _effect) -> Tuple[List[str], str]:

            def _rec_find(el: _structured_element):
                
                if el is None:
                    return []

                if el.type == "reg_in":
                    return [el.info["reg_name"]]

                if el.is_op():
                    return _rec_find(el.info["term_1"]) + _rec_find(el.info["term_2"])

                if el.type == "64b_stack_val":
                    raise RuntimeError("wanted effect contains stack elements")

                return []

            if ef.type == "LOAD_CT":
                return [], ef.destination_element.info["reg_name"]

            elif ef.type == "ARITH":
                
                found = _rec_find(ef.params[0])

                to_return = []
                for r in found:
                    if r not in to_return:
                        to_return.append(r)

                return to_return, ef.destination_element.info["reg_name"]

        # generator that computes all the possible 
        # value transitions for the given registers, according to trans graph
        # (including identity replacements)
        # NOTE: a reg from regs_to_replace is a fixed source, and the outputs contain all possible destinations
        # NOTE: it assumes there is no stack element
        def _replace_seq_gen(regs_to_replace: List[str]):
            
            if len(regs_to_replace) == 0:
                yield []

            else:
                current_reg = regs_to_replace[0]
                for suffix in _replace_seq_gen(regs_to_replace[1:]):
                    
                    for dest in path_from.keys():
                        if (path_from[dest][current_reg] is True) and (dest not in suffix):

                            yield [dest] + suffix

        # generator that returns all nodes that can reach dest_reg
        # NOTE: the dest_reg is a fixed destination, and the results contain all possible sources
        def _replace_dest_reg(dest_reg: str):
            
            for src, is_path in path_from[dest_reg].items():
                if is_path is True:
                    yield src

        # creates a new copy of the given effect,
        # and replaces all reg_in elements and, separately, the destination register
        # NOTE: it assumes there is no stack element
        def _apply_substitutions(ef: _effect, regs_to_replace: List[str], replacements: List[str], dest_reg_replacement: str):
            
            def _rec_subst(el: _structured_element):

                if el is None:
                    return None

                if el.type == "reg_in":
                    el.info["reg_name"] = replacements[regs_to_replace.index(el.info["reg_name"])]

                elif el.is_op():
                    _rec_subst(el.info["term_1"])
                    _rec_subst(el.info["term_2"])

                elif el.type == "64b_stack_val":
                    raise RuntimeError("wanted effect contains stack elements")

            subst_ef = deepcopy(ef)
            subst_ef.destination_element.info["reg_name"] = dest_reg_replacement

            if subst_ef.type == "ARITH":
                _rec_subst(subst_ef.params[0])

            return subst_ef

        # replace every Rk[i] with the corresponding Rx[i]
        # the rx should be part of the result yielded by replace seq gen called on rk
        # mss - max stack size
        def _genpath(rk: List[str], rx: List[str], mss: int):

            def _perm(n, k):

                if k == 0:
                    yield []

                else:
                    for suf in _perm(n, k - 1):
                        for i in range(n):
                            if i not in suf:
                                yield [i] + suf

            def _internal_genpath(_rk, _rx, _mss):

                if len(_rk) == 0:
                    yield [], 0

                else:
                    rk_current = _rk[0]
                    rx_current = _rx[0]

                    for trans_gs, stack_size in self.transition_chain_generator(rx_current, rk_current, trans_graph, _mss):
                        for suffix, suf_stack_size in _internal_genpath(_rk[1:], _rx[1:], _mss - stack_size):

                            yield trans_gs + suffix, suf_stack_size + stack_size

            for p in _perm(len(rk), len(rk)):

                shuffled_rk = [rk[i] for i in p]
                shuffled_rx = [rx[i] for i in p]

                for path, stack_size in _internal_genpath(shuffled_rk, shuffled_rx, mss):
                    yield path, stack_size

        try:

            wef_used_regs, dest_reg = _find_used_regs(wanted_effect)

            for repl_seq in _replace_seq_gen(wef_used_regs):
                for repl_dest_reg in _replace_dest_reg(dest_reg):
                    
                    wef_subst = _apply_substitutions(wanted_effect, regs_to_replace=wef_used_regs, 
                                                        replacements=repl_seq, dest_reg_replacement=repl_dest_reg)

                    gs = self.search_gadget(wef_subst, max_stack_size=max_stack_size, fixed_reg_list=[],
                                            reg_start_values=[], max_search_cnt=2 ** 63)

                    if len(gs) == 0:
                        continue

                    try:

                        # for each gadget that satisfies wanted effect with substitutions
                        #   for each way to move the result from intermediary dest reg to the real dest reg
                        #       for each way to replace all the reg_in elements
                        for wef_g in gs:

                            mss_aux1 = max_stack_size - wef_g.get_stack_size()
                            for repl_dest_path, ss_1 in self.transition_chain_generator(dest_reg, repl_dest_reg, trans_graph, mss_aux1):
                                
                                mss_aux2 = mss_aux1 - ss_1
                                if mss_aux2 < 0:
                                    raise RuntimeError(f"stack size bigger than mss in genpath: {mss_aux1}, max {ss_1}")

                                for path, ss_2 in _genpath(wef_used_regs, repl_seq, mss_aux2):

                                    if ss_2 > mss_aux2:
                                        raise RuntimeError(f"stack size bigger than mss in genpath: {ss_2}, max {mss_aux2}")

                                    # join from the end to the beginning: repl_dest_path, g, path
                                    final_path: List[ROP_gadget]
                                    final_path = repl_dest_path + [wef_g] + path

                                    if _ROP_searcher._check_if_duplicate(path, b_cache) is True:
                                        continue

                                    candidate_ch = ROP_chain.convert(final_path[-1].duplicate()[0])
                                    for g_aux in final_path[-2::-1]:
                    
                                        candidate_ch_aux = candidate_ch.join(g_aux)
                                        candidate_ch.remove_stack_ids()
                                        candidate_ch = candidate_ch_aux
                                
                                    if candidate_ch.get_stack_size() != ss_1 + ss_2 + wef_g.get_stack_size():
                                        raise RuntimeError(f"stack size inconsistent: expected {ss_1 + ss_2 + wef_g.get_stack_size()}, got {candidate_ch.get_stack_size()}")

                                    b = candidate_ch.get_bytes()
                                    if b in b_cache.keys():
                                        candidate_ch.remove_stack_ids()
                                        continue
                                    
                                    b_cache.update({b: False})

                                    # check if the obtained result really matches the wanted effect
                                    # (check is needed because the transition paths' side effects are not taken into account when searching)

                                    # also, the start values are plugged in
                                    candidate_ch_cpy, org_to_fstid = candidate_ch.duplicate()

                                    start_values_cpy = deepcopy(reg_start_values)
                                    candidate_ch_cpy.effects = _effect.join_effects(start_values_cpy, candidate_ch_cpy.effects)

                                    to_check_effect: _effect = None
                                    for ef in candidate_ch_cpy.effects:

                                        if ef.destination_element.info["reg_name"] == dest_reg:
                                            to_check_effect = ef
                                            break
                                    
                                    if to_check_effect is None:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    wanted_effect_cpy = deepcopy(wanted_effect)

                                    if wanted_effect_cpy.match(to_check_effect) is False:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    if candidate_ch_cpy.check_fixed_regs(fixed_reg_list) is False:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    # match arith might have changed some stack values
                                    accepted_chain, org_to_sndid = candidate_ch.duplicate(copy_stack_associated_values=True)

                                    for org_stack_elem in candidate_ch.stack.elements:
                                        if org_stack_elem.type == "64b_stack_val":

                                            fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                                            if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != _64b_stack_view.stack_values[fstid]:

                                                if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                                    raise RuntimeError("original chain and cloned chain non-null values are different")

                                                sndid = _get_new_id(org_to_sndid, org_stack_elem.info["id"])
                                                _64b_stack_view.stack_values[sndid] = _64b_stack_view.stack_values[fstid]

                                    candidate_ch_cpy.remove_stack_ids()
                                    candidate_ch.remove_stack_ids()

                                    b_cache[b] = True
                                    yield accepted_chain

                    finally:

                        g: ROP_gadget
                        for g in gs:
                            g.remove_stack_ids()
        
        finally:

            # clean up unused stack ids
            for _, d in trans_graph.items():
                for _, gs in d.items():
                    if gs is not None:
                        for g in gs:
                            g.remove_stack_ids()
    
    # exactly like the above method
    # but also tries to substitute constants
    def _search_chain_by_substitution_adv(self, wanted_effect: _effect, max_stack_size: int = 20, fixed_reg_list: List[str] = [], 
                                        reg_start_values: List[_effect] = [], b_cache: Dict[bytes, bool] = {}):

        if wanted_effect.type not in ["ARITH", "LOAD_CT"]:
            raise RuntimeError(f"tyring to search chain inside _search_chain_by_substitution for wanted effect type {wanted_effect.type}")

        # graph as a list(dict) of neighbours, and the path existence matrix
        trans_graph, path_from = self.get_trans_reg_graph()

        # gadget {Ri: {CTj: [gk, ...]}, ...} that stores gadgets of type gk: Ri <- CTj
        # almost the same as _ROP_searcher.effects_to_gadgets
        load_ct_gadgets_cache: Dict[str, Dict[int, List[ROP_gadget]]] = {r: {} for r in self.platform.SUPPORTED_REGS}

        # auxiliary method that helps with substituting constants
        def _init_ct_g_cache():

            for r in self.platform.SUPPORTED_REGS:
                for g in self.effects_to_gadgets["LOAD_CT"][r]:
                    
                    for ef in g.effects:
                        if ef.destination_element.info["reg_name"] == r:

                            ct = ef.params[0].info["value"]

                            if ct in load_ct_gadgets_cache[r].keys():
                                load_ct_gadgets_cache[r][ct].append(g)
                            else:
                                load_ct_gadgets_cache[r].update({ct: [g]})

        # auxiliary method
        def _get_new_id(old_new_id: Dict[int, int], old_id: int):

            if old_id in old_new_id.keys():
                return old_new_id[old_id]

            return None

        # returns a list of all reg_in and constants used, and the reg_out
        # the registers or constants that can(will) be substituted in this function
        # are simply called symbols 
        def _find_subst_symbols(ef: _effect) -> Tuple[List[str | int], str]:

            def _rec_find(el: _structured_element):
                
                if el is None:
                    return []

                if el.type == "reg_in":
                    return [el.info["reg_name"]]

                if el.type == "ct_val":
                    return [el.info["value"]]

                if el.is_op():
                    return _rec_find(el.info["term_1"]) + _rec_find(el.info["term_2"])

                if el.type == "64b_stack_val":
                    raise RuntimeError("wanted effect contains stack elements")

                return []

            if ef.type == "LOAD_CT":
                return [], ef.destination_element.info["reg_name"]

            elif ef.type == "ARITH":
                
                found = _rec_find(ef.params[0])
                
                to_return = []
                for sym in found:
                    if sym not in to_return:
                        to_return.append(sym)

                return to_return, ef.destination_element.info["reg_name"]

        # generator that computes all the possible 
        # value transitions for the given registers, according to trans graph
        # and all possible constant substitution with registers, also according to trans graph
        # but also according to load_ct_gadgets_cache
        # it includes identity replacements, both for registers and constants (the case a constant is NOT replaced is marked with None)
        # NOTE: a reg from syms_to_replace is a fixed source, and the outputs contain all possible destinations
        # NOTE: it assumes there is no stack element
        def _replace_seq_gen(syms_to_replace: List[str | int]):
            
            if len(syms_to_replace) == 0:
                yield []

            else:
                current_sym = syms_to_replace[0]
                for suffix in _replace_seq_gen(syms_to_replace[1:]):
                    
                    # it is a register to be substituted
                    if current_sym in self.platform.SUPPORTED_REGS:
                    
                        for dest in path_from.keys():
                            if (path_from[dest][current_sym] is True) and (dest not in suffix):

                                yield [dest] + suffix

                    # it is a constant to be substituted
                    else:
                        
                        # base case when the constant is NOT replaced
                        yield [None] + suffix
                        
                        for r, gs_dict in load_ct_gadgets_cache.items():
                            if current_sym in gs_dict.keys():
                                
                                for r_ in self.platform.SUPPORTED_REGS:
                                    if (path_from[r_][r] is True) and (r_ not in suffix):

                                        yield [(r_, r)] + suffix

        # generator that returns all nodes that can reach dest_reg
        # NOTE: the dest_reg is a fixed destination, and the results contain all possible sources
        def _replace_dest_reg(dest_reg: str):
            
            for src, is_path in path_from[dest_reg].items():
                if is_path is True:
                    yield src

        # creates a new copy of the given effect,
        # and replaces all reg_in elements and constants, and, separately, the destination register
        # NOTE: it assumes there is no stack element
        def _apply_substitutions(ef: _effect, syms_to_replace: List[str | int], replacements: List[str | None | Tuple[str, str]], dest_reg_replacement: str):
            
            def _rec_subst(el: _structured_element):

                if el is None:
                    return None

                if el.type == "reg_in":
                    el.info["reg_name"] = replacements[syms_to_replace.index(el.info["reg_name"])]

                elif el.type == "ct_val":
                    
                    subst = replacements[syms_to_replace.index(el.info["value"])]
                    if subst is not None:

                        el.type = "reg_in"
                        el.info = {"reg_name": subst[0]}

                elif el.is_op():
                    _rec_subst(el.info["term_1"])
                    _rec_subst(el.info["term_2"])

                elif el.type == "64b_stack_val":
                    raise RuntimeError("wanted effect contains stack elements")

            subst_ef = deepcopy(ef)
            subst_ef.destination_element.info["reg_name"] = dest_reg_replacement

            if subst_ef.type == "ARITH":
                _rec_subst(subst_ef.params[0])

            return subst_ef

        # replace every Rk[i] with the corresponding Rx[i]
        # the rx should be part of the result yielded by replace seq gen called on rk
        # mss - max stack size
        def _genpath(rk: List[str | int], rx: List[str | None | Tuple[str, str]], mss: int):

            def _perm(n, k):

                if k == 0:
                    yield []

                else:
                    for suf in _perm(n, k - 1):
                        for i in range(n):
                            if i not in suf:
                                yield [i] + suf

            def _internal_genpath(_rk, _rx, _mss):

                if _mss < 1:
                    return

                if len(_rk) == 0:
                    yield [], 0

                else:

                    rk_current = _rk[0]
                    rx_current = _rx[0]

                    # Rx <- Rk register substitution
                    if rk_current in self.platform.SUPPORTED_REGS:

                        for trans_gs, stack_size in self.transition_chain_generator(rx_current, rk_current, trans_graph, _mss):
                            for suffix, suf_stack_size in _internal_genpath(_rk[1:], _rx[1:], _mss - stack_size):

                                yield trans_gs + suffix, suf_stack_size + stack_size

                    # Rx <- CT constant to register substitution
                    elif rx_current is not None:

                        subst_reg, loadct_reg = rx_current

                        for trans_gs, stack_size in self.transition_chain_generator(subst_reg, loadct_reg, trans_graph, _mss):
                            for loadct_g in load_ct_gadgets_cache[loadct_reg][rk_current]:

                                loadct_g_ss = loadct_g.get_stack_size()

                                for suffix, suf_stack_size in _internal_genpath(_rk[1:], _rx[1:], _mss - stack_size - loadct_g_ss):
                                    yield trans_gs + [loadct_g] + suffix, suf_stack_size + stack_size + loadct_g_ss

                    # CT remains unchanged
                    else:
                        yield from _internal_genpath(_rk[1:], _rx[1:], _mss)

            for p in _perm(len(rk), len(rk)):

                shuffled_rk = [rk[i] for i in p]
                shuffled_rx = [rx[i] for i in p]

                for path, stack_size in _internal_genpath(shuffled_rk, shuffled_rx, mss):
                    yield path, stack_size

        try:

            _init_ct_g_cache()

            wef_used_syms, dest_reg = _find_subst_symbols(wanted_effect)

            for repl_seq in _replace_seq_gen(wef_used_syms):
                for repl_dest_reg in _replace_dest_reg(dest_reg):
                    
                    wef_subst = _apply_substitutions(wanted_effect, syms_to_replace=wef_used_syms, 
                                                        replacements=repl_seq, dest_reg_replacement=repl_dest_reg)

                    gs = self.search_gadget(wef_subst, max_stack_size=max_stack_size, fixed_reg_list=[],
                                            reg_start_values=[], max_search_cnt=2 ** 63)

                    if len(gs) == 0:
                        continue

                    try:

                        # for each gadget that satisfies wanted effect with substitutions
                        #   for each way to move the result from intermediary dest reg to the real dest reg
                        #       for each way to replace all the reg_in elements
                        for wef_g in gs:

                            mss_aux1 = max_stack_size - wef_g.get_stack_size()
                            for repl_dest_path, ss_1 in self.transition_chain_generator(dest_reg, repl_dest_reg, trans_graph, mss_aux1):
                                
                                mss_aux2 = mss_aux1 - ss_1
                                if mss_aux2 < 0:
                                    raise RuntimeError(f"stack size bigger than mss in genpath: {mss_aux1}, max {ss_1}")

                                for path, ss_2 in _genpath(wef_used_syms, repl_seq, mss_aux2):

                                    if ss_2 > mss_aux2:
                                        raise RuntimeError(f"stack size bigger than mss in genpath: {ss_2}, max {mss_aux2}")

                                    # join from the end to the beginning: repl_dest_path, g, path
                                    final_path: List[ROP_gadget]
                                    final_path = repl_dest_path + [wef_g] + path

                                    if _ROP_searcher._check_if_duplicate(path, b_cache) is True:
                                        continue

                                    candidate_ch = ROP_chain.convert(final_path[-1].duplicate()[0])
                                    for g_aux in final_path[-2::-1]:
                    
                                        candidate_ch_aux = candidate_ch.join(g_aux)
                                        candidate_ch.remove_stack_ids()
                                        candidate_ch = candidate_ch_aux
                                
                                    if candidate_ch.get_stack_size() != ss_1 + ss_2 + wef_g.get_stack_size():
                                        raise RuntimeError(f"stack size inconsistent: expected {ss_1 + ss_2 + wef_g.get_stack_size()}, got {candidate_ch.get_stack_size()}")

                                    b = candidate_ch.get_bytes()
                                    if b in b_cache.keys():
                                        candidate_ch.remove_stack_ids()
                                        continue
                                    
                                    b_cache.update({b: False})

                                    # check if the obtained result really matches the wanted effect
                                    # (check is needed because the transition paths' side effects are not taken into account when searching)

                                    # also, the start values are plugged in
                                    candidate_ch_cpy, org_to_fstid = candidate_ch.duplicate()

                                    start_values_cpy = deepcopy(reg_start_values)
                                    candidate_ch_cpy.effects = _effect.join_effects(start_values_cpy, candidate_ch_cpy.effects)

                                    to_check_effect: _effect = None
                                    for ef in candidate_ch_cpy.effects:

                                        if ef.destination_element.info["reg_name"] == dest_reg:
                                            to_check_effect = ef
                                            break
                                    
                                    if to_check_effect is None:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    wanted_effect_cpy = deepcopy(wanted_effect)

                                    if wanted_effect_cpy.match(to_check_effect) is False:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    if candidate_ch_cpy.check_fixed_regs(fixed_reg_list) is False:
                                        candidate_ch_cpy.remove_stack_ids()
                                        candidate_ch.remove_stack_ids()
                                        continue

                                    # match arith might have changed some stack values
                                    accepted_chain, org_to_sndid = candidate_ch.duplicate(copy_stack_associated_values=True)

                                    for org_stack_elem in candidate_ch.stack.elements:
                                        if org_stack_elem.type == "64b_stack_val":

                                            fstid = _get_new_id(org_to_fstid, org_stack_elem.info["id"])
                                            if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != _64b_stack_view.stack_values[fstid]:

                                                if _64b_stack_view.stack_values[org_stack_elem.info["id"]] != None:
                                                    raise RuntimeError("original chain and cloned chain non-null values are different")

                                                sndid = _get_new_id(org_to_sndid, org_stack_elem.info["id"])
                                                _64b_stack_view.stack_values[sndid] = _64b_stack_view.stack_values[fstid]

                                    candidate_ch_cpy.remove_stack_ids()
                                    candidate_ch.remove_stack_ids()

                                    b_cache[b] = True
                                    yield accepted_chain

                    finally:

                        g: ROP_gadget
                        for g in gs:
                            g.remove_stack_ids()
        
        finally:

            # clean up unused stack ids
            for _, d in trans_graph.items():
                for _, gs in d.items():
                    if gs is not None:
                        for g in gs:
                            g.remove_stack_ids()

# auxiliary class that helps in building the payload
class ROP_payload:

    class _alignment:

        # default alignment at the beginning of a payload
        DEFAULT_ALIGNMENT = 8

        SUPPORTED_ALIGNMENTS = [8, 16, 32, 64]
        
        def __init__(self, bound: int, is_aligned = False):

            self.bound = bound
            self.is_aligned = is_aligned

    class _addr:

        def __init__(self, addr: int):
            self.addr = addr

    def __init__(self, rop_searcher, output_handle = stdout):

        self.logger = Logger(session_name = "PAYLOAD BUILDER", output_handle = output_handle)
        self.rop_searcher: _ROP_searcher = rop_searcher
        
        self.pad_byte = b'A'
        self.max_b_size = 160
        self.forbidden_bytes: List[bytes] = []

        self._raw_payload: List[ROP_payload._addr | bytes | ROP_payload._alignment | ROP_chain] = []

    def set_max_size(self, max_byte_size: int) -> None:
        self.max_b_size = max_byte_size

    def add_chain(self, ch: ROP_chain) -> None:
        self._raw_payload.append(ch)

    def add_bytes(self, b: bytes) -> None:
        self._raw_payload.append(b)

    def add_padding(self, pad_len: int)-> None:
        self._raw_payload.append(self.pad_byte * pad_len)

    def add_addr(self, addr: int) -> None:
        self._raw_payload.append(ROP_payload._addr(addr))

    # it marks that the stack is aligned to the specified boundary
    # thus ignoring the (deduced) alignment up to this point
    def is_aligned_as(self, bound: int = 8) -> None:

        if bound not in ROP_payload._alignment.SUPPORTED_ALIGNMENTS:
            raise RuntimeError(f"Requested stack alignment of {bound} bytes is not supported")

        self._raw_payload.append(ROP_payload._alignment(bound, is_aligned = True))

    # when building payload
    # this statement is equivalent to adding return-only gadgets
    def align_as(self, bound: int = 8) -> None:

        if bound not in ROP_payload._alignment.SUPPORTED_ALIGNMENTS:
            raise RuntimeError(f"Requested stack alignment of {bound} bytes is not supported")

        self._raw_payload.append(ROP_payload._alignment(bound, is_aligned = False))

    # remove the last added element
    def remove_last_added(self) -> None:

        if len(self._raw_payload) > 0:
            self._raw_payload.pop()

    # method responsible for building final payload, in bytes
    # NOTE: addr offset does NOT apply to given "naked" addresses,
    #       only to chain(gadget) addresses (and ret-only alignment gadgets)
    def build(self, chain_addr_offset: int = 0) -> bytes:

        _t = self.logger.log_info("Building payload...", start_timer = True)
        
        payload = b''

        # check if bytes contain any forbidden byte
        def _check_bytes(to_check: bytes):

            for b in to_check:
                if b in self.forbidden_bytes:
                    return False

            return True

        # returns the (biggest) alignment
        def _check_alignment(to_check_len: int):
            
            for al in ROP_payload._alignment.SUPPORTED_ALIGNMENTS[::-1]:
                if to_check_len % al == 0:
                    return al

            return 0

        # searches for return address 
        # that does not contain forbidden bytes
        _cached_ret_addr = None
        def _get_ret_addr():

            nonlocal _cached_ret_addr
            
            if _cached_ret_addr is None:
                for ret_addr in self.rop_searcher.retonly_gadget.get_current_addrs():

                    b_ret_addr = to_bytes(ret_addr + chain_addr_offset)
                    if _check_bytes(b_ret_addr) is True:

                        _cached_ret_addr = b_ret_addr
                        break

            return _cached_ret_addr

        # preprocess the payload:
        #   * join adjacent chains
        def _preprocess():

            preproc_payload = [self._raw_payload[0]]

            for i in range(1, len(self._raw_payload)):

                if (type(preproc_payload[-1]) != ROP_chain) or (type(self._raw_payload[i]) != ROP_chain):
                    preproc_payload.append(self._raw_payload[i])

                elif (type(preproc_payload[-1]) == ROP_chain) and (type(self._raw_payload[i]) == ROP_chain):

                    aux_ch = preproc_payload[-1].join(self._raw_payload[i])
                    preproc_payload[-1].remove_stack_ids()
                    preproc_payload[-1] = aux_ch

                else:
                    raise RuntimeError(f"Encountered element of unknown type {type(self._raw_payload[i])} while trying to make payload")

            return preproc_payload

        preproc_payload = _preprocess()

        b_mss = self.max_b_size
        alignment_aux = ROP_payload._alignment.DEFAULT_ALIGNMENT
        
        for item in preproc_payload:

            if type(item) == bytes:

                if _check_bytes(item) is True:

                    payload += item
                    b_mss -= len(item)

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += len(item)
                    alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("Some given bytes for building payload contains forbidden bytes", end_timer = _t)
                    return None

            elif type(item) == ROP_payload._addr:

                b_item = to_bytes(item.addr)

                if _check_bytes(b_item) is True:

                    payload += b_item
                    b_mss -= 8

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += 8
                    alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("A given address for building payload contains forbidden bytes", end_timer = _t)
                    return None

            elif type(item) == ROP_payload._alignment:

                if item.is_aligned is False:
                    
                    current_alignment = _check_alignment(alignment_aux)
                    while current_alignment < item.bound:

                        b_ret_addr = _get_ret_addr()
                        if b_ret_addr is None:

                            self.logger.log_warning("Could not find return address for alignment that does not contain forbidden bytes", end_timer = _t)
                            return None

                        payload += b_ret_addr
                        b_mss -= 8

                        if b_mss < 0:
                            self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                            return None

                        alignment_aux += 8
                        alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]
                        current_alignment = _check_alignment(alignment_aux)

                else:
                    alignment_aux = item.bound

            elif type(item) == ROP_chain:

                if b_mss < 8:
                    self.logger.log_warning(f"Not enough payload length for constructing payload for a given chain: only {b_mss} bytes left", end_timer = _t)
                
                payload_ = item._make_payload(max_stack_size = b_mss // 8, forbidden_bytes = self.forbidden_bytes, 
                                                addr_offset = chain_addr_offset, pad_byte = self.pad_byte)
                if payload_ is not None:

                    payload += payload_
                    b_mss -= len(payload_)

                    if b_mss < 0:
                        self.logger.log_warning(f"Maximum payload byte size surpassed by (at least) {-b_mss} bytes", end_timer = _t)
                        return None

                    alignment_aux += len(payload_)
                    alignment_aux %= ROP_payload._alignment.SUPPORTED_ALIGNMENTS[-1]

                else:
                    self.logger.log_warning("Creating payload for a given rop chain failed", end_timer = _t)
                    return None

        self.logger.log_success("Successfully built the payload", end_timer = _t)

        return payload

# main class, the "entry point" in using the functionalities implemented in this file
# it only implements a tiny fraction of the functionality the ROP concept can provide
# but it should be easy to extend at any time
class ROP_util:

    def __init__(self, filepath: str, platform: Platform, session_name = "ROP_util", print_log = True):
        
        self.platform = platform
        self.filepath = filepath
        self.rop_searcher = _ROP_searcher(filepath, platform)

        self.logger = Logger(session_name = session_name, print_log = print_log)

    def scout_for_gadgets(self) -> None:

        _t = self.logger.log_info(f"Analysing the binary {self.filepath} ...", start_timer = True)

        self.rop_searcher.find_ret_gadgets()

        self.logger.log_success(f"Done analysing the binary {self.filepath}", end_timer = _t)

    # method that parses the input 
    # in an internal format
    def _parse_input(self, wanted_effects_raw: str, reg_start_values_raw: str) -> Tuple[List[_effect], List[_effect]]:

        def _parse_expr(raw: str) -> _structured_element:

            # reg
            if raw in self.platform.SUPPORTED_REGS:

                el = _structured_element.instantiate_structured_element("reg_in")
                el.info["reg_name"] = raw

                return el

            # value
            ct = _is_int(raw)
            if ct is not None:

                el = _structured_element.instantiate_structured_element("ct_val")
                el.info["value"] = ct

                return el

            # negation
            if raw[0] == "!":

                to_negate = _parse_expr(raw[1:].strip())

                el = _structured_element.instantiate_structured_element("neg")
                el.info["term_1"] = to_negate

                return el           

            # binary operations and paranthesis     

            bin_ops = {"+": "add", "-": "sub", "&": "and", "|": "or", "^": "xor"}

            open_paranthesis = 0

            op = None
            left_operand_raw = None
            right_operand_raw = None

            for i in range(len(raw)):
                c = raw[i]

                if c == "(":
                    open_paranthesis += 1

                elif c == ")":
                    open_paranthesis -= 1

                elif (open_paranthesis == 0) and (c in bin_ops.keys()):
                    
                    op = c
                    left_operand_raw, right_operand_raw = raw[:i].strip(), raw[i + 1:].strip()
                    break
            
            if op is not None:
                
                el = _structured_element.instantiate_structured_element(bin_ops[op])
                el.info["term_1"] = _parse_expr(left_operand_raw)
                el.info["term_2"] = _parse_expr(right_operand_raw)

                return el

            elif open_paranthesis == 0 and raw[0] == "(" and raw[-1] == ")":
                return _parse_expr(raw[1:-1].strip())

            raise RuntimeError(f"cannot parse statement {raw} while trying to search for chains")

        def _parse_effect(raw: str, split_s = "="):
            
            dest_reg, raw_assign = raw.split(split_s)
            dest_reg = dest_reg.strip()
            raw_assign = raw_assign.strip()

            if dest_reg not in self.platform.SUPPORTED_REGS:
                raise RuntimeError(f"cannot parse statement {raw} while trying to search for chains")
            
            wef = None
            wef_param = _parse_expr(raw_assign)

            if wef_param.type == "ct_val":
                wef = _effect.make_load_ct_effect(dest_reg, wef_param.info["value"])

            elif wef_param.type == "reg_in":
                wef = _effect.make_mov_rr_effect(dest_reg, wef_param.info["reg_name"])

            elif wef_param.is_op():
                wef = _effect.make_arith_custom_effect(dest_reg, wef_param)

            return wef

        wefs: List[_effect] = []
        start_values: List[_effect] = []

        raw_wefs = wanted_effects_raw.split(",")
        for raw_wef in raw_wefs:
            wefs.append(_parse_effect(raw_wef.strip(), split_s = "="))

        if "==" in reg_start_values_raw:
            raw_rsvs = reg_start_values_raw.split(",")
            for raw_rsv in raw_rsvs:
                start_values.append(_parse_effect(raw_rsv.strip(), split_s = "=="))

        return wefs, start_values

    # search a chain, specifying the effects in a statement
    # statement is parsed and converted in an internal format
    def search_chain(self, wanted_effects: str, fixed_regs: List[str] = [], reg_start_values: str = '', 
                        max_stack_byte_size: int = 160, max_search_cnt: int = 3, only_gadgets = False) -> Generator[ROP_chain]:

        _t = self.logger.log_info(f"Searching for chains in {self.filepath}...", start_timer = True)
        
        wanted_effects, reg_start_values = self._parse_input(wanted_effects, reg_start_values)
        max_stack_size = max_stack_byte_size // 8

        found_cnt = 0
        
        for ch in self.rop_searcher.search_chain(wanted_effects = wanted_effects, max_stack_size = max_stack_size,
                                                fixed_reg_list = fixed_regs, reg_start_values = reg_start_values, only_gadgets = only_gadgets):
            yield ch

            found_cnt += 1
            if found_cnt == max_search_cnt:

                self.logger.log_success(f"Done searching for chains in {self.filepath}", end_timer = _t)
                return

        self.logger.log_warning(f"Could not find requested chains in {self.filepath}", end_timer = _t)

    def disable_bruteforce(self) -> None:
        self.rop_searcher.BRUTEFORCE_DEPTH = 0

    # enable bruteforce when searching chains
    # chain_g_depth - max number of gadgets to form a chain (distinct or not)
    def enable_bruteforce(self, chain_g_depth = 2) -> None:
        self.rop_searcher.BRUTEFORCE_DEPTH = chain_g_depth

    # returns a payload object
    # does NOT return payload bytes
    def make_payload(self) -> ROP_payload:
        return ROP_payload(self.rop_searcher)
